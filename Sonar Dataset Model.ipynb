{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Model - Sonar Dataset\n",
    "\n",
    "The task of the trained model is to train a network to discriminate between sonar signals bounced off a metal cylinder and those bounced off a roughly cylindrical rock."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set the seed\n",
    "Sets the starting integer value while generating the random numbers.That means that  a random result will occur everytime a line of code is run without specifying random_state, this is expected behavior. Examples can be seen when shuffling data i.e. K-Fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"sonar.csv\", delimiter = ',')\n",
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:60].astype(float)\n",
    "Y = dataset[:,60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Defining the model\n",
    "\n",
    "The Sequential model is a 'box' that contain layers of the neural network. \n",
    "As exhibited, there are three Dense layers in this model - which means that all layers are fully connected. \n",
    "i.e all neurons are connected to each other.\n",
    "\n",
    "Input dimension: It is the number of columns in the tabular data set. (this is also the number of attributes)\n",
    "\n",
    "Activation functions  \n",
    "Relu: Rectified linear unit function, it has a low tax on computational memory due to its simple algorithim, it also provides sparsity which aids in predicting unknown/future data.\n",
    "Sigmoid: Replaces Final layer in a binary classification model always has a sigmoid activation fucntion as it has to produce a probability output between 0 and 1.\n",
    "\n",
    "Finally, the digits in each layer represent number of neurons in each layer. Realise the last layer has one neuron that is our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    # create model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(60, input_dim=60, activation = 'relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "K-Fold cross validation is used to enhance the overall performance of the model. Shuffling 10 folds, each with 30 sections. The seed comes works as a checkpoint in this instance, it allows themodel to provide consistant loss and accuracy measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 81.07% (7.23%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_baseline, epochs = 100, batch_size = 50, verbose = 0) \n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = seed)\n",
    "results = cross_val_score(estimator, X,Y, cv = kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" %(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 5: Data preparation \n",
    "\n",
    "Data can be prepared using scikit-learn 'StandardScaler' function. This standardises our tabular data and preserves Gaussian-like (normal dist.) whilst normalising tendencies for each attribute.\n",
    "\n",
    "Another function from scikit-learn is Pipeline, this allows standardization to affect solely the training data. Often used once initial exploration is done. It chains different transformers and estimators and applies them to the training data. Ultimately looping through several models to find the best one. In this case Pipeline will be used as an estimator and pass to cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardised: 84.54% (6.68%)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardise', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs = 100, batch_size = 50, verbose = 0))) \n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv = kfold)\n",
    "print(\"Standardised: %.2f%% (%.2f%%)\" %(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Tuning the model - Layers and Hyperparameters\n",
    "\n",
    "Improving a neural network is achievable by tuning various things such as the optimizer's learning rate, activation functions, number of neurons and layers, etc. Two models have been created below based off of our baseline model: 1) Smaller model with half the neurons in previous model (60 to 30). This puts pressure on the network to pick most important structure in the input data to model. (This will also be standardised to boost performance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smaller: 84.11% (6.31%)\n"
     ]
    }
   ],
   "source": [
    "def create_smaller():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=60, activation = 'relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "estimators = []\n",
    "estimators.append(('standardise', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs = 100, batch_size = 50, verbose = 0))) \n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv = kfold)\n",
    "print(\"Smaller: %.2f%% (%.2f%%)\" %(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "Expanding the model to include an extra layer has actually increased overall performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Larger: 84.07% (6.40%)\n"
     ]
    }
   ],
   "source": [
    "def create_larger():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=60, activation = 'relu'))\n",
    "    model.add(Dense(40, activation = 'relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    return model\n",
    "estimators = []\n",
    "estimators.append(('standardise', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs = 100, batch_size = 50, verbose = 0))) \n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv = kfold)\n",
    "print(\"Larger: %.2f%% (%.2f%%)\" %(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout layer\n",
    "Adding a dropout layer to the stratified model had improved both loss and accuracy, however by conducting further analysis and optimising hyper parameters, its been evident that at a certain number of epochs data starts to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 155 samples, validate on 52 samples\n",
      "Epoch 1/500\n",
      "155/155 [==============================] - 4s 26ms/step - loss: 0.7552 - acc: 0.4645 - val_loss: 0.7567 - val_acc: 0.3269\n",
      "Epoch 2/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.7615 - acc: 0.4645 - val_loss: 0.7451 - val_acc: 0.3077\n",
      "Epoch 3/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.7755 - acc: 0.3677 - val_loss: 0.7353 - val_acc: 0.3269\n",
      "Epoch 4/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.7216 - acc: 0.4710 - val_loss: 0.7281 - val_acc: 0.3462\n",
      "Epoch 5/500\n",
      "155/155 [==============================] - 0s 59us/step - loss: 0.7465 - acc: 0.3935 - val_loss: 0.7219 - val_acc: 0.4423\n",
      "Epoch 6/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.7231 - acc: 0.5032 - val_loss: 0.7168 - val_acc: 0.4615\n",
      "Epoch 7/500\n",
      "155/155 [==============================] - 0s 60us/step - loss: 0.7264 - acc: 0.4516 - val_loss: 0.7128 - val_acc: 0.5385\n",
      "Epoch 8/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.7145 - acc: 0.4968 - val_loss: 0.7095 - val_acc: 0.5385\n",
      "Epoch 9/500\n",
      "155/155 [==============================] - 0s 59us/step - loss: 0.7363 - acc: 0.4774 - val_loss: 0.7067 - val_acc: 0.5385\n",
      "Epoch 10/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.7157 - acc: 0.4968 - val_loss: 0.7041 - val_acc: 0.5385\n",
      "Epoch 11/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.7104 - acc: 0.5613 - val_loss: 0.7016 - val_acc: 0.5385\n",
      "Epoch 12/500\n",
      "155/155 [==============================] - 0s 90us/step - loss: 0.7103 - acc: 0.5226 - val_loss: 0.6989 - val_acc: 0.5385\n",
      "Epoch 13/500\n",
      "155/155 [==============================] - 0s 94us/step - loss: 0.6992 - acc: 0.5161 - val_loss: 0.6959 - val_acc: 0.5385\n",
      "Epoch 14/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.6903 - acc: 0.5484 - val_loss: 0.6929 - val_acc: 0.5385\n",
      "Epoch 15/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.6967 - acc: 0.5419 - val_loss: 0.6899 - val_acc: 0.5385\n",
      "Epoch 16/500\n",
      "155/155 [==============================] - 0s 57us/step - loss: 0.6758 - acc: 0.5548 - val_loss: 0.6870 - val_acc: 0.5385\n",
      "Epoch 17/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.6964 - acc: 0.5226 - val_loss: 0.6843 - val_acc: 0.5385\n",
      "Epoch 18/500\n",
      "155/155 [==============================] - 0s 61us/step - loss: 0.6858 - acc: 0.5613 - val_loss: 0.6815 - val_acc: 0.5385\n",
      "Epoch 19/500\n",
      "155/155 [==============================] - 0s 89us/step - loss: 0.6591 - acc: 0.6065 - val_loss: 0.6789 - val_acc: 0.5577\n",
      "Epoch 20/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.6762 - acc: 0.5935 - val_loss: 0.6766 - val_acc: 0.5577\n",
      "Epoch 21/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.6817 - acc: 0.5548 - val_loss: 0.6743 - val_acc: 0.5769\n",
      "Epoch 22/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.6745 - acc: 0.5677 - val_loss: 0.6722 - val_acc: 0.5962\n",
      "Epoch 23/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.6552 - acc: 0.6065 - val_loss: 0.6703 - val_acc: 0.5769\n",
      "Epoch 24/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.6539 - acc: 0.6387 - val_loss: 0.6688 - val_acc: 0.6154\n",
      "Epoch 25/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.6652 - acc: 0.6194 - val_loss: 0.6672 - val_acc: 0.6346\n",
      "Epoch 26/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.6422 - acc: 0.6968 - val_loss: 0.6655 - val_acc: 0.6538\n",
      "Epoch 27/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.6607 - acc: 0.6000 - val_loss: 0.6635 - val_acc: 0.6346\n",
      "Epoch 28/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.6502 - acc: 0.6645 - val_loss: 0.6615 - val_acc: 0.6538\n",
      "Epoch 29/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.6436 - acc: 0.6710 - val_loss: 0.6593 - val_acc: 0.6538\n",
      "Epoch 30/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.6409 - acc: 0.6516 - val_loss: 0.6568 - val_acc: 0.6538\n",
      "Epoch 31/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.6739 - acc: 0.5871 - val_loss: 0.6542 - val_acc: 0.6731\n",
      "Epoch 32/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.6649 - acc: 0.6194 - val_loss: 0.6513 - val_acc: 0.6923\n",
      "Epoch 33/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.6097 - acc: 0.7290 - val_loss: 0.6483 - val_acc: 0.7115\n",
      "Epoch 34/500\n",
      "155/155 [==============================] - 0s 61us/step - loss: 0.6392 - acc: 0.6903 - val_loss: 0.6451 - val_acc: 0.7308\n",
      "Epoch 35/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.6208 - acc: 0.7484 - val_loss: 0.6417 - val_acc: 0.7308\n",
      "Epoch 36/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.6221 - acc: 0.6839 - val_loss: 0.6383 - val_acc: 0.7308\n",
      "Epoch 37/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.6344 - acc: 0.6710 - val_loss: 0.6348 - val_acc: 0.7308\n",
      "Epoch 38/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.6320 - acc: 0.6581 - val_loss: 0.6316 - val_acc: 0.7308\n",
      "Epoch 39/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.6309 - acc: 0.6516 - val_loss: 0.6285 - val_acc: 0.7308\n",
      "Epoch 40/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.6321 - acc: 0.6774 - val_loss: 0.6255 - val_acc: 0.7500\n",
      "Epoch 41/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.6159 - acc: 0.6839 - val_loss: 0.6226 - val_acc: 0.7500\n",
      "Epoch 42/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.6198 - acc: 0.6968 - val_loss: 0.6196 - val_acc: 0.7500\n",
      "Epoch 43/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.5972 - acc: 0.7097 - val_loss: 0.6169 - val_acc: 0.7500\n",
      "Epoch 44/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.6272 - acc: 0.6645 - val_loss: 0.6145 - val_acc: 0.7500\n",
      "Epoch 45/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.6063 - acc: 0.7097 - val_loss: 0.6123 - val_acc: 0.6923\n",
      "Epoch 46/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.5943 - acc: 0.7226 - val_loss: 0.6103 - val_acc: 0.6923\n",
      "Epoch 47/500\n",
      "155/155 [==============================] - 0s 81us/step - loss: 0.6031 - acc: 0.6968 - val_loss: 0.6083 - val_acc: 0.6923\n",
      "Epoch 48/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.6021 - acc: 0.6774 - val_loss: 0.6066 - val_acc: 0.6923\n",
      "Epoch 49/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.6103 - acc: 0.6968 - val_loss: 0.6048 - val_acc: 0.6923\n",
      "Epoch 50/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.5842 - acc: 0.7032 - val_loss: 0.6030 - val_acc: 0.6923\n",
      "Epoch 51/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.5868 - acc: 0.7290 - val_loss: 0.6012 - val_acc: 0.6923\n",
      "Epoch 52/500\n",
      "155/155 [==============================] - 0s 93us/step - loss: 0.6143 - acc: 0.6968 - val_loss: 0.5993 - val_acc: 0.6731\n",
      "Epoch 53/500\n",
      "155/155 [==============================] - 0s 89us/step - loss: 0.5831 - acc: 0.7290 - val_loss: 0.5974 - val_acc: 0.6731\n",
      "Epoch 54/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.5793 - acc: 0.7484 - val_loss: 0.5953 - val_acc: 0.6923\n",
      "Epoch 55/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.5830 - acc: 0.7613 - val_loss: 0.5931 - val_acc: 0.6923\n",
      "Epoch 56/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.5799 - acc: 0.7097 - val_loss: 0.5910 - val_acc: 0.6923\n",
      "Epoch 57/500\n",
      "155/155 [==============================] - 0s 81us/step - loss: 0.5713 - acc: 0.7419 - val_loss: 0.5889 - val_acc: 0.6923\n",
      "Epoch 58/500\n",
      "155/155 [==============================] - 0s 85us/step - loss: 0.5710 - acc: 0.7871 - val_loss: 0.5869 - val_acc: 0.6923\n",
      "Epoch 59/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.5777 - acc: 0.7097 - val_loss: 0.5849 - val_acc: 0.6923\n",
      "Epoch 60/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.5729 - acc: 0.7419 - val_loss: 0.5829 - val_acc: 0.6923\n",
      "Epoch 61/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.5633 - acc: 0.7161 - val_loss: 0.5809 - val_acc: 0.7115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "155/155 [==============================] - 0s 82us/step - loss: 0.5767 - acc: 0.7419 - val_loss: 0.5790 - val_acc: 0.7115\n",
      "Epoch 63/500\n",
      "155/155 [==============================] - 0s 106us/step - loss: 0.5579 - acc: 0.7742 - val_loss: 0.5771 - val_acc: 0.7115\n",
      "Epoch 64/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.5610 - acc: 0.7742 - val_loss: 0.5752 - val_acc: 0.7115\n",
      "Epoch 65/500\n",
      "155/155 [==============================] - 0s 82us/step - loss: 0.5557 - acc: 0.7677 - val_loss: 0.5734 - val_acc: 0.7115\n",
      "Epoch 66/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.5591 - acc: 0.7806 - val_loss: 0.5717 - val_acc: 0.7115\n",
      "Epoch 67/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.5562 - acc: 0.7742 - val_loss: 0.5700 - val_acc: 0.7115\n",
      "Epoch 68/500\n",
      "155/155 [==============================] - 0s 84us/step - loss: 0.5387 - acc: 0.7871 - val_loss: 0.5681 - val_acc: 0.7115\n",
      "Epoch 69/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.5618 - acc: 0.7871 - val_loss: 0.5662 - val_acc: 0.7308\n",
      "Epoch 70/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.5468 - acc: 0.7677 - val_loss: 0.5642 - val_acc: 0.7115\n",
      "Epoch 71/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.5515 - acc: 0.7290 - val_loss: 0.5623 - val_acc: 0.7115\n",
      "Epoch 72/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.5348 - acc: 0.7806 - val_loss: 0.5603 - val_acc: 0.7115\n",
      "Epoch 73/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.5459 - acc: 0.7548 - val_loss: 0.5581 - val_acc: 0.7115\n",
      "Epoch 74/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.5382 - acc: 0.7613 - val_loss: 0.5561 - val_acc: 0.7115\n",
      "Epoch 75/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.5365 - acc: 0.7677 - val_loss: 0.5540 - val_acc: 0.7308\n",
      "Epoch 76/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.5425 - acc: 0.7484 - val_loss: 0.5522 - val_acc: 0.7308\n",
      "Epoch 77/500\n",
      "155/155 [==============================] - 0s 85us/step - loss: 0.5208 - acc: 0.7613 - val_loss: 0.5504 - val_acc: 0.7308\n",
      "Epoch 78/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.5509 - acc: 0.7548 - val_loss: 0.5488 - val_acc: 0.7308\n",
      "Epoch 79/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.5268 - acc: 0.7935 - val_loss: 0.5473 - val_acc: 0.7308\n",
      "Epoch 80/500\n",
      "155/155 [==============================] - 0s 59us/step - loss: 0.5302 - acc: 0.7484 - val_loss: 0.5460 - val_acc: 0.7308\n",
      "Epoch 81/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.5224 - acc: 0.7742 - val_loss: 0.5449 - val_acc: 0.7115\n",
      "Epoch 82/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.5295 - acc: 0.7419 - val_loss: 0.5437 - val_acc: 0.7115\n",
      "Epoch 83/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.5253 - acc: 0.7935 - val_loss: 0.5426 - val_acc: 0.7115\n",
      "Epoch 84/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.5298 - acc: 0.7871 - val_loss: 0.5415 - val_acc: 0.7115\n",
      "Epoch 85/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.5060 - acc: 0.7806 - val_loss: 0.5405 - val_acc: 0.6923\n",
      "Epoch 86/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.4984 - acc: 0.8258 - val_loss: 0.5396 - val_acc: 0.6923\n",
      "Epoch 87/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.5335 - acc: 0.7677 - val_loss: 0.5388 - val_acc: 0.6923\n",
      "Epoch 88/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.5112 - acc: 0.8065 - val_loss: 0.5381 - val_acc: 0.6923\n",
      "Epoch 89/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.5177 - acc: 0.7677 - val_loss: 0.5375 - val_acc: 0.6923\n",
      "Epoch 90/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.4962 - acc: 0.8387 - val_loss: 0.5364 - val_acc: 0.6731\n",
      "Epoch 91/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.4981 - acc: 0.8000 - val_loss: 0.5350 - val_acc: 0.6923\n",
      "Epoch 92/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.5140 - acc: 0.8129 - val_loss: 0.5333 - val_acc: 0.6923\n",
      "Epoch 93/500\n",
      "155/155 [==============================] - 0s 84us/step - loss: 0.5012 - acc: 0.8065 - val_loss: 0.5316 - val_acc: 0.6923\n",
      "Epoch 94/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.4995 - acc: 0.7484 - val_loss: 0.5297 - val_acc: 0.6923\n",
      "Epoch 95/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.5083 - acc: 0.8065 - val_loss: 0.5281 - val_acc: 0.6923\n",
      "Epoch 96/500\n",
      "155/155 [==============================] - 0s 61us/step - loss: 0.5213 - acc: 0.7613 - val_loss: 0.5264 - val_acc: 0.7115\n",
      "Epoch 97/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.5123 - acc: 0.7935 - val_loss: 0.5250 - val_acc: 0.7115\n",
      "Epoch 98/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.4944 - acc: 0.8258 - val_loss: 0.5236 - val_acc: 0.7115\n",
      "Epoch 99/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.5329 - acc: 0.7871 - val_loss: 0.5224 - val_acc: 0.7115\n",
      "Epoch 100/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.5090 - acc: 0.7806 - val_loss: 0.5213 - val_acc: 0.7115\n",
      "Epoch 101/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.4909 - acc: 0.8065 - val_loss: 0.5201 - val_acc: 0.7115\n",
      "Epoch 102/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.4884 - acc: 0.8065 - val_loss: 0.5189 - val_acc: 0.7115\n",
      "Epoch 103/500\n",
      "155/155 [==============================] - 0s 91us/step - loss: 0.4914 - acc: 0.8452 - val_loss: 0.5176 - val_acc: 0.7115\n",
      "Epoch 104/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.4832 - acc: 0.8129 - val_loss: 0.5163 - val_acc: 0.7115\n",
      "Epoch 105/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.4910 - acc: 0.7677 - val_loss: 0.5150 - val_acc: 0.6923\n",
      "Epoch 106/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.4837 - acc: 0.8065 - val_loss: 0.5138 - val_acc: 0.6923\n",
      "Epoch 107/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.4965 - acc: 0.7484 - val_loss: 0.5125 - val_acc: 0.6923\n",
      "Epoch 108/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.4787 - acc: 0.8194 - val_loss: 0.5111 - val_acc: 0.6923\n",
      "Epoch 109/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.4797 - acc: 0.8065 - val_loss: 0.5095 - val_acc: 0.6923\n",
      "Epoch 110/500\n",
      "155/155 [==============================] - 0s 82us/step - loss: 0.4707 - acc: 0.8258 - val_loss: 0.5076 - val_acc: 0.6923\n",
      "Epoch 111/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.4747 - acc: 0.8323 - val_loss: 0.5058 - val_acc: 0.7115\n",
      "Epoch 112/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.4678 - acc: 0.8323 - val_loss: 0.5039 - val_acc: 0.7115\n",
      "Epoch 113/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.4668 - acc: 0.8323 - val_loss: 0.5020 - val_acc: 0.7115\n",
      "Epoch 114/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.4746 - acc: 0.8516 - val_loss: 0.5000 - val_acc: 0.7115\n",
      "Epoch 115/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.4658 - acc: 0.8323 - val_loss: 0.4979 - val_acc: 0.7115\n",
      "Epoch 116/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.4584 - acc: 0.8323 - val_loss: 0.4962 - val_acc: 0.7115\n",
      "Epoch 117/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.4758 - acc: 0.8000 - val_loss: 0.4949 - val_acc: 0.7115\n",
      "Epoch 118/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.4575 - acc: 0.8065 - val_loss: 0.4938 - val_acc: 0.7115\n",
      "Epoch 119/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.4779 - acc: 0.8194 - val_loss: 0.4929 - val_acc: 0.7115\n",
      "Epoch 120/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.4704 - acc: 0.8065 - val_loss: 0.4921 - val_acc: 0.7115\n",
      "Epoch 121/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.4693 - acc: 0.8129 - val_loss: 0.4915 - val_acc: 0.7308\n",
      "Epoch 122/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.4499 - acc: 0.8516 - val_loss: 0.4910 - val_acc: 0.7308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.4522 - acc: 0.8194 - val_loss: 0.4905 - val_acc: 0.7308\n",
      "Epoch 124/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.4511 - acc: 0.8516 - val_loss: 0.4901 - val_acc: 0.7308\n",
      "Epoch 125/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.4654 - acc: 0.7871 - val_loss: 0.4898 - val_acc: 0.7308\n",
      "Epoch 126/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.4718 - acc: 0.7871 - val_loss: 0.4891 - val_acc: 0.7308\n",
      "Epoch 127/500\n",
      "155/155 [==============================] - 0s 84us/step - loss: 0.4413 - acc: 0.8258 - val_loss: 0.4884 - val_acc: 0.7308\n",
      "Epoch 128/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.4565 - acc: 0.8065 - val_loss: 0.4874 - val_acc: 0.7308\n",
      "Epoch 129/500\n",
      "155/155 [==============================] - 0s 61us/step - loss: 0.4403 - acc: 0.8452 - val_loss: 0.4865 - val_acc: 0.7308\n",
      "Epoch 130/500\n",
      "155/155 [==============================] - 0s 82us/step - loss: 0.4508 - acc: 0.8452 - val_loss: 0.4854 - val_acc: 0.7308\n",
      "Epoch 131/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.4511 - acc: 0.8065 - val_loss: 0.4843 - val_acc: 0.7308\n",
      "Epoch 132/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.4527 - acc: 0.8129 - val_loss: 0.4832 - val_acc: 0.7308\n",
      "Epoch 133/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.4452 - acc: 0.8387 - val_loss: 0.4821 - val_acc: 0.7308\n",
      "Epoch 134/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.4437 - acc: 0.8129 - val_loss: 0.4810 - val_acc: 0.7308\n",
      "Epoch 135/500\n",
      "155/155 [==============================] - 0s 57us/step - loss: 0.4563 - acc: 0.8258 - val_loss: 0.4801 - val_acc: 0.7308\n",
      "Epoch 136/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.4594 - acc: 0.8258 - val_loss: 0.4793 - val_acc: 0.7308\n",
      "Epoch 137/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.4445 - acc: 0.8258 - val_loss: 0.4785 - val_acc: 0.7308\n",
      "Epoch 138/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.4375 - acc: 0.8387 - val_loss: 0.4779 - val_acc: 0.7308\n",
      "Epoch 139/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.4287 - acc: 0.8323 - val_loss: 0.4771 - val_acc: 0.7308\n",
      "Epoch 140/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.4410 - acc: 0.8516 - val_loss: 0.4764 - val_acc: 0.7308\n",
      "Epoch 141/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.4406 - acc: 0.8194 - val_loss: 0.4758 - val_acc: 0.7308\n",
      "Epoch 142/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.4526 - acc: 0.8194 - val_loss: 0.4752 - val_acc: 0.7308\n",
      "Epoch 143/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.4253 - acc: 0.8323 - val_loss: 0.4745 - val_acc: 0.7308\n",
      "Epoch 144/500\n",
      "155/155 [==============================] - 0s 85us/step - loss: 0.4451 - acc: 0.8258 - val_loss: 0.4737 - val_acc: 0.7308\n",
      "Epoch 145/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.4403 - acc: 0.8452 - val_loss: 0.4728 - val_acc: 0.7308\n",
      "Epoch 146/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.4249 - acc: 0.8387 - val_loss: 0.4719 - val_acc: 0.7308\n",
      "Epoch 147/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.4321 - acc: 0.8258 - val_loss: 0.4706 - val_acc: 0.7308\n",
      "Epoch 148/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.4399 - acc: 0.8323 - val_loss: 0.4693 - val_acc: 0.7308\n",
      "Epoch 149/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.4371 - acc: 0.8258 - val_loss: 0.4681 - val_acc: 0.7308\n",
      "Epoch 150/500\n",
      "155/155 [==============================] - 0s 61us/step - loss: 0.4292 - acc: 0.8581 - val_loss: 0.4671 - val_acc: 0.7308\n",
      "Epoch 151/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.4016 - acc: 0.8645 - val_loss: 0.4663 - val_acc: 0.7308\n",
      "Epoch 152/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.4215 - acc: 0.8516 - val_loss: 0.4656 - val_acc: 0.7308\n",
      "Epoch 153/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.4142 - acc: 0.8581 - val_loss: 0.4652 - val_acc: 0.7308\n",
      "Epoch 154/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.4202 - acc: 0.8258 - val_loss: 0.4647 - val_acc: 0.7308\n",
      "Epoch 155/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.4245 - acc: 0.8258 - val_loss: 0.4644 - val_acc: 0.7308\n",
      "Epoch 156/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.4043 - acc: 0.8645 - val_loss: 0.4642 - val_acc: 0.7308\n",
      "Epoch 157/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.4054 - acc: 0.8581 - val_loss: 0.4640 - val_acc: 0.7308\n",
      "Epoch 158/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.4248 - acc: 0.8323 - val_loss: 0.4637 - val_acc: 0.7308\n",
      "Epoch 159/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.4276 - acc: 0.8581 - val_loss: 0.4629 - val_acc: 0.7308\n",
      "Epoch 160/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.4216 - acc: 0.8516 - val_loss: 0.4619 - val_acc: 0.7308\n",
      "Epoch 161/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.4231 - acc: 0.8581 - val_loss: 0.4605 - val_acc: 0.7308\n",
      "Epoch 162/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.4277 - acc: 0.8323 - val_loss: 0.4590 - val_acc: 0.7308\n",
      "Epoch 163/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.4212 - acc: 0.8258 - val_loss: 0.4579 - val_acc: 0.7308\n",
      "Epoch 164/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.4287 - acc: 0.8581 - val_loss: 0.4570 - val_acc: 0.7308\n",
      "Epoch 165/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.3991 - acc: 0.8387 - val_loss: 0.4563 - val_acc: 0.7308\n",
      "Epoch 166/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.3966 - acc: 0.8323 - val_loss: 0.4553 - val_acc: 0.7308\n",
      "Epoch 167/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.3998 - acc: 0.8581 - val_loss: 0.4545 - val_acc: 0.7308\n",
      "Epoch 168/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.4107 - acc: 0.8194 - val_loss: 0.4538 - val_acc: 0.7308\n",
      "Epoch 169/500\n",
      "155/155 [==============================] - 0s 84us/step - loss: 0.4129 - acc: 0.8387 - val_loss: 0.4531 - val_acc: 0.7308\n",
      "Epoch 170/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.4072 - acc: 0.8387 - val_loss: 0.4528 - val_acc: 0.7308\n",
      "Epoch 171/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.4094 - acc: 0.8387 - val_loss: 0.4524 - val_acc: 0.7308\n",
      "Epoch 172/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.4208 - acc: 0.8645 - val_loss: 0.4521 - val_acc: 0.7308\n",
      "Epoch 173/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.4195 - acc: 0.8452 - val_loss: 0.4516 - val_acc: 0.7500\n",
      "Epoch 174/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.3996 - acc: 0.8903 - val_loss: 0.4508 - val_acc: 0.7500\n",
      "Epoch 175/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.3966 - acc: 0.8581 - val_loss: 0.4498 - val_acc: 0.7308\n",
      "Epoch 176/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.4006 - acc: 0.8452 - val_loss: 0.4488 - val_acc: 0.7308\n",
      "Epoch 177/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.3952 - acc: 0.8710 - val_loss: 0.4478 - val_acc: 0.7308\n",
      "Epoch 178/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.4082 - acc: 0.8323 - val_loss: 0.4468 - val_acc: 0.7308\n",
      "Epoch 179/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.4149 - acc: 0.8645 - val_loss: 0.4461 - val_acc: 0.7308\n",
      "Epoch 180/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.4084 - acc: 0.8258 - val_loss: 0.4456 - val_acc: 0.7500\n",
      "Epoch 181/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.4043 - acc: 0.8387 - val_loss: 0.4452 - val_acc: 0.7500\n",
      "Epoch 182/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.3973 - acc: 0.8645 - val_loss: 0.4449 - val_acc: 0.7500\n",
      "Epoch 183/500\n",
      "155/155 [==============================] - 0s 82us/step - loss: 0.4044 - acc: 0.8581 - val_loss: 0.4444 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.3995 - acc: 0.8452 - val_loss: 0.4441 - val_acc: 0.7500\n",
      "Epoch 185/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.3872 - acc: 0.8452 - val_loss: 0.4439 - val_acc: 0.7500\n",
      "Epoch 186/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.3846 - acc: 0.8387 - val_loss: 0.4437 - val_acc: 0.7500\n",
      "Epoch 187/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.3822 - acc: 0.8581 - val_loss: 0.4438 - val_acc: 0.7500\n",
      "Epoch 188/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.3861 - acc: 0.8645 - val_loss: 0.4439 - val_acc: 0.7500\n",
      "Epoch 189/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.4030 - acc: 0.8581 - val_loss: 0.4439 - val_acc: 0.7500\n",
      "Epoch 190/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.3942 - acc: 0.8710 - val_loss: 0.4439 - val_acc: 0.7500\n",
      "Epoch 191/500\n",
      "155/155 [==============================] - 0s 60us/step - loss: 0.3889 - acc: 0.8387 - val_loss: 0.4439 - val_acc: 0.7500\n",
      "Epoch 192/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.3955 - acc: 0.8452 - val_loss: 0.4439 - val_acc: 0.7500\n",
      "Epoch 193/500\n",
      "155/155 [==============================] - 0s 112us/step - loss: 0.3864 - acc: 0.8710 - val_loss: 0.4437 - val_acc: 0.7500\n",
      "Epoch 194/500\n",
      "155/155 [==============================] - 0s 132us/step - loss: 0.3858 - acc: 0.8645 - val_loss: 0.4436 - val_acc: 0.7500\n",
      "Epoch 195/500\n",
      "155/155 [==============================] - 0s 93us/step - loss: 0.3907 - acc: 0.8710 - val_loss: 0.4430 - val_acc: 0.7692\n",
      "Epoch 196/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.4082 - acc: 0.8323 - val_loss: 0.4418 - val_acc: 0.7500\n",
      "Epoch 197/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.3680 - acc: 0.8645 - val_loss: 0.4404 - val_acc: 0.7500\n",
      "Epoch 198/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.3813 - acc: 0.8774 - val_loss: 0.4392 - val_acc: 0.7500\n",
      "Epoch 199/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.3932 - acc: 0.8645 - val_loss: 0.4386 - val_acc: 0.7500\n",
      "Epoch 200/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.3775 - acc: 0.8774 - val_loss: 0.4380 - val_acc: 0.7500\n",
      "Epoch 201/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.3913 - acc: 0.8839 - val_loss: 0.4377 - val_acc: 0.7500\n",
      "Epoch 202/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.3566 - acc: 0.8645 - val_loss: 0.4374 - val_acc: 0.7500\n",
      "Epoch 203/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.3536 - acc: 0.8903 - val_loss: 0.4370 - val_acc: 0.7500\n",
      "Epoch 204/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.3726 - acc: 0.8839 - val_loss: 0.4366 - val_acc: 0.7500\n",
      "Epoch 205/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.3830 - acc: 0.8516 - val_loss: 0.4365 - val_acc: 0.7500\n",
      "Epoch 206/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.3787 - acc: 0.8129 - val_loss: 0.4359 - val_acc: 0.7500\n",
      "Epoch 207/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.3763 - acc: 0.8903 - val_loss: 0.4355 - val_acc: 0.7500\n",
      "Epoch 208/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.3767 - acc: 0.8581 - val_loss: 0.4354 - val_acc: 0.7500\n",
      "Epoch 209/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.3669 - acc: 0.8645 - val_loss: 0.4349 - val_acc: 0.7500\n",
      "Epoch 210/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.3539 - acc: 0.8774 - val_loss: 0.4348 - val_acc: 0.7500\n",
      "Epoch 211/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.3800 - acc: 0.8452 - val_loss: 0.4346 - val_acc: 0.7500\n",
      "Epoch 212/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.3807 - acc: 0.8710 - val_loss: 0.4346 - val_acc: 0.7500\n",
      "Epoch 213/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.3597 - acc: 0.8710 - val_loss: 0.4344 - val_acc: 0.7500\n",
      "Epoch 214/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.3642 - acc: 0.8516 - val_loss: 0.4344 - val_acc: 0.7500\n",
      "Epoch 215/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.3678 - acc: 0.8774 - val_loss: 0.4345 - val_acc: 0.7500\n",
      "Epoch 216/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.3686 - acc: 0.8645 - val_loss: 0.4349 - val_acc: 0.7500\n",
      "Epoch 217/500\n",
      "155/155 [==============================] - 0s 61us/step - loss: 0.3820 - acc: 0.8452 - val_loss: 0.4352 - val_acc: 0.7500\n",
      "Epoch 218/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.3817 - acc: 0.8581 - val_loss: 0.4353 - val_acc: 0.7500\n",
      "Epoch 219/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.3785 - acc: 0.8452 - val_loss: 0.4351 - val_acc: 0.7500\n",
      "Epoch 220/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.3659 - acc: 0.8903 - val_loss: 0.4348 - val_acc: 0.7500\n",
      "Epoch 221/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.3636 - acc: 0.8581 - val_loss: 0.4344 - val_acc: 0.7500\n",
      "Epoch 222/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.3692 - acc: 0.8839 - val_loss: 0.4340 - val_acc: 0.7500\n",
      "Epoch 223/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.3552 - acc: 0.8774 - val_loss: 0.4337 - val_acc: 0.7500\n",
      "Epoch 224/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.3604 - acc: 0.8839 - val_loss: 0.4337 - val_acc: 0.7500\n",
      "Epoch 225/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.3701 - acc: 0.8516 - val_loss: 0.4336 - val_acc: 0.7500\n",
      "Epoch 226/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.3600 - acc: 0.9032 - val_loss: 0.4338 - val_acc: 0.7500\n",
      "Epoch 227/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.3440 - acc: 0.9161 - val_loss: 0.4341 - val_acc: 0.7500\n",
      "Epoch 228/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.3554 - acc: 0.8710 - val_loss: 0.4344 - val_acc: 0.7500\n",
      "Epoch 229/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.3601 - acc: 0.8516 - val_loss: 0.4350 - val_acc: 0.7500\n",
      "Epoch 230/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.3747 - acc: 0.8581 - val_loss: 0.4356 - val_acc: 0.7692\n",
      "Epoch 231/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.3499 - acc: 0.8839 - val_loss: 0.4352 - val_acc: 0.7500\n",
      "Epoch 232/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.3543 - acc: 0.8903 - val_loss: 0.4343 - val_acc: 0.7500\n",
      "Epoch 233/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.3547 - acc: 0.8710 - val_loss: 0.4337 - val_acc: 0.7500\n",
      "Epoch 234/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.3503 - acc: 0.8645 - val_loss: 0.4330 - val_acc: 0.7500\n",
      "Epoch 235/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.3359 - acc: 0.8903 - val_loss: 0.4323 - val_acc: 0.7500\n",
      "Epoch 236/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.3436 - acc: 0.9032 - val_loss: 0.4317 - val_acc: 0.7500\n",
      "Epoch 237/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.3525 - acc: 0.8839 - val_loss: 0.4310 - val_acc: 0.7500\n",
      "Epoch 238/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.3691 - acc: 0.8645 - val_loss: 0.4301 - val_acc: 0.7500\n",
      "Epoch 239/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.3549 - acc: 0.8516 - val_loss: 0.4293 - val_acc: 0.7500\n",
      "Epoch 240/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.3317 - acc: 0.8968 - val_loss: 0.4287 - val_acc: 0.7500\n",
      "Epoch 241/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.3551 - acc: 0.8645 - val_loss: 0.4280 - val_acc: 0.7500\n",
      "Epoch 242/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.3331 - acc: 0.8710 - val_loss: 0.4273 - val_acc: 0.7500\n",
      "Epoch 243/500\n",
      "155/155 [==============================] - 0s 81us/step - loss: 0.3533 - acc: 0.8581 - val_loss: 0.4267 - val_acc: 0.7500\n",
      "Epoch 244/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.3479 - acc: 0.8645 - val_loss: 0.4258 - val_acc: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.3623 - acc: 0.8645 - val_loss: 0.4250 - val_acc: 0.7500\n",
      "Epoch 246/500\n",
      "155/155 [==============================] - 0s 103us/step - loss: 0.3400 - acc: 0.8839 - val_loss: 0.4246 - val_acc: 0.7500\n",
      "Epoch 247/500\n",
      "155/155 [==============================] - 0s 129us/step - loss: 0.3388 - acc: 0.8710 - val_loss: 0.4240 - val_acc: 0.7500\n",
      "Epoch 248/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.3362 - acc: 0.8903 - val_loss: 0.4241 - val_acc: 0.7500\n",
      "Epoch 249/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.3479 - acc: 0.8581 - val_loss: 0.4240 - val_acc: 0.7500\n",
      "Epoch 250/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.3422 - acc: 0.8839 - val_loss: 0.4238 - val_acc: 0.7500\n",
      "Epoch 251/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.3570 - acc: 0.8516 - val_loss: 0.4241 - val_acc: 0.7500\n",
      "Epoch 252/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.3420 - acc: 0.9032 - val_loss: 0.4245 - val_acc: 0.7500\n",
      "Epoch 253/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.3372 - acc: 0.8645 - val_loss: 0.4247 - val_acc: 0.7885\n",
      "Epoch 254/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.3391 - acc: 0.9032 - val_loss: 0.4246 - val_acc: 0.7885\n",
      "Epoch 255/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.3505 - acc: 0.8452 - val_loss: 0.4247 - val_acc: 0.7885\n",
      "Epoch 256/500\n",
      "155/155 [==============================] - 0s 90us/step - loss: 0.3415 - acc: 0.8839 - val_loss: 0.4244 - val_acc: 0.7885\n",
      "Epoch 257/500\n",
      "155/155 [==============================] - 0s 94us/step - loss: 0.3320 - acc: 0.8645 - val_loss: 0.4242 - val_acc: 0.7885\n",
      "Epoch 258/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.3400 - acc: 0.8968 - val_loss: 0.4240 - val_acc: 0.7692\n",
      "Epoch 259/500\n",
      "155/155 [==============================] - 0s 86us/step - loss: 0.3328 - acc: 0.8839 - val_loss: 0.4235 - val_acc: 0.7692\n",
      "Epoch 260/500\n",
      "155/155 [==============================] - 0s 89us/step - loss: 0.3161 - acc: 0.9032 - val_loss: 0.4231 - val_acc: 0.7500\n",
      "Epoch 261/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.3595 - acc: 0.8581 - val_loss: 0.4224 - val_acc: 0.7500\n",
      "Epoch 262/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.3283 - acc: 0.8839 - val_loss: 0.4220 - val_acc: 0.7500\n",
      "Epoch 263/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.3413 - acc: 0.8645 - val_loss: 0.4216 - val_acc: 0.7500\n",
      "Epoch 264/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.3301 - acc: 0.8968 - val_loss: 0.4214 - val_acc: 0.7692\n",
      "Epoch 265/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.3339 - acc: 0.8645 - val_loss: 0.4209 - val_acc: 0.7692\n",
      "Epoch 266/500\n",
      "155/155 [==============================] - 0s 101us/step - loss: 0.3253 - acc: 0.8968 - val_loss: 0.4206 - val_acc: 0.7692\n",
      "Epoch 267/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.3395 - acc: 0.8710 - val_loss: 0.4206 - val_acc: 0.7692\n",
      "Epoch 268/500\n",
      "155/155 [==============================] - 0s 61us/step - loss: 0.3448 - acc: 0.8516 - val_loss: 0.4209 - val_acc: 0.7692\n",
      "Epoch 269/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.3370 - acc: 0.8903 - val_loss: 0.4208 - val_acc: 0.7692\n",
      "Epoch 270/500\n",
      "155/155 [==============================] - 0s 87us/step - loss: 0.3302 - acc: 0.8452 - val_loss: 0.4211 - val_acc: 0.7692\n",
      "Epoch 271/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.3403 - acc: 0.8968 - val_loss: 0.4212 - val_acc: 0.7692\n",
      "Epoch 272/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.3242 - acc: 0.8903 - val_loss: 0.4216 - val_acc: 0.7692\n",
      "Epoch 273/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.3368 - acc: 0.8645 - val_loss: 0.4222 - val_acc: 0.7692\n",
      "Epoch 274/500\n",
      "155/155 [==============================] - 0s 122us/step - loss: 0.3363 - acc: 0.8839 - val_loss: 0.4224 - val_acc: 0.7885\n",
      "Epoch 275/500\n",
      "155/155 [==============================] - 0s 88us/step - loss: 0.3359 - acc: 0.8710 - val_loss: 0.4224 - val_acc: 0.8077\n",
      "Epoch 276/500\n",
      "155/155 [==============================] - 0s 84us/step - loss: 0.3471 - acc: 0.8645 - val_loss: 0.4219 - val_acc: 0.8077\n",
      "Epoch 277/500\n",
      "155/155 [==============================] - 0s 83us/step - loss: 0.3133 - acc: 0.8903 - val_loss: 0.4214 - val_acc: 0.8077\n",
      "Epoch 278/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.3201 - acc: 0.8774 - val_loss: 0.4203 - val_acc: 0.8077\n",
      "Epoch 279/500\n",
      "155/155 [==============================] - 0s 86us/step - loss: 0.3298 - acc: 0.8645 - val_loss: 0.4185 - val_acc: 0.7885\n",
      "Epoch 280/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.3103 - acc: 0.8710 - val_loss: 0.4171 - val_acc: 0.7885\n",
      "Epoch 281/500\n",
      "155/155 [==============================] - 0s 93us/step - loss: 0.3131 - acc: 0.8968 - val_loss: 0.4162 - val_acc: 0.8077\n",
      "Epoch 282/500\n",
      "155/155 [==============================] - 0s 95us/step - loss: 0.3158 - acc: 0.9161 - val_loss: 0.4151 - val_acc: 0.8269\n",
      "Epoch 283/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.3250 - acc: 0.9097 - val_loss: 0.4143 - val_acc: 0.8269\n",
      "Epoch 284/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.3380 - acc: 0.8581 - val_loss: 0.4139 - val_acc: 0.8269\n",
      "Epoch 285/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.3248 - acc: 0.8839 - val_loss: 0.4138 - val_acc: 0.8077\n",
      "Epoch 286/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.3103 - acc: 0.9097 - val_loss: 0.4139 - val_acc: 0.8077\n",
      "Epoch 287/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.3318 - acc: 0.8839 - val_loss: 0.4143 - val_acc: 0.8077\n",
      "Epoch 288/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.3224 - acc: 0.8903 - val_loss: 0.4145 - val_acc: 0.8077\n",
      "Epoch 289/500\n",
      "155/155 [==============================] - 0s 95us/step - loss: 0.3085 - acc: 0.8903 - val_loss: 0.4142 - val_acc: 0.8077\n",
      "Epoch 290/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.3149 - acc: 0.8903 - val_loss: 0.4141 - val_acc: 0.8077\n",
      "Epoch 291/500\n",
      "155/155 [==============================] - 0s 81us/step - loss: 0.3205 - acc: 0.8839 - val_loss: 0.4135 - val_acc: 0.8077\n",
      "Epoch 292/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.3292 - acc: 0.8774 - val_loss: 0.4130 - val_acc: 0.8269\n",
      "Epoch 293/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.3096 - acc: 0.8968 - val_loss: 0.4124 - val_acc: 0.8269\n",
      "Epoch 294/500\n",
      "155/155 [==============================] - 0s 82us/step - loss: 0.3250 - acc: 0.8968 - val_loss: 0.4119 - val_acc: 0.8269\n",
      "Epoch 295/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.3119 - acc: 0.8903 - val_loss: 0.4119 - val_acc: 0.8269\n",
      "Epoch 296/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.3148 - acc: 0.8839 - val_loss: 0.4123 - val_acc: 0.8269\n",
      "Epoch 297/500\n",
      "155/155 [==============================] - 0s 93us/step - loss: 0.3044 - acc: 0.8903 - val_loss: 0.4131 - val_acc: 0.8269\n",
      "Epoch 298/500\n",
      "155/155 [==============================] - 0s 99us/step - loss: 0.3071 - acc: 0.9032 - val_loss: 0.4144 - val_acc: 0.8077\n",
      "Epoch 299/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.3160 - acc: 0.8774 - val_loss: 0.4160 - val_acc: 0.8269\n",
      "Epoch 300/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.3080 - acc: 0.8774 - val_loss: 0.4172 - val_acc: 0.8269\n",
      "Epoch 301/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.3363 - acc: 0.8968 - val_loss: 0.4181 - val_acc: 0.8269\n",
      "Epoch 302/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.3238 - acc: 0.8645 - val_loss: 0.4187 - val_acc: 0.8269\n",
      "Epoch 303/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.3159 - acc: 0.8774 - val_loss: 0.4192 - val_acc: 0.8269\n",
      "Epoch 304/500\n",
      "155/155 [==============================] - 0s 95us/step - loss: 0.2982 - acc: 0.9032 - val_loss: 0.4186 - val_acc: 0.8269\n",
      "Epoch 305/500\n",
      "155/155 [==============================] - 0s 94us/step - loss: 0.2780 - acc: 0.9032 - val_loss: 0.4176 - val_acc: 0.8269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/500\n",
      "155/155 [==============================] - 0s 81us/step - loss: 0.2946 - acc: 0.8968 - val_loss: 0.4161 - val_acc: 0.8269\n",
      "Epoch 307/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.3009 - acc: 0.8839 - val_loss: 0.4146 - val_acc: 0.8269\n",
      "Epoch 308/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.2817 - acc: 0.9161 - val_loss: 0.4137 - val_acc: 0.8269\n",
      "Epoch 309/500\n",
      "155/155 [==============================] - 0s 93us/step - loss: 0.3198 - acc: 0.8516 - val_loss: 0.4133 - val_acc: 0.8269\n",
      "Epoch 310/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.3032 - acc: 0.9097 - val_loss: 0.4136 - val_acc: 0.8269\n",
      "Epoch 311/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.3073 - acc: 0.8968 - val_loss: 0.4144 - val_acc: 0.8269\n",
      "Epoch 312/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.3185 - acc: 0.8710 - val_loss: 0.4148 - val_acc: 0.8269\n",
      "Epoch 313/500\n",
      "155/155 [==============================] - 0s 91us/step - loss: 0.2987 - acc: 0.8968 - val_loss: 0.4155 - val_acc: 0.8077\n",
      "Epoch 314/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.3113 - acc: 0.8774 - val_loss: 0.4158 - val_acc: 0.8077\n",
      "Epoch 315/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.3115 - acc: 0.9032 - val_loss: 0.4163 - val_acc: 0.8077\n",
      "Epoch 316/500\n",
      "155/155 [==============================] - 0s 82us/step - loss: 0.3022 - acc: 0.8710 - val_loss: 0.4174 - val_acc: 0.8269\n",
      "Epoch 317/500\n",
      "155/155 [==============================] - 0s 117us/step - loss: 0.2931 - acc: 0.8968 - val_loss: 0.4182 - val_acc: 0.8269\n",
      "Epoch 318/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.2995 - acc: 0.8903 - val_loss: 0.4186 - val_acc: 0.8269\n",
      "Epoch 319/500\n",
      "155/155 [==============================] - 0s 86us/step - loss: 0.2993 - acc: 0.8839 - val_loss: 0.4183 - val_acc: 0.8269\n",
      "Epoch 320/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.2941 - acc: 0.8968 - val_loss: 0.4180 - val_acc: 0.8269\n",
      "Epoch 321/500\n",
      "155/155 [==============================] - 0s 91us/step - loss: 0.2948 - acc: 0.9032 - val_loss: 0.4168 - val_acc: 0.8269\n",
      "Epoch 322/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.3150 - acc: 0.8903 - val_loss: 0.4152 - val_acc: 0.8269\n",
      "Epoch 323/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.3022 - acc: 0.8968 - val_loss: 0.4141 - val_acc: 0.8269\n",
      "Epoch 324/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.2877 - acc: 0.9226 - val_loss: 0.4132 - val_acc: 0.8077\n",
      "Epoch 325/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.2896 - acc: 0.9226 - val_loss: 0.4125 - val_acc: 0.8269\n",
      "Epoch 326/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.3031 - acc: 0.9032 - val_loss: 0.4124 - val_acc: 0.8269\n",
      "Epoch 327/500\n",
      "155/155 [==============================] - 0s 57us/step - loss: 0.2765 - acc: 0.9032 - val_loss: 0.4126 - val_acc: 0.8269\n",
      "Epoch 328/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.2981 - acc: 0.8645 - val_loss: 0.4125 - val_acc: 0.8269\n",
      "Epoch 329/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.2986 - acc: 0.8839 - val_loss: 0.4124 - val_acc: 0.8269\n",
      "Epoch 330/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.3124 - acc: 0.8839 - val_loss: 0.4131 - val_acc: 0.8077\n",
      "Epoch 331/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.2781 - acc: 0.8968 - val_loss: 0.4145 - val_acc: 0.8269\n",
      "Epoch 332/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.2933 - acc: 0.9032 - val_loss: 0.4158 - val_acc: 0.8269\n",
      "Epoch 333/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.2952 - acc: 0.9032 - val_loss: 0.4163 - val_acc: 0.8269\n",
      "Epoch 334/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.3038 - acc: 0.8903 - val_loss: 0.4168 - val_acc: 0.8269\n",
      "Epoch 335/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.2875 - acc: 0.9226 - val_loss: 0.4163 - val_acc: 0.8269\n",
      "Epoch 336/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.3050 - acc: 0.8645 - val_loss: 0.4150 - val_acc: 0.8269\n",
      "Epoch 337/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.2916 - acc: 0.9226 - val_loss: 0.4136 - val_acc: 0.8269\n",
      "Epoch 338/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.2996 - acc: 0.8968 - val_loss: 0.4124 - val_acc: 0.8077\n",
      "Epoch 339/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.2913 - acc: 0.8968 - val_loss: 0.4117 - val_acc: 0.8269\n",
      "Epoch 340/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.2976 - acc: 0.8968 - val_loss: 0.4119 - val_acc: 0.8269\n",
      "Epoch 341/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.2940 - acc: 0.8839 - val_loss: 0.4122 - val_acc: 0.8077\n",
      "Epoch 342/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.2865 - acc: 0.9161 - val_loss: 0.4131 - val_acc: 0.8077\n",
      "Epoch 343/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.2903 - acc: 0.9097 - val_loss: 0.4141 - val_acc: 0.8269\n",
      "Epoch 344/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.2746 - acc: 0.9161 - val_loss: 0.4153 - val_acc: 0.8269\n",
      "Epoch 345/500\n",
      "155/155 [==============================] - 0s 87us/step - loss: 0.2877 - acc: 0.9226 - val_loss: 0.4162 - val_acc: 0.8269\n",
      "Epoch 346/500\n",
      "155/155 [==============================] - 0s 100us/step - loss: 0.2873 - acc: 0.8710 - val_loss: 0.4174 - val_acc: 0.8269\n",
      "Epoch 347/500\n",
      "155/155 [==============================] - 0s 84us/step - loss: 0.2846 - acc: 0.9097 - val_loss: 0.4175 - val_acc: 0.8269\n",
      "Epoch 348/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.2825 - acc: 0.9032 - val_loss: 0.4171 - val_acc: 0.8269\n",
      "Epoch 349/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.2752 - acc: 0.9097 - val_loss: 0.4154 - val_acc: 0.8269\n",
      "Epoch 350/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.2860 - acc: 0.9226 - val_loss: 0.4134 - val_acc: 0.8269\n",
      "Epoch 351/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.2744 - acc: 0.9226 - val_loss: 0.4121 - val_acc: 0.8077\n",
      "Epoch 352/500\n",
      "155/155 [==============================] - 0s 94us/step - loss: 0.2748 - acc: 0.9032 - val_loss: 0.4111 - val_acc: 0.8269\n",
      "Epoch 353/500\n",
      "155/155 [==============================] - 0s 83us/step - loss: 0.3091 - acc: 0.8645 - val_loss: 0.4108 - val_acc: 0.8269\n",
      "Epoch 354/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.2595 - acc: 0.9226 - val_loss: 0.4105 - val_acc: 0.8269\n",
      "Epoch 355/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.2775 - acc: 0.9097 - val_loss: 0.4105 - val_acc: 0.8269\n",
      "Epoch 356/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.2646 - acc: 0.9032 - val_loss: 0.4108 - val_acc: 0.8269\n",
      "Epoch 357/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.2897 - acc: 0.8839 - val_loss: 0.4117 - val_acc: 0.8269\n",
      "Epoch 358/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.2728 - acc: 0.9032 - val_loss: 0.4132 - val_acc: 0.8077\n",
      "Epoch 359/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.2831 - acc: 0.8774 - val_loss: 0.4153 - val_acc: 0.8269\n",
      "Epoch 360/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.2795 - acc: 0.8968 - val_loss: 0.4170 - val_acc: 0.8269\n",
      "Epoch 361/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.2731 - acc: 0.9032 - val_loss: 0.4178 - val_acc: 0.8269\n",
      "Epoch 362/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.2852 - acc: 0.8968 - val_loss: 0.4181 - val_acc: 0.8269\n",
      "Epoch 363/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.2788 - acc: 0.9097 - val_loss: 0.4177 - val_acc: 0.8269\n",
      "Epoch 364/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.2712 - acc: 0.9161 - val_loss: 0.4167 - val_acc: 0.8269\n",
      "Epoch 365/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.2742 - acc: 0.9032 - val_loss: 0.4149 - val_acc: 0.8269\n",
      "Epoch 366/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.2856 - acc: 0.8968 - val_loss: 0.4132 - val_acc: 0.8269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.2784 - acc: 0.8968 - val_loss: 0.4116 - val_acc: 0.8462\n",
      "Epoch 368/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.2629 - acc: 0.9226 - val_loss: 0.4111 - val_acc: 0.8462\n",
      "Epoch 369/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.2875 - acc: 0.8903 - val_loss: 0.4107 - val_acc: 0.8269\n",
      "Epoch 370/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.2835 - acc: 0.9097 - val_loss: 0.4110 - val_acc: 0.8269\n",
      "Epoch 371/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.2824 - acc: 0.8839 - val_loss: 0.4109 - val_acc: 0.8269\n",
      "Epoch 372/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.2681 - acc: 0.9097 - val_loss: 0.4106 - val_acc: 0.8269\n",
      "Epoch 373/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.2771 - acc: 0.8968 - val_loss: 0.4102 - val_acc: 0.8269\n",
      "Epoch 374/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.2687 - acc: 0.9097 - val_loss: 0.4098 - val_acc: 0.8269\n",
      "Epoch 375/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.2935 - acc: 0.8774 - val_loss: 0.4095 - val_acc: 0.8269\n",
      "Epoch 376/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.2883 - acc: 0.8839 - val_loss: 0.4100 - val_acc: 0.8269\n",
      "Epoch 377/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.2705 - acc: 0.9097 - val_loss: 0.4111 - val_acc: 0.8077\n",
      "Epoch 378/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.2639 - acc: 0.9161 - val_loss: 0.4118 - val_acc: 0.8269\n",
      "Epoch 379/500\n",
      "155/155 [==============================] - 0s 61us/step - loss: 0.2571 - acc: 0.9290 - val_loss: 0.4125 - val_acc: 0.8269\n",
      "Epoch 380/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.2802 - acc: 0.8903 - val_loss: 0.4131 - val_acc: 0.8269\n",
      "Epoch 381/500\n",
      "155/155 [==============================] - 0s 56us/step - loss: 0.2743 - acc: 0.9161 - val_loss: 0.4141 - val_acc: 0.8269\n",
      "Epoch 382/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.2677 - acc: 0.8903 - val_loss: 0.4148 - val_acc: 0.8269\n",
      "Epoch 383/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.2805 - acc: 0.8903 - val_loss: 0.4146 - val_acc: 0.8269\n",
      "Epoch 384/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.2651 - acc: 0.8968 - val_loss: 0.4137 - val_acc: 0.8269\n",
      "Epoch 385/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.2617 - acc: 0.9097 - val_loss: 0.4122 - val_acc: 0.8269\n",
      "Epoch 386/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.2655 - acc: 0.8968 - val_loss: 0.4112 - val_acc: 0.8269\n",
      "Epoch 387/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.2595 - acc: 0.9097 - val_loss: 0.4101 - val_acc: 0.8269\n",
      "Epoch 388/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.2691 - acc: 0.9032 - val_loss: 0.4097 - val_acc: 0.8269\n",
      "Epoch 389/500\n",
      "155/155 [==============================] - 0s 61us/step - loss: 0.2610 - acc: 0.9032 - val_loss: 0.4097 - val_acc: 0.8269\n",
      "Epoch 390/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.2605 - acc: 0.9032 - val_loss: 0.4103 - val_acc: 0.8269\n",
      "Epoch 391/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.2467 - acc: 0.9097 - val_loss: 0.4112 - val_acc: 0.8462\n",
      "Epoch 392/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.2533 - acc: 0.9226 - val_loss: 0.4118 - val_acc: 0.8462\n",
      "Epoch 393/500\n",
      "155/155 [==============================] - 0s 99us/step - loss: 0.2783 - acc: 0.8903 - val_loss: 0.4122 - val_acc: 0.8462\n",
      "Epoch 394/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.2673 - acc: 0.9032 - val_loss: 0.4125 - val_acc: 0.8269\n",
      "Epoch 395/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.2753 - acc: 0.8903 - val_loss: 0.4122 - val_acc: 0.8462\n",
      "Epoch 396/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.2686 - acc: 0.9097 - val_loss: 0.4120 - val_acc: 0.8462\n",
      "Epoch 397/500\n",
      "155/155 [==============================] - 0s 92us/step - loss: 0.2604 - acc: 0.8839 - val_loss: 0.4112 - val_acc: 0.8462\n",
      "Epoch 398/500\n",
      "155/155 [==============================] - 0s 80us/step - loss: 0.2658 - acc: 0.9097 - val_loss: 0.4102 - val_acc: 0.8269\n",
      "Epoch 399/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.2520 - acc: 0.9161 - val_loss: 0.4090 - val_acc: 0.8269\n",
      "Epoch 400/500\n",
      "155/155 [==============================] - 0s 387us/step - loss: 0.2376 - acc: 0.9097 - val_loss: 0.4080 - val_acc: 0.8269\n",
      "Epoch 401/500\n",
      "155/155 [==============================] - 0s 294us/step - loss: 0.2538 - acc: 0.9097 - val_loss: 0.4072 - val_acc: 0.8269\n",
      "Epoch 402/500\n",
      "155/155 [==============================] - 0s 166us/step - loss: 0.2508 - acc: 0.9161 - val_loss: 0.4070 - val_acc: 0.8269\n",
      "Epoch 403/500\n",
      "155/155 [==============================] - 0s 329us/step - loss: 0.2698 - acc: 0.9032 - val_loss: 0.4076 - val_acc: 0.8269\n",
      "Epoch 404/500\n",
      "155/155 [==============================] - 0s 302us/step - loss: 0.2500 - acc: 0.9097 - val_loss: 0.4081 - val_acc: 0.8462\n",
      "Epoch 405/500\n",
      "155/155 [==============================] - 0s 356us/step - loss: 0.2450 - acc: 0.9226 - val_loss: 0.4092 - val_acc: 0.8462\n",
      "Epoch 406/500\n",
      "155/155 [==============================] - 0s 364us/step - loss: 0.2514 - acc: 0.9032 - val_loss: 0.4104 - val_acc: 0.8269\n",
      "Epoch 407/500\n",
      "155/155 [==============================] - 0s 341us/step - loss: 0.2349 - acc: 0.9484 - val_loss: 0.4113 - val_acc: 0.8269\n",
      "Epoch 408/500\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.2714 - acc: 0.9161 - val_loss: 0.4117 - val_acc: 0.8269\n",
      "Epoch 409/500\n",
      "155/155 [==============================] - 0s 306us/step - loss: 0.2547 - acc: 0.9032 - val_loss: 0.4117 - val_acc: 0.8269\n",
      "Epoch 410/500\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2725 - acc: 0.8903 - val_loss: 0.4115 - val_acc: 0.8269\n",
      "Epoch 411/500\n",
      "155/155 [==============================] - 0s 135us/step - loss: 0.2500 - acc: 0.9097 - val_loss: 0.4116 - val_acc: 0.8269\n",
      "Epoch 412/500\n",
      "155/155 [==============================] - 0s 125us/step - loss: 0.2639 - acc: 0.9097 - val_loss: 0.4114 - val_acc: 0.8269\n",
      "Epoch 413/500\n",
      "155/155 [==============================] - 0s 83us/step - loss: 0.2551 - acc: 0.8968 - val_loss: 0.4116 - val_acc: 0.8269\n",
      "Epoch 414/500\n",
      "155/155 [==============================] - 0s 116us/step - loss: 0.2710 - acc: 0.9161 - val_loss: 0.4117 - val_acc: 0.8269\n",
      "Epoch 415/500\n",
      "155/155 [==============================] - 0s 102us/step - loss: 0.2507 - acc: 0.9161 - val_loss: 0.4114 - val_acc: 0.8269\n",
      "Epoch 416/500\n",
      "155/155 [==============================] - 0s 135us/step - loss: 0.2627 - acc: 0.9161 - val_loss: 0.4110 - val_acc: 0.8269\n",
      "Epoch 417/500\n",
      "155/155 [==============================] - 0s 119us/step - loss: 0.2523 - acc: 0.9032 - val_loss: 0.4113 - val_acc: 0.8269\n",
      "Epoch 418/500\n",
      "155/155 [==============================] - 0s 94us/step - loss: 0.2555 - acc: 0.8968 - val_loss: 0.4117 - val_acc: 0.8462\n",
      "Epoch 419/500\n",
      "155/155 [==============================] - 0s 131us/step - loss: 0.2494 - acc: 0.9161 - val_loss: 0.4111 - val_acc: 0.8462\n",
      "Epoch 420/500\n",
      "155/155 [==============================] - 0s 164us/step - loss: 0.2686 - acc: 0.8903 - val_loss: 0.4107 - val_acc: 0.8462\n",
      "Epoch 421/500\n",
      "155/155 [==============================] - 0s 107us/step - loss: 0.2568 - acc: 0.9161 - val_loss: 0.4101 - val_acc: 0.8462\n",
      "Epoch 422/500\n",
      "155/155 [==============================] - 0s 105us/step - loss: 0.2354 - acc: 0.9161 - val_loss: 0.4091 - val_acc: 0.8462\n",
      "Epoch 423/500\n",
      "155/155 [==============================] - 0s 134us/step - loss: 0.2549 - acc: 0.8903 - val_loss: 0.4086 - val_acc: 0.8462\n",
      "Epoch 424/500\n",
      "155/155 [==============================] - 0s 121us/step - loss: 0.2475 - acc: 0.9097 - val_loss: 0.4081 - val_acc: 0.8462\n",
      "Epoch 425/500\n",
      "155/155 [==============================] - 0s 167us/step - loss: 0.2494 - acc: 0.9290 - val_loss: 0.4081 - val_acc: 0.8462\n",
      "Epoch 426/500\n",
      "155/155 [==============================] - 0s 101us/step - loss: 0.2631 - acc: 0.9161 - val_loss: 0.4077 - val_acc: 0.8462\n",
      "Epoch 427/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 139us/step - loss: 0.2543 - acc: 0.9097 - val_loss: 0.4073 - val_acc: 0.8269\n",
      "Epoch 428/500\n",
      "155/155 [==============================] - 0s 208us/step - loss: 0.2504 - acc: 0.9097 - val_loss: 0.4076 - val_acc: 0.8462\n",
      "Epoch 429/500\n",
      "155/155 [==============================] - 0s 185us/step - loss: 0.2570 - acc: 0.9161 - val_loss: 0.4077 - val_acc: 0.8462\n",
      "Epoch 430/500\n",
      "155/155 [==============================] - 0s 134us/step - loss: 0.2492 - acc: 0.9097 - val_loss: 0.4076 - val_acc: 0.8462\n",
      "Epoch 431/500\n",
      "155/155 [==============================] - 0s 95us/step - loss: 0.2384 - acc: 0.9161 - val_loss: 0.4076 - val_acc: 0.8462\n",
      "Epoch 432/500\n",
      "155/155 [==============================] - 0s 107us/step - loss: 0.2403 - acc: 0.9097 - val_loss: 0.4076 - val_acc: 0.8269\n",
      "Epoch 433/500\n",
      "155/155 [==============================] - 0s 136us/step - loss: 0.2679 - acc: 0.9032 - val_loss: 0.4076 - val_acc: 0.8269\n",
      "Epoch 434/500\n",
      "155/155 [==============================] - 0s 150us/step - loss: 0.2517 - acc: 0.9161 - val_loss: 0.4079 - val_acc: 0.8269\n",
      "Epoch 435/500\n",
      "155/155 [==============================] - 0s 98us/step - loss: 0.2468 - acc: 0.9290 - val_loss: 0.4082 - val_acc: 0.8269\n",
      "Epoch 436/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.2379 - acc: 0.9355 - val_loss: 0.4088 - val_acc: 0.8269\n",
      "Epoch 437/500\n",
      "155/155 [==============================] - 0s 92us/step - loss: 0.2380 - acc: 0.9226 - val_loss: 0.4098 - val_acc: 0.8269\n",
      "Epoch 438/500\n",
      "155/155 [==============================] - 0s 84us/step - loss: 0.2491 - acc: 0.9097 - val_loss: 0.4109 - val_acc: 0.8462\n",
      "Epoch 439/500\n",
      "155/155 [==============================] - 0s 84us/step - loss: 0.2411 - acc: 0.9226 - val_loss: 0.4125 - val_acc: 0.8462\n",
      "Epoch 440/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.2385 - acc: 0.9290 - val_loss: 0.4144 - val_acc: 0.8269\n",
      "Epoch 441/500\n",
      "155/155 [==============================] - 0s 125us/step - loss: 0.2413 - acc: 0.9097 - val_loss: 0.4152 - val_acc: 0.8269\n",
      "Epoch 442/500\n",
      "155/155 [==============================] - 0s 116us/step - loss: 0.2534 - acc: 0.9226 - val_loss: 0.4152 - val_acc: 0.8269\n",
      "Epoch 443/500\n",
      "155/155 [==============================] - 0s 86us/step - loss: 0.2534 - acc: 0.9032 - val_loss: 0.4138 - val_acc: 0.8269\n",
      "Epoch 444/500\n",
      "155/155 [==============================] - 0s 125us/step - loss: 0.2372 - acc: 0.9097 - val_loss: 0.4116 - val_acc: 0.8462\n",
      "Epoch 445/500\n",
      "155/155 [==============================] - 0s 85us/step - loss: 0.2364 - acc: 0.9355 - val_loss: 0.4101 - val_acc: 0.8269\n",
      "Epoch 446/500\n",
      "155/155 [==============================] - 0s 106us/step - loss: 0.2596 - acc: 0.9226 - val_loss: 0.4092 - val_acc: 0.8269\n",
      "Epoch 447/500\n",
      "155/155 [==============================] - 0s 103us/step - loss: 0.2618 - acc: 0.8903 - val_loss: 0.4083 - val_acc: 0.8269\n",
      "Epoch 448/500\n",
      "155/155 [==============================] - 0s 91us/step - loss: 0.2394 - acc: 0.9226 - val_loss: 0.4076 - val_acc: 0.8269\n",
      "Epoch 449/500\n",
      "155/155 [==============================] - 0s 86us/step - loss: 0.2201 - acc: 0.9032 - val_loss: 0.4073 - val_acc: 0.8269\n",
      "Epoch 450/500\n",
      "155/155 [==============================] - 0s 97us/step - loss: 0.2387 - acc: 0.9290 - val_loss: 0.4073 - val_acc: 0.8269\n",
      "Epoch 451/500\n",
      "155/155 [==============================] - 0s 143us/step - loss: 0.2610 - acc: 0.9032 - val_loss: 0.4076 - val_acc: 0.8269\n",
      "Epoch 452/500\n",
      "155/155 [==============================] - 0s 146us/step - loss: 0.2521 - acc: 0.9226 - val_loss: 0.4087 - val_acc: 0.8269\n",
      "Epoch 453/500\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.2470 - acc: 0.8903 - val_loss: 0.4099 - val_acc: 0.8462\n",
      "Epoch 454/500\n",
      "155/155 [==============================] - 0s 138us/step - loss: 0.2436 - acc: 0.9032 - val_loss: 0.4110 - val_acc: 0.8462\n",
      "Epoch 455/500\n",
      "155/155 [==============================] - 0s 122us/step - loss: 0.2432 - acc: 0.9097 - val_loss: 0.4120 - val_acc: 0.8462\n",
      "Epoch 456/500\n",
      "155/155 [==============================] - 0s 105us/step - loss: 0.2266 - acc: 0.9290 - val_loss: 0.4123 - val_acc: 0.8462\n",
      "Epoch 457/500\n",
      "155/155 [==============================] - 0s 187us/step - loss: 0.2296 - acc: 0.9161 - val_loss: 0.4122 - val_acc: 0.8462\n",
      "Epoch 458/500\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.2338 - acc: 0.9032 - val_loss: 0.4123 - val_acc: 0.8462\n",
      "Epoch 459/500\n",
      "155/155 [==============================] - 0s 195us/step - loss: 0.2400 - acc: 0.9161 - val_loss: 0.4125 - val_acc: 0.8462\n",
      "Epoch 460/500\n",
      "155/155 [==============================] - 0s 140us/step - loss: 0.2401 - acc: 0.9226 - val_loss: 0.4128 - val_acc: 0.8462\n",
      "Epoch 461/500\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.2405 - acc: 0.9097 - val_loss: 0.4125 - val_acc: 0.8269\n",
      "Epoch 462/500\n",
      "155/155 [==============================] - 0s 250us/step - loss: 0.2427 - acc: 0.9032 - val_loss: 0.4127 - val_acc: 0.8269\n",
      "Epoch 463/500\n",
      "155/155 [==============================] - 0s 243us/step - loss: 0.2450 - acc: 0.9161 - val_loss: 0.4121 - val_acc: 0.8269\n",
      "Epoch 464/500\n",
      "155/155 [==============================] - 0s 353us/step - loss: 0.2313 - acc: 0.9161 - val_loss: 0.4122 - val_acc: 0.8269\n",
      "Epoch 465/500\n",
      "155/155 [==============================] - 0s 195us/step - loss: 0.2261 - acc: 0.9355 - val_loss: 0.4122 - val_acc: 0.8269\n",
      "Epoch 466/500\n",
      "155/155 [==============================] - 0s 226us/step - loss: 0.2275 - acc: 0.9290 - val_loss: 0.4125 - val_acc: 0.8269\n",
      "Epoch 467/500\n",
      "155/155 [==============================] - 0s 138us/step - loss: 0.2433 - acc: 0.9161 - val_loss: 0.4129 - val_acc: 0.8269\n",
      "Epoch 468/500\n",
      "155/155 [==============================] - 0s 151us/step - loss: 0.2328 - acc: 0.9161 - val_loss: 0.4135 - val_acc: 0.8269\n",
      "Epoch 469/500\n",
      "155/155 [==============================] - 0s 83us/step - loss: 0.2491 - acc: 0.9097 - val_loss: 0.4143 - val_acc: 0.8462\n",
      "Epoch 470/500\n",
      "155/155 [==============================] - 0s 106us/step - loss: 0.2150 - acc: 0.9226 - val_loss: 0.4157 - val_acc: 0.8462\n",
      "Epoch 471/500\n",
      "155/155 [==============================] - 0s 91us/step - loss: 0.2345 - acc: 0.9161 - val_loss: 0.4159 - val_acc: 0.8269\n",
      "Epoch 472/500\n",
      "155/155 [==============================] - 0s 90us/step - loss: 0.2271 - acc: 0.9355 - val_loss: 0.4157 - val_acc: 0.8269\n",
      "Epoch 473/500\n",
      "155/155 [==============================] - 0s 109us/step - loss: 0.2384 - acc: 0.9097 - val_loss: 0.4146 - val_acc: 0.8462\n",
      "Epoch 474/500\n",
      "155/155 [==============================] - 0s 82us/step - loss: 0.2292 - acc: 0.9226 - val_loss: 0.4139 - val_acc: 0.8462\n",
      "Epoch 475/500\n",
      "155/155 [==============================] - 0s 105us/step - loss: 0.2108 - acc: 0.9419 - val_loss: 0.4133 - val_acc: 0.8462\n",
      "Epoch 476/500\n",
      "155/155 [==============================] - 0s 97us/step - loss: 0.2263 - acc: 0.9161 - val_loss: 0.4119 - val_acc: 0.8269\n",
      "Epoch 477/500\n",
      "155/155 [==============================] - 0s 100us/step - loss: 0.2334 - acc: 0.9226 - val_loss: 0.4106 - val_acc: 0.8269\n",
      "Epoch 478/500\n",
      "155/155 [==============================] - 0s 115us/step - loss: 0.2201 - acc: 0.9355 - val_loss: 0.4098 - val_acc: 0.8269\n",
      "Epoch 479/500\n",
      "155/155 [==============================] - 0s 99us/step - loss: 0.2403 - acc: 0.9161 - val_loss: 0.4093 - val_acc: 0.8269\n",
      "Epoch 480/500\n",
      "155/155 [==============================] - 0s 134us/step - loss: 0.2439 - acc: 0.8968 - val_loss: 0.4095 - val_acc: 0.8269\n",
      "Epoch 481/500\n",
      "155/155 [==============================] - 0s 119us/step - loss: 0.2298 - acc: 0.9161 - val_loss: 0.4097 - val_acc: 0.8269\n",
      "Epoch 482/500\n",
      "155/155 [==============================] - 0s 127us/step - loss: 0.2113 - acc: 0.9484 - val_loss: 0.4110 - val_acc: 0.8269\n",
      "Epoch 483/500\n",
      "155/155 [==============================] - 0s 112us/step - loss: 0.2380 - acc: 0.9097 - val_loss: 0.4123 - val_acc: 0.8462\n",
      "Epoch 484/500\n",
      "155/155 [==============================] - 0s 100us/step - loss: 0.2344 - acc: 0.9032 - val_loss: 0.4137 - val_acc: 0.8462\n",
      "Epoch 485/500\n",
      "155/155 [==============================] - 0s 126us/step - loss: 0.2527 - acc: 0.9161 - val_loss: 0.4149 - val_acc: 0.8462\n",
      "Epoch 486/500\n",
      "155/155 [==============================] - 0s 152us/step - loss: 0.2235 - acc: 0.9097 - val_loss: 0.4157 - val_acc: 0.8462\n",
      "Epoch 487/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 98us/step - loss: 0.2220 - acc: 0.9355 - val_loss: 0.4160 - val_acc: 0.8462\n",
      "Epoch 488/500\n",
      "155/155 [==============================] - 0s 111us/step - loss: 0.2232 - acc: 0.9290 - val_loss: 0.4155 - val_acc: 0.8462\n",
      "Epoch 489/500\n",
      "155/155 [==============================] - 0s 92us/step - loss: 0.2188 - acc: 0.9226 - val_loss: 0.4152 - val_acc: 0.8462\n",
      "Epoch 490/500\n",
      "155/155 [==============================] - 0s 113us/step - loss: 0.2195 - acc: 0.9419 - val_loss: 0.4150 - val_acc: 0.8462\n",
      "Epoch 491/500\n",
      "155/155 [==============================] - 0s 122us/step - loss: 0.2129 - acc: 0.9226 - val_loss: 0.4149 - val_acc: 0.8462\n",
      "Epoch 492/500\n",
      "155/155 [==============================] - 0s 110us/step - loss: 0.2287 - acc: 0.8968 - val_loss: 0.4151 - val_acc: 0.8269\n",
      "Epoch 493/500\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.2348 - acc: 0.9161 - val_loss: 0.4155 - val_acc: 0.8462\n",
      "Epoch 494/500\n",
      "155/155 [==============================] - 0s 101us/step - loss: 0.2068 - acc: 0.9355 - val_loss: 0.4159 - val_acc: 0.8462\n",
      "Epoch 495/500\n",
      "155/155 [==============================] - 0s 220us/step - loss: 0.2237 - acc: 0.9290 - val_loss: 0.4169 - val_acc: 0.8462\n",
      "Epoch 496/500\n",
      "155/155 [==============================] - 0s 84us/step - loss: 0.2112 - acc: 0.9290 - val_loss: 0.4176 - val_acc: 0.8462\n",
      "Epoch 497/500\n",
      "155/155 [==============================] - 0s 88us/step - loss: 0.2240 - acc: 0.9032 - val_loss: 0.4174 - val_acc: 0.8462\n",
      "Epoch 498/500\n",
      "155/155 [==============================] - 0s 301us/step - loss: 0.2319 - acc: 0.9290 - val_loss: 0.4171 - val_acc: 0.8462\n",
      "Epoch 499/500\n",
      "155/155 [==============================] - 0s 139us/step - loss: 0.2164 - acc: 0.9355 - val_loss: 0.4168 - val_acc: 0.8462\n",
      "Epoch 500/500\n",
      "155/155 [==============================] - 0s 171us/step - loss: 0.2384 - acc: 0.9161 - val_loss: 0.4158 - val_acc: 0.8462\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(60, input_dim=60, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer = optimizers.adam(lr=0.001), metrics = ['accuracy'])\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = seed)\n",
    "# fit the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size= 0.25, random_state=seed)\n",
    "history = model.fit(x_train,y_train, validation_data= (x_test,y_test), epochs = 500, batch_size = 200)\n",
    "# list all data in history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Plotting the data\n",
    "\n",
    "Using the same model, the graph provides further insight into reliability of this model. As seen in the graph below, the data starts to overfit around 200 epochs. Further tuning is required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3Xd4U9UbwPHv6QZa2gJlFmhBZBeoFVA2IoIKCCJLfgxluAcuXKC4EFGR4UAUEBRElKUMUZAtUPYS2VLKKKPsQsf5/XGSJmnTQWk638/z9Mm9N/fenLSQN2e9R2mtEUIIIQDccrsAQggh8g4JCkIIIZJJUBBCCJFMgoIQQohkEhSEEEIkk6AghBAimQQFka2UUu5KqUtKqUrZeW5uUkrdopTK9rHbSqk2SqnDdvt7lVLNMnNuFl5rklLqtaxen85931VKTcnu+4rc45HbBRC5Syl1yW63KHANSLTsD9Zaf38j99NaJwK+2X1uYaC1rp4d91FKDQB6a61b2t17QHbcWxR8EhQKOa118oey5ZvoAK31H2mdr5Ty0Fon5ETZhBA5T5qPRLoszQM/KqVmKKUuAr2VUncopf5WSsUqpY4rpcYqpTwt53sopbRSKsSyP93y/CKl1EWl1DqlVOiNnmt5vr1S6l+l1Hml1Dil1BqlVL80yp2ZMg5WSu1XSp1TSo21u9ZdKfWpUuqMUuoA0C6d388bSqmZKY5NUEp9YtkeoJTaY3k/Byzf4tO6V5RSqqVlu6hSapqlbLuA25y87kHLfXcppTpajtcFxgPNLE1zp+1+t2/ZXf+Y5b2fUUrNVUqVy8zvJiNKqQcs5YlVSi1TSlW3e+41pVS0UuqCUuofu/faWCm12XL8pFLqo8y+nnABrbX8yA9aa4DDQJsUx94FrgMdMF8iigC3A40wNc0qwL/AU5bzPQANhFj2pwOngQjAE/gRmJ6Fc0sDF4FOlueGAPFAvzTeS2bKOA/wB0KAs9b3DjwF7AKCgZLASvNfxenrVAEuAcXs7n0KiLDsd7Cco4DWwFUgzPJcG+Cw3b2igJaW7dHAX0AgUBnYneLcbkA5y9+kl6UMZSzPDQD+SlHO6cBblu22ljLWB3yAz4FlmfndOHn/7wJTLNs1LeVobfkbvWb5vXsCtYEjQFnLuaFAFcv2RqCnZdsPaJTb/xcK84/UFERmrNZaL9BaJ2mtr2qtN2qt12utE7TWB4GJQIt0rp+ttY7UWscD32M+jG703PuBrVrreZbnPsUEEKcyWcYPtNbntdaHMR/A1tfqBnyqtY7SWp8BRqbzOgeBnZhgBXA3EKu1jrQ8v0BrfVAby4A/AaedySl0A97VWp/TWh/BfPu3f91ZWuvjlr/JD5iAHpGJ+wI8DEzSWm/VWscBQ4EWSqlgu3PS+t2kpwcwX2u9zPI3GgkUxwTnBEwAqm1pgjxk+d2BCe7VlFIltdYXtdbrM/k+hAtIUBCZcdR+RylVQyn1m1LqhFLqAjACKJXO9Sfstq+QfudyWueWty+H1lpjvlk7lckyZuq1MN9w0/MD0NOy3QsTzKzluF8ptV4pdVYpFYv5lp7e78qqXHplUEr1U0ptszTTxAI1MnlfMO8v+X5a6wvAOaCC3Tk38jdL675JmL9RBa31XuAFzN/hlKU5sqzl1P5ALWCvUmqDUureTL4P4QISFERmpByO+RXm2/EtWuviwDBM84grHcc05wCglFI4foildDNlPA5UtNvPaMjsj0AbyzftTpgggVKqCDAb+ADTtBMA/J7JcpxIqwxKqSrAF8DjQEnLff+xu29Gw2ejMU1S1vv5YZqpjmWiXDdyXzfM3+wYgNZ6uta6CabpyB3ze0FrvVdr3QPTRPgx8LNSyucmyyKySIKCyAo/4DxwWSlVExicA6/5KxCulOqglPIAngWCXFTGWcBzSqkKSqmSwCvpnay1PgmsBiYDe7XW+yxPeQNeQAyQqJS6H7jrBsrwmlIqQJl5HE/ZPeeL+eCPwcTHAZiagtVJINjase7EDOBRpVSYUsob8+G8SmudZs3rBsrcUSnV0vLaL2H6gdYrpWoqpVpZXu+q5ScR8wb+p5QqZalZnLe8t6SbLIvIIgkKIiteAPpi/sN/hfmm7FKWD97uwCfAGaAqsAUzryK7y/gFpu1/B6YTdHYmrvkB03H8g12ZY4HngTmYztqumOCWGcMxNZbDwCLgO7v7bgfGAhss59QA7NvhlwL7gJNKKftmIOv1izHNOHMs11fC9DPcFK31Lszv/AtMwGoHdLT0L3gDozD9QCcwNZM3LJfeC+xRZnTbaKC71vr6zZZHZI0yTbNC5C9KKXdMc0VXrfWq3C6PEAWF1BREvqGUaqeU8rc0QbyJGdGyIZeLJUSBIkFB5CdNgYOYJoh2wANa67Saj4QQWSDNR0IIIZK5tKZgqe7vtUyXH+rk+UpKqeVKqS1Kqe0yPlkIIXKXy2oKlo7AfzEzPKOwTWXfbXfORGCL1voLpVQtYKHWOiS9+5YqVUqHhKR7ihBCiBQ2bdp0Wmud3jBuwLVZUhsC+61T2S1JwzphcrhYacw0eDB5VqIzumlISAiRkZHZXFQhhCjYlFIZzcwHXNt8VAHHafpRpJ6B+hYm62YUsBB42tmNlFKDlFKRSqnImJgYV5RVCCEErg0Kzqbyp2yr6onJsBiMmcAyzTI13vEirSdqrSO01hFBQRnWfoQQQmSRK4NCFI65W4JJ3Tz0KGZqPFrrdZgsiplN6iWEECKbubJPYSMmHW4oJiFWD0wGSXv/YXLBTLHkp/HBTI8XQuQR8fHxREVFERcXl9tFEZng4+NDcHAwnp5ppb5Kn8uCgtY6QSn1FLAEkxHxW631LqXUCCBSaz0fk5/ma6XU85impX5aJk4IkadERUXh5+dHSEgIJjmtyKu01pw5c4aoqChCQ0MzvsAJl67RrLVeiOlAtj82zG57N9DElWUQQtycuLg4CQj5hFKKkiVLcjMDciTNhRAiQxIQ8o+b/VsVrqCQmAjffAMJCbldEiGEyJMKV1AYPx4GDDCBQQiRL5w5c4b69etTv359ypYtS4UKFZL3r1/P3LIL/fv3Z+/evemeM2HCBL7//vt0z8mspk2bsnXr1my5V05zaZ9CnrNrl3lMkkWdhMgvSpYsmfwB+9Zbb+Hr68uLL77ocI7WGq01bm7Ov+dOnjw5w9d58sknb76wBUDhqimcsCxCFRiYu+UQQty0/fv3U6dOHR577DHCw8M5fvw4gwYNIiIigtq1azNixIjkc63f3BMSEggICGDo0KHUq1ePO+64g1OnTgHwxhtvMGbMmOTzhw4dSsOGDalevTpr164F4PLlyzz44IPUq1ePnj17EhERkWGNYPr06dStW5c6derw2muvAZCQkMD//ve/5ONjx44F4NNPP6VWrVrUq1eP3r17Z/vvLDMKV03BGhQyWeUUQqTw3HOQ3c0i9euD5cP4Ru3evZvJkyfz5ZdfAjBy5EhKlChBQkICrVq1omvXrtSqVcvhmvPnz9OiRQtGjhzJkCFD+Pbbbxk6NFUSZ7TWbNiwgfnz5zNixAgWL17MuHHjKFu2LD///DPbtm0jPDw83fJFRUXxxhtvEBkZib+/P23atOHXX38lKCiI06dPs2PHDgBiY2MBGDVqFEeOHMHLyyv5WE4rnDUFmYQjRIFQtWpVbr/99uT9GTNmEB4eTnh4OHv27GH37t2prilSpAjt27cH4LbbbuPw4cNO792lS5dU56xevZoePXoAUK9ePWrXrp1u+davX0/r1q0pVaoUnp6e9OrVi5UrV3LLLbewd+9enn32WZYsWYK/vz8AtWvXpnfv3nz//fdZnnx2swpPTSEujuvRR/ECuHo1t0sjRP6UxW/0rlKsWLHk7X379vHZZ5+xYcMGAgIC6N27t9NZ2F5eXsnb7u7uJKQxGtHb2zvVOTc6tzat80uWLMn27dtZtGgRY8eO5eeff2bixIksWbKEFStWMG/ePN5991127tyJu7v7Db3mzSo0NYXRPz6L36tw3R2pKQhRAF24cAE/Pz+KFy/O8ePHWbJkSba/RtOmTZk1axYAO3bscFoTsde4cWOWL1/OmTNnSEhIYObMmbRo0YKYmBi01jz00EO8/fbbbN68mcTERKKiomjdujUfffQRMTExXLlyJdvfQ0YKTU2h/JGzXPeAfSWgtgQFIQqc8PBwatWqRZ06dahSpQpNmmR/soSnn36aPn36EBYWRnh4OHXq1Elu+nEmODiYESNG0LJlS7TWdOjQgfvuu4/Nmzfz6KOPorVGKcWHH35IQkICvXr14uLFiyQlJfHKK6/g5+eX7e8hI/lujeaIiAidlUV2th7fQoOJ4cz6xYOH2r8AI0e6oHRCFDx79uyhZs2auV2MPCEhIYGEhAR8fHzYt28fbdu2Zd++fXh45K3v187+ZkqpTVrriIyuzVvvxIWql6qBQrG7nDssWQKvvCJDU4UQN+TSpUvcddddJCQkoLXmq6++ynMB4WYVrHeTjiKeRagSWIXdJY7Akq3QqROsXJnbxRJC5CMBAQFs2rQpt4vhUoWmoxmgVlAtdgdaRhps2JC7hRFCiDyo0AWFvSUhwQ1JdSGEEE4UuqAQ7w4HAgGtYdo06JVyMTghhCi8ClVQqF+2PgAbKmCCQp8+MGOG2RZCCFG4gkKd0nUoeQX+rIJjIDh/PtfKJIRIX8uWLVNNRBszZgxPPPFEutf5+voCEB0dTdeuXdO8d0ZD3MeMGeMwiezee+/NlrxEb731FqNHj77p+2S3QhUU3JQbrQ7BslDQ9n0KliyJQoi8p2fPnsycOdPh2MyZM+nZs2emri9fvjyzZ8/O8uunDAoLFy4kICAgy/fL6wpVUAC46xAc9Yf9JewOSlAQIs/q2rUrv/76K9euXQPg8OHDREdH07Rp0+R5A+Hh4dStW5d58+aluv7w4cPUqVMHgKtXr9KjRw/CwsLo3r07V+3yoD3++OPJabeHDx8OwNixY4mOjqZVq1a0atUKgJCQEE6fPg3AJ598Qp06dahTp05y2u3Dhw9Ts2ZNBg4cSO3atWnbtq3D6zizdetWGjduTFhYGJ07d+bcuXPJr1+rVi3CwsKSE/GtWLEieZGhBg0acPHixSz/bp0pNPMUrO46aB7/qALVzloOSlAQIlOeW/wcW09kb+rs+mXrM6Zd2on2SpYsScOGDVm8eDGdOnVi5syZdO/eHaUUPj4+zJkzh+LFi3P69GkaN25Mx44d01yn+IsvvqBo0aJs376d7du3O6S+fu+99yhRogSJiYncddddbN++nWeeeYZPPvmE5cuXU6pUKYd7bdq0icmTJ7N+/Xq01jRq1IgWLVoQGBjIvn37mDFjBl9//TXdunXj559/Tnd9hD59+jBu3DhatGjBsGHDePvttxkzZgwjR47k0KFDeHt7JzdZjR49mgkTJtCkSRMuXbqEj4/Pjfy6M1Toagq3/LCYam5BzG5TznYwJib3CiSEyJB9E5J905HWmtdee42wsDDatGnDsWPHOHnyZJr3WblyZfKHc1hYGGFhYcnPzZo1i/DwcBo0aMCuXbsyTHa3evVqOnfuTLFixfD19aVLly6sWrUKgNDQUOrXNwNb0kvPDWZ9h9jYWFq0aAFA3759WWmZWBsWFsbDDz/M9OnTk2dON2nShCFDhjB27FhiY2OzfUZ1oaspqHvuoYfXY7y78l0OB0BILJDOPyIhhE163+hd6YEHHmDIkCFs3ryZq1evJn/D//7774mJiWHTpk14enoSEhLiNF22PWe1iEOHDjF69Gg2btxIYGAg/fr1y/A+6eWNs6bdBpN6O6Pmo7T89ttvrFy5kvnz5/POO++wa9cuhg4dyn333cfChQtp3Lgxf/zxBzVq1MjS/Z0pdDUFgEG3DcJDufPRnZYDa9bkanmEEOnz9fWlZcuWPPLIIw4dzOfPn6d06dJ4enqyfPlyjhw5ku59mjdvzvfffw/Azp072b59O2DSbhcrVgx/f39OnjzJokWLkq/x8/Nz2m7fvHlz5s6dy5UrV7h8+TJz5syhWbNmN/ze/P39CQwMTK5lTJs2jRYtWpCUlMTRo0dp1aoVo0aNIjY2lkuXLnHgwAHq1q3LK6+8QkREBP/8888Nv2Z6Cl1NASC4eDD9GvTnG7fveCNsIOVGjoe33wZL55IQIu/p2bMnXbp0cRiJ9PDDD9OhQwciIiKoX79+ht+YH3/8cfr3709YWBj169enYcOGgFlFrUGDBtSuXTtV2u1BgwbRvn17ypUrx/Lly5OPh4eH069fv+R7DBgwgAYNGqTbVJSWqVOn8thjj3HlyhWqVKnC5MmTSUxMpHfv3pw/fx6tNc8//zwBAQG8+eabLF++HHd3d2rVqpW8ilx2cWnqbKVUO+AzwB2YpLUemeL5T4FWlt2iQGmtdbpjvbKaOjulg+cOUnNCTR6s3J4f+syDatXg339v+r5CFDSSOjv/uZnU2S5rPlJKuQMTgPZALaCnUsphBW2t9fNa6/pa6/rAOOAXV5UnpSqBVXi92evMODiP397sAQcOgGXImxBCFFau7FNoCOzXWh/UWl8HZgKd0jm/JzDDheVJZWjTodQKqsXj3ku56JEE+/bl5MsLIUSe48qgUAE4arcfZTmWilKqMhAKLEvj+UFKqUilVGRMNg4f9XL3YlKHSUQlnOWN1sDWrZI9VQgn8tsKjYXZzf6tXBkUnM0eSau0PYDZWutEZ09qrSdqrSO01hFBQUHZVkCAOyrewZPhgxnXCP5+9X/g7g533pnxhUIUEj4+Ppw5c0YCQz6gtebMmTM3NaHNlaOPooCKdvvBQHQa5/YAnnRhWdL1fttRzF3+JQM6wuavwGvdOpMwL41ZkUIUJsHBwURFRZGdtXThOj4+PgQHB2f5elcGhY1ANaVUKHAM88GfavECpVR1IBBY58KypMvP248v1pWgQ7uzjGoCb6wEjh+H8uVzq0hC5Bmenp6EhobmdjFEDnFZ85HWOgF4ClgC7AFmaa13KaVGKKU62p3aE5ipc7luev/XK+i+E95pDv+UAjKY4i6EEAWRS+cpuEJ2zVNw5uQj3alZeha1T8GK28bh9uRTLnkdIYTIabk+TyE/KqOL8skSWF0ZJu79ARo2hP/+y+1iCSFEjpGgYE9r+m416bVfKbaOY/9shClTcrtUQgiRYyQo2PP1RQFfLYDr7tD/AUjcuSP1eTIKQwhRQElQsPfOO/Dii1QNupVxi2BpVRjKUsfx2fv3Q+nSMH587pVTCCFcRIKCvcBA+OgjKFqUAZvhiQ0wuvZ5Xl/2ui0wWNde+PLL3CunEEK4SKFMnZ0hyyLd446FkRi5nQ/4gEtxFxhz71jcrItlSJ4kIUQBJEHBGUtQcAu/jS8mb6fYdfiECRT19mXkxUbmnOvXc7GAQgjhGtJ85Iy1NtCgAQoY/TsMjoQP13zIN8cW5GrRhBDClSQoOFPLsuxDgwaAyew3biG03Q+PnZnKpnKW8xKd5u8TQoh8S4KCM7/8AkuWwC23JB/yTIKZsyEowZv+D5ghq7IojxCioJGg4EypUtC2rRl6WrZs8uHAOPhqXSl2lIH3mwFxcblXRiGEcAEJCulxc4NDh+CJJ5IPdfjzKA9vN0Hh4Km9uVg4IYTIfhIUMuLjA/XrOxwatRQ8E+H19e/nUqGEEMI1JChkRooO5fIX4YV1MPPwr2w8tjGXCiWEENlPgkJmVKliHvv0ST700hoI8grk5T9elmUKhRAFhgSFzGjbFjZsMBlTP/gAHnoIv+swbO45/jr8F78f+D23SyiEENlCgkJm3X67WbN56FB4+mkABm2CEAJ59ZcnSNJJuVxAIYS4eRIUssLHBwCvRHjnl3NsuXqQWX0jYNq0XC6YEELcHAkKWWEJCgC9dkDYCXgjcAvx/fqkc5EQQuR9EhSywi4ouGl4/0IEB0rAuMbKZE9VCnY4WZxHCCHyOAkKWWEXFADuLduMe71qM7yF5tjXH5uD33yTCwUTQoibI0EhK1IEBVWrNmNveZp4d3gh5ntzUFJrCyHyIQkKWVGkiG37pZegd2+qVong1VXwY8gl/qiCJMsTQuRLEhSywr6mMGoUeHtDpUq8sgZuOQP9O8GpxAu2c+LiTOZVIYTI4yQoZIWHkwXrgoLw6TeAWT/B6aLQLegv4hPjISkJXn4ZHnwQ1qzJ+bIKIcQNkKCQnQYOpMEJ+HoBrPA9zeBp3UjycIcJE8zz58/nbvmEECIDLg0KSql2Sqm9Sqn9SqmhaZzTTSm1Wym1Syn1gyvLk62++go2b3Y8VqoUAL23w7CdpZh8ZC7PtAedJLOdhRD5g5N2kOyhlHIHJgB3A1HARqXUfK31brtzqgGvAk201ueUUqVdVZ5sN2hQ6mOWoADw1uzTXDkPo5uA73UY+Qdw+XLOlU8IIbLAZUEBaAjs11ofBFBKzQQ6AbvtzhkITNBanwPQWp9yYXlcz88veVNh1l247AUfNoWAOBh64ULa1wohRB7gyuajCsBRu/0oyzF7twK3KqXWKKX+Vkq1c3YjpdQgpVSkUioyJibGRcXNBko57gLjF0Kv7fBqG/ji9KLcKZcQQmSSK4OCcnIs5cIDHkA1oCXQE5iklApIdZHWE7XWEVrriKCgoGwvaLZq3hw6dUredat6C1Pmwv174amrv/Drv7/mYuGEECJ9rgwKUUBFu/1gINrJOfO01vFa60PAXkyQyL9WrICff4bQUJPqIjAQzySYORsaJAbRY3YPthzfktulFEIIp1wZFDYC1ZRSoUopL6AHMD/FOXOBVgBKqVKY5qSDLixTznB3h4MH4ZFHIDAQgGLxsOBEa0oUKcH9M+4n6kJULhdSCCFSc1lQ0FonAE8BS4A9wCyt9S6l1AilVEfLaUuAM0qp3cBy4CWt9RlXlSlXeHsnb5aLTeC3Xr9x8dpF7v/hfi5eu5iLBRNCiNRcOk9Ba71Qa32r1rqq1vo9y7FhWuv5lm2ttR6ita6lta6rtZ7pyvLkCvs5CmvXUnf2Sn566Cd2ntpJj597kJCUkHtlE0KIFGRGs6uNGwe//gr9+kF0NDz1FPfs13x+3+cs3LeQZxc9i9Yp+9+FECJ3uHKeggDT4RwaCsHBMGWKOTZpEoNKlmR/i358FPk5ZX3L8GaLYblaTCGEAAkKOadePTh+HJ580oxOAkZ+DSc7wTCGU8SzKC/e+WIuF1IIUdhJ81FOKlsWbr89eddNwzfzobt7GC8tfYnxG8bnYuGEEEKCQs5r29Yh9bZHEkzz7MEDNR7g6UVP8+2Wb3OxcEKIwk6CQk4LD4dLl2DXruRDnjFnmPngTNpWbcuA+QOYtWtWLhZQCFGYSVDIDd7eUL26bf/ECbw9vJnTfQ5Nyjak9y+9+fPgn7lXPiFEoSVBIbe4u8M775jt77+HCRMoeiWe+c+tp/rlInT+sTObj29O/x5CCJHNVH4bIx8REaEjIyNzuxjZp3RpsGZ+9fCAhASO+cGdIyoRlxDH2kfWUrVE1dwtoxAi31NKbdJaR2R0ntQUctvs2baO5wQzu7nCRVjSewkJSQncM/0eTl46mYsFFEIUJhIUclvz5nD2LEya5HC4xoaDLOy1kOOXjnPvd/dwcfmSXCqgEKIwkaCQF/j5Qd++jsfuu49GwY2Y/dBstp3cRqep7Yg9LzUGIYRrSVDIKzycTC5/7z3aV2vP1F89WFUJbvumEauOrMr5sgkhCg0JCnlRsWLm8Y034LffeHhzAiumQFJiAs2nNGfwgsHExsXmahGFEAWTBIW86MMPbdv33w/AnUdhZ8Q3vHDHC0zaMomaE2oy5u8xsiaDECJbSVDIS2691TwGBzt9uljsFUa3Hc3GgRu5teStPL/keYI/DWbIkiFcvn45BwsqhCioJCjkJRs2mGU8fX2dP3/2LADh5cJZ0W8FfzedQsfQ9oz5ewwtp7Z0HLoaF2fSaQghxA2QoJCX+PubtRdatIBXXoETJxybkjZuNI/x8ZCQQKM2/Zg2IZq5Peay69Qumk1uxtHzR805tWubUU1CCHEDJCjkRR4eMHIklCljfqy++gqUAi8v6NTJHFu1io7VO7L0f0s5efkkzSY3Y//Z/abGIYQQN0iCQl4XFOT8+MKFDrtNKjVhed/lXLp+iWaTm7GjdA6UTQhR4EhQyOtuoAkovFw4K/osQ2loNBAmhYO+csWFhRNCFDQSFPI6f3/z2KULvPkmdO6cevazndoffMOmt0/QOAoGdoQOMzty/OLxHCqsECK/k6CQ14WFweTJJjfSiBHwyy9QsqTjOR98YNseO5Zyl+CP7+DTxfDnsdXU/rw2C/YuyNlyCyHyJQkK+UG/fhAYaNsvUcLx+ddeM0Fjx47kmoWbhuf+hq0NviI0MJSOMzvy2p+vkZCUkHPlFkLkO5kKCkqpqkopb8t2S6XUM0qpANcWTaQpZU0BYOBAU6twd3c4XD2uGGseWcPA8IF8sPoD7pl+D6cun8qhggoh8pvM1hR+BhKVUrcA3wChwA8uK5VIn7OgYGWZ4JbszBl8PHyY2GEi33b8lrVH13L717dzJPaIa8sohMiXMhsUkrTWCUBnYIzW+nmgXEYXKaXaKaX2KqX2K6WGOnm+n1IqRim11fIz4MaKX0jZB4WhqX6tjk7aZjn3b9Cf1f1Xc+HaBVp/15pjF465qIBCiPwqs0EhXinVE+gL/Go55pneBUopd2AC0B6oBfRUStVycuqPWuv6lp9JTp4XKVWrZtuuVCn18+XL27aPO448uq38bSx+eDExl2NoM62NNCUJIRxkNij0B+4A3tNaH1JKhQLTM7imIbBfa31Qa30dmAl0ynpRRbKKFW3bpZ3MUqtd27Z94kSqpxsFN+K3Xr9xJPYId0+7m7NXz6Y6RwhROGUqKGitd2utn9Faz1BKBQJ+WuuRGVxWAThqtx9lOZbSg0qp7Uqp2Uqpik6eRyk1SCkVqZSKjLEucl/YWUcj2c947tEDhgyB4sVtx+xrCn/9BZGRADSr3Iz5Peez9/Re7pl+D+fjzru+zEKIPC+zo4/+UkoVV0qVALYBk5VSn2R0mZNjOsX+AiBEax0G/AFMdXYjrfVErXWE1joiKK20D4XN/v3mp1o1kyt0YpSPAAAgAElEQVTpnXdgxgz4+GPHPgf7oNCqFdx+e/JumyptmN1tNltPbKXp5KYsO7QMrVP+iYQQhYmTNSCd8tdaX7B0BE/WWg9XSm3P4JoowP6bfzAQbX+C1vqM3e7XwIeIzClRwjZfIS7OcSjq+++Dmxt4esK4cdCtm8m+6sT9t97P/B7zGfzrYO767i5qlqpJ5xqdue/W+2hUoRHubu5OrxNCFEyZ7VPwUEqVA7ph62jOyEagmlIqVCnlBfQA5tufYLmnVUdgTybvLeylmJtAyZLwxRfQtKnZ/+knGDUqzcvbV2vP3qf2MqnDJEoXK82Haz6kybdNKDO6DI//+rjjOg1CiAIts0FhBLAEOKC13qiUqgLsS+8CyxDWpyzX7QFmaa13KaVGKKU6Wk57Rim1Sym1DXgG6JeVNyHS8NBDpo8hpWvXUh0q4lmER8Mf5a9+fxHzUgwzH5xJ+2rt+WbLN9w6/lbG/D2G+MT4HCi0ECI3qfzWhhwREaEjLZ2lIpNUiu6dQ4cgJCRTl+49vZdnFj/D7wd+p3ZQbcbfO56WIS2zvYhCCNdSSm3SWkdkdF5mO5qDlVJzlFKnlFInlVI/K6WcLyQs8p7Vq+HLL+Hpp83+yy87P8/JF4Tqpaqz+OHFzOk+h8vxl2k1tRUdZ3Rk8f7FJCYlurDQQojckKmaglJqKSatxTTLod7Aw1rru11YNqekpnATDh6EqlXN9pUrUKSI2T51yiz7+ckncPUq+Pg4vfxq/FU+WvsR4zeMJ+ZKDJX9KzMgfACPNHiE8n7lnV4jhMgbsrWmAARprSdrrRMsP1MAGRua31SpYtJwAxQtajqjO3QwS35+YhlhvHlzmpcX8SzCsBbDiBoSxayus6hWshpvLn+TSp9Wovvs7mw7sS0H3oQQwpUyGxROK6V6K6XcLT+9gTMZXiXynlatbNtPPAG/phhMtmiRedy3D8qWNY8peLl78VDth1j6v6Xsf3o/zzd+niX7l1D/q/o88dsTXImX1d6EyK8yGxQewQxHPQEcB7piUl+I/KZSJWjRIu3n338f/v3XNCedPAnz5qV7u6olqvJR24849Owhnmv0HF9EfkHExAj+PPhnNhdcCJETMpvm4j+tdUetdZDWurTW+gGgi4vLJlxBKZPuok8f588nJcGuXbB+vdlPuaBPGgKLBPJpu09Z+r+lXLp+iTbT2lDn8zq8+PuL/LjzRzYe28jl65ez5z0IIVzmZlZeczIAXuQbkyfD33/DnXfajpWzzCU8eRIOHzbb528sJ1KbKm349+l/+fzezyldrDTjN4ynx889aDipIRU/rcjotaNl1JIQedjNBAVnuY1EfuHmBo0aOQYFa86kqCi4dMlspwwK8fHw7rsQHU1afDx8ePz2x1nWdxnnh55n22Pb+KXbLzQObsxLS1/inun3yCxpIfKomwkK+WvWm3CudWvbdkiICQz2Q37ffRf22GUfGTUK3nwTJkzI1O29PbwJKxNG55qdWfjwQr7t+C1rjq6hxoQaDF8+XNJ2C5HHpBsUlFIXlVIXnPxcBGRgekHQvj0cPQoTJ5ompTJl4E+7TuLERGjeHC5cMDOhf/vNHL961TzGx5vjmdS/QX8iB0bSKqQVI1aOoNKnlRi0YBDz987nxKXUaz8IIXKWpLkQjkqWTL3Os73AQDh3Drp2NYn2+vaF774zzU3Fit3QS+08tZOP133MrF2zkoex1ixVk7dbvk3XWl1RKdNzCCGyLLsnr4nCootlUFmvXs6fP3fOPP73n3n87jvH4zegTuk6TO40mdMvnWbNI2v4pO0nuLu50212N27/+nYW7Vsk6zsIkcOkpiAcxcebLKq+vo6J9AYMgEmWJbQDAkwqjOPHbefcdRfMmpXpIaxpSUxKZNr2aby94m0Oxx6mSmAVmlVqRu2g2tQuXZvyfuWJT4wnPimehKQEKvhVIDQwFDcl32+ESE9mawoSFETa7IPCjBkwfLiZ2Pa//8G0aXDkCFSubDunRw9zXja4nnid6dunM/efuWyM3phuf4Oflx+vNn2Vl5u8LIsCCZEGCQri5t13HyxcaLbXrYP69WH3bpNMr1kzkz/pil1KCz8/eP558PaG117L1qKcvXqWPTF7OHX5FJ7unni6eeLu5s6R2CMs+HcB8/bOo0XlFrzS5BWaVGpCce/iGd9UiEJEgoK4eQkJcPo0/P67qR1Yaw7Xr5smJOsIJGe2boV69XKkmFprpmydwgu/v8C5ONO3UcGvAjWDalKrVC1qBtWkZqma1AqqRVCxIBKSEvjv/H/EXI6hZNGShASE4OFmW5k2PjGeDcc2kJCUQNNKTaX2IQoECQrCtZo2hTVroF8/mDIl9fPvvw+vvpqjRbqWcI1lh5ax7eQ29pzew+6Y3eyJ2cPleFt6DS93L5J0EglJCcnHingUoUG5Bvh7+3M5/jKR0ZHJo6FCAkJ4IuIJ+tXvR1AxSQws8q/MBgWPjE4QwqmyZc1j/fqpnytSxDQ35TBvD2/aV2tP+2rtk48l6SSiLkSxJ8YEiZOXT+Km3KgaWJUyvmU4feU0205sY9PxTcRcicHL3YtHGzxK88rNSUxKZMLGCbz8x8u8vux1utTswrONnuWOinfk+HsTIqdIUBBZU7OmeSxd2vF4xYomPffSpY7HExPNmg333WcmyU2dCt98Y9ZzcCE35UYl/0pU8q/EPbfcc8PXd6/Tnd0xu/l609dM3TaVH3f9SFiZMPrW60v/+v0JLBLoglILkXuk+UhkTVwcfPstDB4MHnbfLXr2NOkyPvrI9D1ERZn+hcOH4ZlnHO9Ruzbs3JmTpb4pl65fYurWqUzbPo31x9ZT1LMoHW7twL3V7sXf2x+AYxePceLSCTzcPKjsX5mwMmHUKV0HT3fPXC69KOyk+Ui4lo+PWaQHzApuwcGmb6F/f9iyxXRSz5xpmwRnv7iPVZ06jvsnTpiah1venHPg6+XLkw2f5MmGT7L1xFa+jPySX/b8wo+7fnQ4T6HQdqnBinoWpXFwY5pVakazSs2oULwCV+KvcDj2MHtP72Xvmb2cunyKJhWbMPC2gZQuVjrlSwuRY6SmILLf11/DoEGOx8qUMSm5K1Y0mVcvXDBrOkydap4/dMgsF9q6tWPupTwuISmBvaf3EpcQh0ZTwa8CpYuVJkknceDcAbad2Maao2tY9d8qtp3Y5hAsrMr7lSfQJ5BdMbsIKhrEb71+4/YKt2e6DJevX+an3T+xPmo9d1e9m841OjtNEbL/7H7+PPgn5f3K0zKkJX7efll6z4lJiSTqRLzcvdI8J+ZyDPvO7iOsTBi+Xr5Zeh1hRtZdTbhKUc+iN30vqSmI3BMQkPrYyZOmqenLL82s6Vq1HNNyb9liHpctM/0P7u5w+TJ4eYFn3m168XDzoHbp2qmOu+NOjVI1qFGqBt3rdAfgfNx51kWt49zVcxTxLELF4hW5teStyR/Ou07tosOMDrSc2pLXmr7Gs42fzfADdeOxjTz8y8PsO7sPDzcPvtz0JT3q9ODbjt9SxLMIF65dYMHeBSw+sJgZO2aQqM1aFhX8KjC3x1wiyjt+Ruw4uYOx68eyM2YnXWt25bnGzyUPyU3SSUzZOoWXlr5EbFwsD9d9mEkdJ6UKDp9v/JznFj9HfFI8gT6BfNvpWx6o8UCGv8sL1y7g7e6Nt4d3hue6mtaarSe24uXu5fTvm1lnrpxh6rapuCt3utfpTlnfsk7PW3t0LYv2LaKif0Xqlq5Lkk4iMjqSSVsmsfPUTsoUK0Pr0Na81/o9QgNDs1yezJCagsh+S5dC27apjw8bBm+/bbabNTN9EcuXw9y58McftnTc9s1InTqZ5wuJ4xeP89hvjzF/73x8vXypVqIacQlxnL92Hm93b1qFtKJzzc7UKFWD6dun896q9yjrW5ZvOn5D69DWjF47mtf+fI0qgVWoXqo6fx78k2uJ1wjwCaB33d483ehpDsceZtCCQURdiGJg+EDaV2tPkk5i/9n9vLn8TTzdPAkNDGX7ye3cFXoXY9uPJfpiNEP/GMqm45u4s+KdhJUO48tNX9L+lvbM7jY7+Zvsd9u+o+/cvrS/pT0DwwfyweoP2Hx8M9M6T6Nn3Z6p3q/WmrVH1/JF5BfM3DkTHw8f3mj+Bi/d+VJyMIpLiGPDsQ3EJ8ZTt0zdNJvX4hPjSdJJeLh5oJQiMSkRT3dP4hPjb6hPJz4xnod+eoh5e81StGPbjeXpRk+nOi8hKYGtJ7Zy4doFzl09x8XrF/F29ya4eDDRF6PZeWonk7ZMSp6N7+PhQ5+wPrx/1/uULGrWLrkaf5XnlzzPV5u+clqW2kG16VqrK4djD/PT7p/4pO0nDI4YnOn3Yk/mKYjcs3EjNGxotj/91MxyBvOhb+2HuP9+s1DPq69Ct26O12/bZmZF16hh9pOSHFNuFALrjq5j+vbpHIo9RFHPovh7+3Ph+gV+P/A7F65dSD6vR50efH7v5w6joH4/8Dvvr3qfU5dPcVfoXfSq24uGFRo6TMKLuRzD8L+GM2nzJOKT4pOPtw5tzQ9dfqB0sdJ8s+Ubnln0DFcTzCTF8n7lGdVmFL3q9kIpxaTNkxi0YBDl/MrROLgxF69dZOnBpbQKacXChxfi4+HDxWsXuX/G/aw6sooG5Rrg4+FDBb8KhJUJI6hoEJ+t/4w9p/fg6+VLv3r9OHrhKPP2zqNJxSb0rdeXv478xdx/5ibPG/F082TQbYN4u+XbyR+sW09s5bnFz7HyyEo0GjflhkKhlKKCXwX+O/8f9crWo3vt7nSv3T3db9qHzh1iwIIBLDu0jGHNh7Hp+CYW7lvIx20/5smGTybXitYdXcfgXwez49SOdP+Obau25Z1W7xDgE8DotaOZum0qZYqV4d3W71LcuzhvLn+Tnad28tKdLzGsxTCiL0az/+x+knQSDco2oLxf+eSmwOiL0ZQpVibLkyklKIjcs28f3Hqr2Y6JgSDLpK/Zs+HBB832ww+b5UDr1YM5c8wxT0/TtLR0qbmHNYDs2mWam9KyYIHJufTDD655P3nItYRrrPpvFVEXoggvF05YmbCbut/pK6c5HHsYd+WOj4cPNUrVcOiPOBx7mIX7FlLWtyxtq7ZN1Zy1/NByxm0Yx+6Y3Xi6e/JgzQd5temrDk1AV+Kv8NGaj1h+eDlKKaIuRLH/7H4AqpesztCmQ+laqyu+Xr5orZm2fRov/v4iMVdi8Pf2p2edntx3630U9SzKT7t+4uvNXxPgE8Cg2wZx4NwBZu+eTckiJRkYPpBiXsW4En8FrTWJOpHDsYcJCQhh5ZGVrIsyc2eszXrBfsGcunIKd+WOu5s7u2N2s+3ENop4FuGzdp/xSINHuBJ/hW4/deO3fb9RsXhFOlbvyJmrZ/hx548EFw/mnVbvEBIQQnHv4vh6+RIbF8vpK6cJLh5MJf9K+Pv4O/y+IqMj6TOnD3tOm4WrgooGMa3ztCwNl75ReSIoKKXaAZ8B7sAkrfXINM7rCvwE3K61TvcTX4JCPnD6tC0QWPsHAFatMjOhwXzg//ijaSY6ccKs4/Deeyap3vTpsHYtfP65CRRdupjFgPr0cV5jsB5LSLC9lsjTLly7QNSFKKqXrO70m681FUl5v/L4ePg4PLfj5A6G/D6EPw7+QVDRIHqH9ebN5m9mOGfkcOxhZu2axer/VrM7ZjenLp+inF+55BnuoQGh3FnxTgbfNpiK/hWTr9Nas+TAEkauHsm2k9tQKPrV78eIViOy1ImepJPYFL0JjaZWUK0c64jP9aCglHIH/gXuBqKAjUBPrfXuFOf5Ab8BXsBTEhQKgPh400EMoDW0bGnScf/1l2kWAtNsNHKk+RB/5RUTEM6dM6m3330XFi82uZWqVDGL+YBZJvS228xKcMWKwaJF5rg1KFy4YJLyiULhSvwVvN29JTdVJuWFRXYaAvu11ge11teBmUAnJ+e9A4wC4lxYFpGTPD2hXDkzgQ1MMFi3zhYQwDZCKTHRNjs6IMBc+8YbsHq1CQj32FWrrWm5V60yQSOly5dTHxMFVlHPohIQXMCVQaECcNRuP8pyLJlSqgFQUWv9a3o3UkoNUkpFKqUiY2Jisr+kIvtFR8OLL6b9vLUjGuDuu82jUhAebjvu7m5qGVaRkabmYTV/Ppw6Zdu/dOmmiiyEcG1QcDZcJPl/tFLKDfgUeCGjG2mtJ2qtI7TWEUFBkqmyQGjVyuRC+vFHM7HNasYM0zwE5rFqVdMR3aED7N9v+iusOnUyfQ1WixebTmchRJa5cvJaFFDRbj8YiLbb9wPqAH9ZRjuUBeYrpTpm1K8gCgjrUFV7oaGwYoUZtVTSDDnkgQdMjqQFC0xgsLd5s237actY8sBAU4PwkLmZQtwoV9YUNgLVlFKhSikvoAcw3/qk1vq81rqU1jpEax0C/A1IQBBGUJBjDqRq1czjihUZX3vunOl0FkLcMJcFBa11AvAUsATYA8zSWu9SSo1QSnV01euKAuq220yQsC7cs2WL6ZBOy8WLphNbCHFDXJqOUmu9UGt9q9a6qtb6PcuxYVrr+U7ObSm1BJGmW26B118326GhZnGfESNMCoxp01Kff+aMaT4aMcJ27L//zHEwfRn9+pljQohkeTNHsRDOvPkmvPACzJpl9pUync2tW6c+1zqXZfhwM6lt2TKoXBl69zbHP/3UZGh9/PGcKbsQ+YT0xIn8w9MTRo9OfbxYsdTH7JcDLV3aFgzWrjWPhw6Zx4ULTf9D8eKO11+6ZJqrit58ymIh8hOpKYj8zxoUAgLMUp9g8ip5eMCAAabjeeZMc9zDw0xyO3XK9FMAHDiQ+p5+fqbJSohCRoKCyP88PExajVtusc1x+Ocf0/cwcaIZ2mqd9BgbawsC1klzmzaZ/Evz5zvWMI4fd3ydU6fgyhXXvhchcpkEBVEw+PqaiW72uY/KlTP9DmF2mUSTksySoWBLoTFwoDm3Uye4806Tp8mZMmUcZ1gLUQBJUBAFwwcfwLPPOgaFspZVrlKuBb15s5no1qKF8wR6R4+mPhZvWXNg48bsKa8QeZQEBVEwDBoEd9xhku5ZZzJbg0LVqqnP/+gjU4uwH7JqZf/Bb53rkLIpCWDMGDOsVYgCRIKCKFiUsgUFa06llEGhTRtbxtbnnoMpUxyfnz3btm1dR/rYMduxpCTz+PzzZlhrRnr0gI8/zlTxhchtEhREwRNnycJurSlUqWIefXxMx7P9hz44ZmwF+OUX2/aqVaZz2T4ozJ3r2OGcmGiytyplW4Pa3o8/pp8xVog8RIKCKHiaNTOPJUqYx1DLmrzly5tOZX/HJRIJCTGPb71lOxZhWYvkgQdgyBDHoPDgg45zI86dMz8p7yFEPiRBQRQ8c+fCyy+bZiKAIkXMLOg//3R+fpEiZtbz8OG2Y02a2LanT4etW9N+vdOnHdNlLFsGzzyT9fILkYtcukazK8hynMKlrEt7rlplOq87dIBRo0zgKFHCscZgNXeuqVGkdPKkmVBn7b9I7//aX3+ZobD3uH4Bd1E45YXlOIXIv26/HXbvhj59zP7Vq3Dvvc7Ptc6WTmnrVueT3WbNMjmc7LVqBe3aZb28QmQTCQpC2Hv9dTOvwfrtvnJl23PWGdBWo0aZx23bnN8rMtI2eglg3jzz2L27WXXuyBGT4juf1dZFwSZBQQh7774LO3bY9n19bR3WjRs7nlurlknSt2eP2X/iCcfnX3/d1okNponJPs9SSIgZGeVsDgSYYHP4cBbehBBZJ0FBiIxUrmyGtwYHOx6vVMkMcbUaP96sGAdQt67ze61e7bh/+nTaiffq17eNnErP6tVmLoR1/oQQN0FSZwuRkUcfNX0K1k5oq5IlzYzmS5dseZY2bTLNQW++6VjjsLLOgHZ3t82W9vQ09wfzwe7mBtev267Zv98EJB8f5+Xr2tV0an/4oWNzlxBZIDUFITLy5JO2yWe+vuZx8GDb5LinnjJzFwAqVjQ1iC5d0r+nfZK+unVtM54nTTK5mY4csT1frRp062a2t26Fs2cd71WypHk8ePDG3pcQTkhQEOJG/Pef6QP48kvzjT4tnTqZxXvSYr+EqI+PLTHf4MFmnYeUazwsWGBmajdoAJ07Oz5XqpR53L8/8+9DiDRIUBDiRgQG2moIGbHPwDpihK25CKB2bVs6DW/v1NlanS38Y22OWrnSZHm1stZeJCiIbCBBQYic0LevqVmsXAnbt5tjrVubzK4ffph6OVDrOfbsZ2SPH2/bttZI7PswtHYMQkJkkgQFIXKCda3nZs1sI5P8/c2a0XXqONYUiheHLVvM6CN706c77ls/9GNjzePff9tGIPXqZbLFzpkDv/6ave9FFGgy+kgIV/L1NaOTrEEhLfZB4cIF06H81FOm89haE9i1y/Ga+fPNczt3mv1z5+Dff6FGDdssa2uHd8oJcvv3m2ASkWHWA1HISE1BCFdav95MiMsoKKR8Pj7e5F2yn/yWUpcutiGu1ol1zvoiwDQt2S8z+uqr0LOn4zlr15ohtaJQk6AghCvVqmVmNmfklltg2DBb6oyGDU0+pNBQMyEuIMDMbbjzTufXW+dQnDjh/PmwMDN3wurYMTh0yGSHtWrSJGs1h/370w5GIt9xaVBQSrVTSu1VSu1XSg118vxjSqkdSqmtSqnVSqlariyPEHmWm5tZoKd/f3jsMfjtN3P86afN8Ro1oHlz0ynt5wc//eR4vXXmszUoWHM32Vu71rZ96pTpk4iKMvs3k3+pWrW0Z2WLfMdlqbOVUu7Av8DdQBSwEeiptd5td05xrfUFy3ZH4AmtdbqpIiV1tiiUjh41M5+tw2Hj4kw6b4AvvjBJ9kJDTVbXsWPNUqSnTjnew9fXJOhzczOd2RcvmrUfSpe2/YDpp5gwwUyomzXL1FjSY62lSGK/PC2zqbNd2dHcENivtT5oKdBMoBOQHBSsAcGiGCD/qoRwpmJFx30fH7OQUEQEPPSQOVa2rKkpLFtmCwje3ra+hEuXYN8+M+P64kVzbOxYsx6EfSrvp56C774z20OHmlFNKVN8iALLlc1HFYCjdvtRlmMOlFJPKqUOAKMAWa5KiMz68ENbQAATFKKj4a67zH63bmZIKtiCSo0ajsuRzp1rHq1pNsCk/LbasMGs82DNBCsKPFcGBWdfLVLVBLTWE7TWVYFXgDec3kipQUqpSKVUZExMTDYXU4gComxZWLPGtl+xogkQjz8OK1bYjsfHp3+flKvL/f676TC/dCn7yiryLFcGhSjAvs4bDESnc/5MwMmahqC1nqi1jtBaRwRZUxMLIRyVKeO47+sLXl7w+eeOKbitfRHlyzueb+0stl8YyN7336c+Zp/N9UZs3WqCmH3iP5EnuDIobASqKaVClVJeQA9gvv0JSqlqdrv3AftcWB4hCraUOZlSzn346SeYPNnMlj5wANq2dXy+ShXzmFaK7scegylTHI9Z+ybATIYbNizjmgiYyXUnT8KYMRmfK3KUy4KC1joBeApYAuwBZmmtdymlRlhGGgE8pZTapZTaCgwB+rqqPEIUeCmDQspv8V27mslu1aubAGAdbWRlDQrWrKtgFgHats00H4EZMhsSYlJnxMTAunW2c4cPh3feMSOWwDYa6exZ0/TUqZNtKK11NTv75i6RJ7g0zYXWeiGwMMWxYXbbz7ry9YUoVFI2H2XUB/DkkyaQDBli9q1BISDArCiXkGDWaihZ0nzYW9eMOHIEevc2Q1fth6Fam53++AOqVjXJ/tavh0aNTKA5fdqk5rh0Cc6cMeeePn1z71lkO5nRLERBkbKmkN56D2CGpj7/vG3fumpbYCC0b2/SbFh16WKGqoKZVa112vMSpkwxAQHMHApw/PB/7DHbQkHHj5skfn//bXI3LVmSfpmFy0lQEKKgsNYUvLzgtdfMHIMb4WFpOAgISP/+DRvaag32Vq1KfWzRIufnWVODx8WZYbN33GFqE+3apV5ZLjraBK+sdmqLGyJBQYiCokwZ01/w/ffw3nup12hIi7u7eWzd2uRIeu895+dZ03J7eprmoZScLQd68qTjfni4aX7asMF2bONGx/sfPep4zauvmg7pBg1MzUK4lAQFIQoKDw/45x/ToXwjDhwwzTcBAaZT2breQ0r33GMeO3aERx4xH/A3ytk19osDQeqgYM3jtHs3PPFE2vfeuxdGjzb3S0w0tRBxwyQoCFHYVa5sOoMz0qiR6Xxu2hTKlTNptk+eTD1/Yfx4mDoV5s0z+/a5k+rVS33fbdsc948eNZ3Y1uVK7Ws8++xGrZ8/b/onLl40K9rVqAEvvWQWMurf3zYfA0wt5ty5jN+jkEV2hBA3wNrUZFW6dOoO7ieftG1v22aatKxzH+rUsT3Xt6/54D92zNzXupLcnj2mY/vPP823/gt2KdL+/dcEgObN4dNP4auvzKgp+zKcPw/TppntuDjz2lWrQnBw6lqIlVLw7LMybwKpKQghbpb9N3IvL8fnwsIc03i3bGk+7GNj4ZtvoEULc9y6WpyfH4wbZ1uPetMmW8dzjx5mYlyLFqa5y9o8FB8PxYo5L9v69bZgY58mfPFiWx+GdbLdZ5/d8FsviCQoCCFujvXDFcxsaWfsm5BatzZJ+dzdbcn7SpY06b8HDnS87sMPTcd006a2BYgA/vvPNiRW67T7D1q2NLmb7P3yixlyO3682U8rrYe9b7+F224zr/PJJ6mbvAoQaT4SQtwcX1/z+NJLtpnPKS1Z4nxIqTUoWGdRDx9uJrdNnGj2rdlZO3Y0zT/FisHlyyZQWCfnnTvnOAs7JfugcOaMbQTTunUmOGSUFvzaNXj0UbN96JAtzXgBXT9CagpCiJtTrx6sXg3vv5/2OZ6ezpt46tQxaTOsQ1yLFzf9BBs3Oi4tWqKE+fC+dMmMkjp40Iy0AtPZnd7sbft+gqFDbbWZmTPh1ltNcj6rlB/08fGOE++sr1mASU1BCHHzmjTJ2meF+J4AAAvbSURBVHVKmX6DlMn7rGtFW9NjWHMlgQkiX35p24+KMrWHzJg0KfWxhXaZeM6ft03emzEDevVynNm9e7dt29qJfbPOnTOzxceNc3yfuURqCkKI3FWiRNofrtaRR/Xr246FhDies2KFbbGgzp3N47Jl6b+mfRCyn3W9aZNZH3vvXjPKCRyDhn1Q+Ouv9F8D4Mcf0x7xZPXpp/DDD2YJ1DxAgoIQIu+y9kNY+x7AMSgMHux4/rhxpomoeXPTpBUdDT//DG3aOJ43dKiZS1G5smMz1fffw/33m9FQ//5rjllHL4FjUPjhh9TlTUoyczkArlwxI6bapbvsvK2Wk3LkVi6RoCCEyLvmzDHzHuwXBLIGhdtvhxdfdDy/QgX44AMzsqlJEzPJrksXWLrUds7zz8Prr0OfPqaj2apdOxMorPY5Wd7FGhQeegimT7fNhwATPO67zwSgxER46y1z3D7oWEVHm4B26RJcvWqOZUdTVDaQoCCEyLseeMA2dNTKms01MdGsFmf/QZ4Zw4fbMsjaj5Zq3txxeO3Ro46d48HBtprLxx+b/pABA8w18+ebILN4sVnjeuZM+Ogjc66zHFQdO5oRVitX2oLClSs39j5cRIKCECJ/sdYarM00vXrd2PX2H9L2QeG221Kfa988VaGCefT3N+tfjx1rgsSKFWYBoR9+MEHq8mUzdNXK39/0W1jXrQDTdwFmkp51Nbv05kucP29yUlkXKXIhCQpCiPylZk0zxNXaPONxg4Mo7ecl3Hmn+eD/5x9o3Ng0SXXtajquJ02yzU8oU8a2Up01hbg1SFhHNB08aGoQYGoLVgcPwr33mg7l8+cdlyv95BPbtn1QOHfO1JCsQ2RjYmDnzhxJ8idDUoUQ+YufX+qJcH36QLVqzs+3mjPHtOXbK1LEcXirfUpvq23bTHOTdb6DNc+SNSj88IOpcYSG2tastl9bwn4d619/NavWORMba9vu1s2sYNeihcntNGKEOZ7eJL1sIkFBCJH/ZaZf4YEHsnbvsDDzGBRkHlPWFMCsfQ3mA9zNLfVCQVb2qTqsypc3HeL2NYU//jCPly/Dyy/bOrStZXAhaT4SQojMsDYfWRMA2q+JbW1m8vU1HdZgOpNT1gqsK86BqVmA+aD397cFBWtfCZjag33tJQdqChIUhBAiM6w5nqzpw93d4emnYdYsx5nIQ4aYeQ6vv277gA8MNLUBe9a1JQICzM/atWZEkn0T14ABjv0TUlMQQog8wjpc1c3uY3PsWDNnwV6HDiaRX8OGtuGmn3+eOlmgtVlKKbMwEJhOb/u1tY8dc7wmZToQF5CgIIQQmdGypXlMq6PYGevcg8DA1N/yq1c3j9eumQV+5swx+zNmpH2/jDK6ZgMJCkIIkRnVq5shotbgkBnWoFC0qK2mMXGiuY+1OSkuznzYP/CAbXGhXCRBQQghXOXLL02Hc8OGtvkJ1slz1n6Ia9ds57du7fw+mzbB4cMuK6Y9CQpCCOEqderAvHlmSdKmTc0x63wKa7qOQYMcr9m1y6wOZ69BA9v5Lqa0C1cPUkq1Az4D3IFJWuuRKZ4fAgwAEoAY4BGt9ZH07hkREaEj7XvjhRAiP0hKMim5a9Z0PKaU874C67GrV7MlWZ5SapPWOiKj81w2eU0p5Q5MAO4GooCNSqn5Wmu73LNsASK01leUUo8Do4DuriqTEELkGjc3x4BgPZaWX34xgSGHs6e6ckZzQ2C/1voggFJqJtAJSA4KWuvlduf/DdxAt74QQhRg1gWDcpgr+xQqAPZLDkVZjqXlUWCRsyeUUoOUUpFKqciYmJhsLKIQQgh7rgwKzgbUOu3AUEr1BiKAj5w9r7WeqLWO0FpHBOXAjD4hhCisXNl8FAVUtNsPBqJTnqSUagO8DrTQWl9L+bwQQoic48qawkagmlIqVCnlBfQA5tufoJRqAHz1//buL1Sqco3j+Pd3LMzynCytEOy0T9RFBWV/6Nifi4oI6xy8OUFIUEQQRZFBVMqBoOgmggwpoqKIKPpHf5GoZGdBFEqWlmaWhVdZWykL4SBlTxfvM6tpn723k3vPrGbN7wPDWutZi/F9xqXvvGvNel5gUUSMdLEtZmbWga51ChHxM3AD8AawGXguIjZJulPSojzsHmAm8Lyk9ZJeHeftzMysB7o6n0JEvAa8Nip2e9v6hd38883M7I/xE81mZlZxp2BmZpWulrnoBkk7gAlLYUxgDrBzCpvTD5zzYHDOg2EyOR8TEfv8TX/fdQqTIemDTmp/NIlzHgzOeTD0ImdfPjIzs4o7BTMzqwxap/Bw3Q2ogXMeDM55MHQ954G6p2BmZhMbtJGCmZlNwJ2CmZlVBqJTkLRQ0hZJWyUtrbs9U0XSY5JGJG1six0uaZWkL3J5WMYlaUV+Bh9LOq2+lu8/SUdLWi1ps6RNkpZkvLF5SzpI0lpJGzLnOzL+D0lrMudns/Akkqbn9tbcP1Rn+ydD0jRJH0lamduNzlnSNkmfZC24DzLW03O78Z1C27SgFwMnAoslnVhvq6bM48DCUbGlwHBEHA8M5zaU/I/P1zXAgz1q41T7Gbg5Ik4AFgDX599nk/PeA1wQEacA84GFkhYAdwPLM+fvKRNVkcvvI+I4YHke16+WUApqtgxCzudHxPy25xF6e25HRKNfwFnAG23by4BldbdrCvMbAja2bW8B5ub6XGBLrj8ELB7ruH5+Aa9Q5gEfiLyBg4EPgX9Snmw9IOPVeU6pTHxWrh+Qx6nutu9HrvMo/wleAKykTNzV9Jy3AXNGxXp6bjd+pMAfnxa03x0VEdsBcnlkxhv3OeQlglOBNTQ877yMsh4YAVYBXwK7opSoh9/nVeWc+38AZve2xVPiPuBW4Jfcnk3zcw7gTUnrJF2TsZ6e210tnf0n0fG0oA3XqM9B0kzgBeCmiPhRGiu9cugYsb7LOyL2AvMlzQJeAk4Y67Bc9n3Okv4NjETEOknntcJjHNqYnNM5EfG1pCOBVZI+m+DYruQ8CCOFjqYFbZBvJc0FyGVrRrvGfA6SDqR0CE9FxIsZbnzeABGxC3ibcj9llqTWF7v2vKqcc/+hwHe9bemknQMskrQNeIZyCek+mp0zEfF1Lkconf+Z9PjcHoROYZ/TgjbMq8CVuX4l5Zp7K35F/mJhAfBDa0jaT1SGBI8CmyPi3rZdjc1b0hE5QkDSDOBCys3X1cCledjonFufxaXAW5EXnftFRCyLiHkRMUT5N/tWRFxOg3OWdIikv7bWgYuAjfT63K77xkqPbt5cAnxOuQ7737rbM4V5PQ1sB36ifGu4mnIddRj4IpeH57Gi/ArrS+AT4Iy627+fOZ9LGSJ/DKzP1yVNzhs4Gfgoc94I3J7xY4G1wFbgeWB6xg/K7a25/9i6c5hk/ucBK5uec+a2IV+bWv9X9frcdpkLMzOrDMLlIzMz65A7BTMzq7hTMDOzijsFMzOruFMwM7OKOwWzJGlvVqdsvaasoq6kIbVVszX7sxqEMhdmnfpfRMyvuxFmdfJIwWwfssb93TmnwVpJx2X8GEnDWct+WNLfM36UpJdy/oMNks7Ot5om6ZGcE+HNfDoZSTdK+jTf55ma0jQD3CmYtZsx6vLRZW37foyIM4H7KTV4yPUnIuJk4ClgRcZXAO9Emf/gNMrTqVDq3j8QEScBu4D/ZHwpcGq+z7XdSs6sE36i2SxJ2h0RM8eIb6NMcvNVFuP7JiJmS9pJqV//U8a3R8QcSTuAeRGxp+09hoBVUSZKQdJtwIERcZek14HdwMvAyxGxu8upmo3LIwWzzsQ46+MdM5Y9bet7+e2e3r8oNWxOB9a1VQE16zl3Cmaduaxt+X6uv0ep4AlwOfBurg8D10E1Oc7fxntTSX8Bjo6I1ZQJZWYB/zdaMesVfyMx+82MnN2s5fWIaP0sdbqkNZQvUoszdiPwmKRbgB3AVRlfAjws6WrKiOA6SjXbsUwDnpR0KKXq5fIocyaY1cL3FMz2Ie8pnBERO+tui1m3+fKRmZlVPFIwM7OKRwpmZlZxp2BmZhV3CmZmVnGnYGZmFXcKZmZW+RXqdgrwXrSL1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "train_line = 'r'\n",
    "val_line = 'g'\n",
    "\n",
    "plt.plot(epochs, loss, train_line, label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, val_line, label = 'Validation loss')\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EarlyStopping\n",
    "By implementing EarlyStopping this allows us to find peak performance utilising the following settings, any further and the data starts to be exposed to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 155 samples, validate on 52 samples\n",
      "Epoch 1/500\n",
      "155/155 [==============================] - 5s 31ms/step - loss: 0.7155 - acc: 0.4774 - val_loss: 0.7010 - val_acc: 0.4423\n",
      "Epoch 2/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.6904 - acc: 0.5097 - val_loss: 0.6945 - val_acc: 0.4423\n",
      "Epoch 3/500\n",
      "155/155 [==============================] - 0s 59us/step - loss: 0.6977 - acc: 0.5161 - val_loss: 0.6888 - val_acc: 0.6154\n",
      "Epoch 4/500\n",
      "155/155 [==============================] - 0s 127us/step - loss: 0.6857 - acc: 0.5419 - val_loss: 0.6849 - val_acc: 0.6154\n",
      "Epoch 5/500\n",
      "155/155 [==============================] - 0s 84us/step - loss: 0.6742 - acc: 0.5742 - val_loss: 0.6823 - val_acc: 0.5769\n",
      "Epoch 6/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.6912 - acc: 0.5484 - val_loss: 0.6805 - val_acc: 0.5577\n",
      "Epoch 7/500\n",
      "155/155 [==============================] - 0s 60us/step - loss: 0.6904 - acc: 0.5677 - val_loss: 0.6791 - val_acc: 0.5577\n",
      "Epoch 8/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.6904 - acc: 0.5226 - val_loss: 0.6777 - val_acc: 0.5385\n",
      "Epoch 9/500\n",
      "155/155 [==============================] - 0s 56us/step - loss: 0.6712 - acc: 0.6000 - val_loss: 0.6763 - val_acc: 0.5385\n",
      "Epoch 10/500\n",
      "155/155 [==============================] - 0s 60us/step - loss: 0.6778 - acc: 0.5226 - val_loss: 0.6748 - val_acc: 0.5577\n",
      "Epoch 11/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.6851 - acc: 0.5548 - val_loss: 0.6732 - val_acc: 0.5962\n",
      "Epoch 12/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.6798 - acc: 0.5548 - val_loss: 0.6715 - val_acc: 0.5962\n",
      "Epoch 13/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.6597 - acc: 0.6065 - val_loss: 0.6699 - val_acc: 0.6346\n",
      "Epoch 14/500\n",
      "155/155 [==============================] - 0s 57us/step - loss: 0.6703 - acc: 0.5806 - val_loss: 0.6684 - val_acc: 0.6154\n",
      "Epoch 15/500\n",
      "155/155 [==============================] - 0s 58us/step - loss: 0.6631 - acc: 0.6194 - val_loss: 0.6668 - val_acc: 0.6346\n",
      "Epoch 16/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.6598 - acc: 0.6258 - val_loss: 0.6654 - val_acc: 0.6346\n",
      "Epoch 17/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.6643 - acc: 0.5935 - val_loss: 0.6641 - val_acc: 0.6538\n",
      "Epoch 18/500\n",
      "155/155 [==============================] - 0s 59us/step - loss: 0.6634 - acc: 0.6129 - val_loss: 0.6628 - val_acc: 0.6731\n",
      "Epoch 19/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.6369 - acc: 0.6645 - val_loss: 0.6615 - val_acc: 0.7115\n",
      "Epoch 20/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.6540 - acc: 0.6323 - val_loss: 0.6604 - val_acc: 0.7115\n",
      "Epoch 21/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.6659 - acc: 0.6194 - val_loss: 0.6594 - val_acc: 0.7115\n",
      "Epoch 22/500\n",
      "155/155 [==============================] - 0s 60us/step - loss: 0.6462 - acc: 0.6452 - val_loss: 0.6584 - val_acc: 0.6538\n",
      "Epoch 23/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.6472 - acc: 0.6645 - val_loss: 0.6573 - val_acc: 0.6538\n",
      "Epoch 24/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.6555 - acc: 0.6452 - val_loss: 0.6559 - val_acc: 0.6154\n",
      "Epoch 25/500\n",
      "155/155 [==============================] - 0s 91us/step - loss: 0.6313 - acc: 0.6774 - val_loss: 0.6544 - val_acc: 0.5962\n",
      "Epoch 26/500\n",
      "155/155 [==============================] - 0s 83us/step - loss: 0.6363 - acc: 0.6774 - val_loss: 0.6526 - val_acc: 0.5962\n",
      "Epoch 27/500\n",
      "155/155 [==============================] - 0s 100us/step - loss: 0.6389 - acc: 0.6710 - val_loss: 0.6508 - val_acc: 0.6154\n",
      "Epoch 28/500\n",
      "155/155 [==============================] - 0s 102us/step - loss: 0.6411 - acc: 0.6903 - val_loss: 0.6489 - val_acc: 0.6346\n",
      "Epoch 29/500\n",
      "155/155 [==============================] - 0s 91us/step - loss: 0.6305 - acc: 0.6516 - val_loss: 0.6469 - val_acc: 0.6538\n",
      "Epoch 30/500\n",
      "155/155 [==============================] - 0s 87us/step - loss: 0.6432 - acc: 0.6258 - val_loss: 0.6449 - val_acc: 0.6731\n",
      "Epoch 31/500\n",
      "155/155 [==============================] - 0s 95us/step - loss: 0.6333 - acc: 0.6581 - val_loss: 0.6429 - val_acc: 0.6731\n",
      "Epoch 32/500\n",
      "155/155 [==============================] - 0s 92us/step - loss: 0.6351 - acc: 0.7097 - val_loss: 0.6409 - val_acc: 0.6923\n",
      "Epoch 33/500\n",
      "155/155 [==============================] - 0s 98us/step - loss: 0.6204 - acc: 0.6903 - val_loss: 0.6390 - val_acc: 0.6923\n",
      "Epoch 34/500\n",
      "155/155 [==============================] - 0s 94us/step - loss: 0.6433 - acc: 0.6516 - val_loss: 0.6371 - val_acc: 0.6923\n",
      "Epoch 35/500\n",
      "155/155 [==============================] - 0s 109us/step - loss: 0.6171 - acc: 0.6903 - val_loss: 0.6353 - val_acc: 0.6923\n",
      "Epoch 36/500\n",
      "155/155 [==============================] - 0s 97us/step - loss: 0.6051 - acc: 0.7290 - val_loss: 0.6336 - val_acc: 0.6923\n",
      "Epoch 37/500\n",
      "155/155 [==============================] - 0s 100us/step - loss: 0.6134 - acc: 0.6903 - val_loss: 0.6319 - val_acc: 0.6923\n",
      "Epoch 38/500\n",
      "155/155 [==============================] - 0s 96us/step - loss: 0.6256 - acc: 0.6774 - val_loss: 0.6302 - val_acc: 0.6923\n",
      "Epoch 39/500\n",
      "155/155 [==============================] - 0s 107us/step - loss: 0.6065 - acc: 0.6774 - val_loss: 0.6285 - val_acc: 0.6923\n",
      "Epoch 40/500\n",
      "155/155 [==============================] - 0s 95us/step - loss: 0.6054 - acc: 0.6968 - val_loss: 0.6269 - val_acc: 0.6923\n",
      "Epoch 41/500\n",
      "155/155 [==============================] - 0s 97us/step - loss: 0.6028 - acc: 0.6903 - val_loss: 0.6252 - val_acc: 0.6923\n",
      "Epoch 42/500\n",
      "155/155 [==============================] - 0s 101us/step - loss: 0.6138 - acc: 0.6968 - val_loss: 0.6236 - val_acc: 0.6923\n",
      "Epoch 43/500\n",
      "155/155 [==============================] - 0s 97us/step - loss: 0.6106 - acc: 0.6903 - val_loss: 0.6220 - val_acc: 0.6923\n",
      "Epoch 44/500\n",
      "155/155 [==============================] - 0s 94us/step - loss: 0.6038 - acc: 0.7032 - val_loss: 0.6203 - val_acc: 0.6923\n",
      "Epoch 45/500\n",
      "155/155 [==============================] - 0s 83us/step - loss: 0.5955 - acc: 0.7484 - val_loss: 0.6185 - val_acc: 0.6731\n",
      "Epoch 46/500\n",
      "155/155 [==============================] - 0s 86us/step - loss: 0.6124 - acc: 0.6710 - val_loss: 0.6169 - val_acc: 0.6538\n",
      "Epoch 47/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.5863 - acc: 0.7419 - val_loss: 0.6152 - val_acc: 0.6538\n",
      "Epoch 48/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.5906 - acc: 0.7419 - val_loss: 0.6135 - val_acc: 0.6731\n",
      "Epoch 49/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.5809 - acc: 0.7548 - val_loss: 0.6119 - val_acc: 0.6731\n",
      "Epoch 50/500\n",
      "155/155 [==============================] - 0s 99us/step - loss: 0.5938 - acc: 0.7226 - val_loss: 0.6104 - val_acc: 0.6731\n",
      "Epoch 51/500\n",
      "155/155 [==============================] - 0s 91us/step - loss: 0.5896 - acc: 0.7226 - val_loss: 0.6087 - val_acc: 0.6731\n",
      "Epoch 52/500\n",
      "155/155 [==============================] - 0s 96us/step - loss: 0.5892 - acc: 0.7290 - val_loss: 0.6069 - val_acc: 0.6538\n",
      "Epoch 53/500\n",
      "155/155 [==============================] - 0s 91us/step - loss: 0.5853 - acc: 0.7677 - val_loss: 0.6051 - val_acc: 0.6731\n",
      "Epoch 54/500\n",
      "155/155 [==============================] - 0s 87us/step - loss: 0.5938 - acc: 0.7484 - val_loss: 0.6032 - val_acc: 0.6731\n",
      "Epoch 55/500\n",
      "155/155 [==============================] - 0s 82us/step - loss: 0.5716 - acc: 0.7677 - val_loss: 0.6013 - val_acc: 0.6923\n",
      "Epoch 56/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.5810 - acc: 0.7419 - val_loss: 0.5993 - val_acc: 0.6923\n",
      "Epoch 57/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.5836 - acc: 0.7097 - val_loss: 0.5974 - val_acc: 0.6923\n",
      "Epoch 58/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.5621 - acc: 0.7677 - val_loss: 0.5954 - val_acc: 0.6923\n",
      "Epoch 59/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.5728 - acc: 0.7548 - val_loss: 0.5934 - val_acc: 0.6923\n",
      "Epoch 60/500\n",
      "155/155 [==============================] - 0s 97us/step - loss: 0.5800 - acc: 0.7290 - val_loss: 0.5915 - val_acc: 0.6923\n",
      "Epoch 61/500\n",
      "155/155 [==============================] - 0s 104us/step - loss: 0.5774 - acc: 0.7097 - val_loss: 0.5897 - val_acc: 0.6923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "155/155 [==============================] - 0s 114us/step - loss: 0.5705 - acc: 0.7484 - val_loss: 0.5880 - val_acc: 0.6923\n",
      "Epoch 63/500\n",
      "155/155 [==============================] - 0s 100us/step - loss: 0.5699 - acc: 0.7613 - val_loss: 0.5862 - val_acc: 0.6923\n",
      "Epoch 64/500\n",
      "155/155 [==============================] - 0s 104us/step - loss: 0.5668 - acc: 0.7548 - val_loss: 0.5846 - val_acc: 0.6923\n",
      "Epoch 65/500\n",
      "155/155 [==============================] - 0s 104us/step - loss: 0.5682 - acc: 0.7613 - val_loss: 0.5831 - val_acc: 0.6923\n",
      "Epoch 66/500\n",
      "155/155 [==============================] - 0s 120us/step - loss: 0.5663 - acc: 0.7548 - val_loss: 0.5816 - val_acc: 0.6923\n",
      "Epoch 67/500\n",
      "155/155 [==============================] - 0s 157us/step - loss: 0.5610 - acc: 0.7484 - val_loss: 0.5800 - val_acc: 0.6923\n",
      "Epoch 68/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.5607 - acc: 0.7548 - val_loss: 0.5784 - val_acc: 0.6923\n",
      "Epoch 69/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.5577 - acc: 0.7677 - val_loss: 0.5768 - val_acc: 0.6923\n",
      "Epoch 70/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.5547 - acc: 0.7548 - val_loss: 0.5753 - val_acc: 0.6923\n",
      "Epoch 71/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.5536 - acc: 0.7548 - val_loss: 0.5739 - val_acc: 0.6923\n",
      "Epoch 72/500\n",
      "155/155 [==============================] - 0s 58us/step - loss: 0.5757 - acc: 0.7290 - val_loss: 0.5726 - val_acc: 0.7115\n",
      "Epoch 73/500\n",
      "155/155 [==============================] - 0s 63us/step - loss: 0.5616 - acc: 0.7806 - val_loss: 0.5712 - val_acc: 0.7115\n",
      "Epoch 74/500\n",
      "155/155 [==============================] - 0s 58us/step - loss: 0.5507 - acc: 0.7484 - val_loss: 0.5697 - val_acc: 0.7115\n",
      "Epoch 75/500\n",
      "155/155 [==============================] - 0s 98us/step - loss: 0.5491 - acc: 0.7419 - val_loss: 0.5682 - val_acc: 0.7115\n",
      "Epoch 76/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.5332 - acc: 0.7935 - val_loss: 0.5665 - val_acc: 0.7115\n",
      "Epoch 77/500\n",
      "155/155 [==============================] - 0s 86us/step - loss: 0.5418 - acc: 0.8065 - val_loss: 0.5649 - val_acc: 0.7115\n",
      "Epoch 78/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.5414 - acc: 0.7806 - val_loss: 0.5633 - val_acc: 0.7115\n",
      "Epoch 79/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.5432 - acc: 0.7419 - val_loss: 0.5616 - val_acc: 0.7115\n",
      "Epoch 80/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.5295 - acc: 0.8065 - val_loss: 0.5600 - val_acc: 0.7115\n",
      "Epoch 81/500\n",
      "155/155 [==============================] - 0s 59us/step - loss: 0.5256 - acc: 0.7806 - val_loss: 0.5583 - val_acc: 0.7115\n",
      "Epoch 82/500\n",
      "155/155 [==============================] - 0s 83us/step - loss: 0.5496 - acc: 0.7548 - val_loss: 0.5566 - val_acc: 0.7115\n",
      "Epoch 83/500\n",
      "155/155 [==============================] - 0s 60us/step - loss: 0.5338 - acc: 0.7935 - val_loss: 0.5549 - val_acc: 0.7115\n",
      "Epoch 84/500\n",
      "155/155 [==============================] - 0s 66us/step - loss: 0.5329 - acc: 0.7677 - val_loss: 0.5533 - val_acc: 0.7115\n",
      "Epoch 85/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.5367 - acc: 0.8000 - val_loss: 0.5516 - val_acc: 0.7115\n",
      "Epoch 86/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.5255 - acc: 0.7548 - val_loss: 0.5498 - val_acc: 0.7115\n",
      "Epoch 87/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.5224 - acc: 0.7742 - val_loss: 0.5481 - val_acc: 0.7115\n",
      "Epoch 88/500\n",
      "155/155 [==============================] - 0s 77us/step - loss: 0.5232 - acc: 0.7677 - val_loss: 0.5464 - val_acc: 0.7115\n",
      "Epoch 89/500\n",
      "155/155 [==============================] - 0s 68us/step - loss: 0.5215 - acc: 0.8065 - val_loss: 0.5447 - val_acc: 0.7115\n",
      "Epoch 90/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.5218 - acc: 0.8065 - val_loss: 0.5430 - val_acc: 0.7115\n",
      "Epoch 91/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.5152 - acc: 0.8000 - val_loss: 0.5414 - val_acc: 0.7115\n",
      "Epoch 92/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.5055 - acc: 0.8323 - val_loss: 0.5395 - val_acc: 0.7115\n",
      "Epoch 93/500\n",
      "155/155 [==============================] - 0s 83us/step - loss: 0.5114 - acc: 0.7935 - val_loss: 0.5377 - val_acc: 0.7115\n",
      "Epoch 94/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.5182 - acc: 0.7742 - val_loss: 0.5357 - val_acc: 0.7115\n",
      "Epoch 95/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.5010 - acc: 0.8129 - val_loss: 0.5335 - val_acc: 0.7115\n",
      "Epoch 96/500\n",
      "155/155 [==============================] - 0s 65us/step - loss: 0.5030 - acc: 0.7871 - val_loss: 0.5314 - val_acc: 0.7115\n",
      "Epoch 97/500\n",
      "155/155 [==============================] - 0s 61us/step - loss: 0.5230 - acc: 0.7613 - val_loss: 0.5294 - val_acc: 0.7115\n",
      "Epoch 98/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.4826 - acc: 0.8387 - val_loss: 0.5274 - val_acc: 0.7115\n",
      "Epoch 99/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.5116 - acc: 0.7806 - val_loss: 0.5257 - val_acc: 0.7115\n",
      "Epoch 100/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.5034 - acc: 0.7613 - val_loss: 0.5242 - val_acc: 0.7115\n",
      "Epoch 101/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.5157 - acc: 0.7871 - val_loss: 0.5228 - val_acc: 0.7115\n",
      "Epoch 102/500\n",
      "155/155 [==============================] - 0s 86us/step - loss: 0.4981 - acc: 0.8258 - val_loss: 0.5214 - val_acc: 0.7308\n",
      "Epoch 103/500\n",
      "155/155 [==============================] - 0s 85us/step - loss: 0.4894 - acc: 0.8323 - val_loss: 0.5201 - val_acc: 0.7308\n",
      "Epoch 104/500\n",
      "155/155 [==============================] - 0s 83us/step - loss: 0.4895 - acc: 0.8000 - val_loss: 0.5188 - val_acc: 0.7115\n",
      "Epoch 105/500\n",
      "155/155 [==============================] - 0s 90us/step - loss: 0.4959 - acc: 0.7871 - val_loss: 0.5175 - val_acc: 0.7115\n",
      "Epoch 106/500\n",
      "155/155 [==============================] - 0s 88us/step - loss: 0.4995 - acc: 0.8000 - val_loss: 0.5164 - val_acc: 0.7115\n",
      "Epoch 107/500\n",
      "155/155 [==============================] - 0s 86us/step - loss: 0.4868 - acc: 0.8000 - val_loss: 0.5149 - val_acc: 0.7115\n",
      "Epoch 108/500\n",
      "155/155 [==============================] - 0s 75us/step - loss: 0.4901 - acc: 0.8194 - val_loss: 0.5135 - val_acc: 0.7115\n",
      "Epoch 109/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.4991 - acc: 0.7742 - val_loss: 0.5119 - val_acc: 0.7115\n",
      "Epoch 110/500\n",
      "155/155 [==============================] - 0s 87us/step - loss: 0.4919 - acc: 0.8065 - val_loss: 0.5102 - val_acc: 0.7115\n",
      "Epoch 111/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.4789 - acc: 0.8194 - val_loss: 0.5085 - val_acc: 0.7115\n",
      "Epoch 112/500\n",
      "155/155 [==============================] - 0s 64us/step - loss: 0.4881 - acc: 0.8129 - val_loss: 0.5066 - val_acc: 0.7115\n",
      "Epoch 113/500\n",
      "155/155 [==============================] - 0s 79us/step - loss: 0.4727 - acc: 0.8194 - val_loss: 0.5049 - val_acc: 0.7115\n",
      "Epoch 114/500\n",
      "155/155 [==============================] - 0s 74us/step - loss: 0.4784 - acc: 0.7806 - val_loss: 0.5032 - val_acc: 0.7115\n",
      "Epoch 115/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.4654 - acc: 0.8452 - val_loss: 0.5014 - val_acc: 0.7115\n",
      "Epoch 116/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.4688 - acc: 0.8194 - val_loss: 0.4998 - val_acc: 0.7115\n",
      "Epoch 117/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.4652 - acc: 0.8387 - val_loss: 0.4982 - val_acc: 0.7115\n",
      "Epoch 118/500\n",
      "155/155 [==============================] - 0s 70us/step - loss: 0.4803 - acc: 0.8129 - val_loss: 0.4968 - val_acc: 0.7115\n",
      "Epoch 119/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.4621 - acc: 0.8581 - val_loss: 0.4955 - val_acc: 0.7115\n",
      "Epoch 120/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.4683 - acc: 0.8258 - val_loss: 0.4940 - val_acc: 0.7308\n",
      "Epoch 121/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.4768 - acc: 0.8194 - val_loss: 0.4928 - val_acc: 0.7308\n",
      "Epoch 122/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.4675 - acc: 0.8387 - val_loss: 0.4916 - val_acc: 0.7308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.4647 - acc: 0.8129 - val_loss: 0.4904 - val_acc: 0.7308\n",
      "Epoch 124/500\n",
      "155/155 [==============================] - 0s 81us/step - loss: 0.4500 - acc: 0.8516 - val_loss: 0.4892 - val_acc: 0.7308\n",
      "Epoch 125/500\n",
      "155/155 [==============================] - 0s 76us/step - loss: 0.4530 - acc: 0.8645 - val_loss: 0.4882 - val_acc: 0.7308\n",
      "Epoch 126/500\n",
      "155/155 [==============================] - 0s 78us/step - loss: 0.4610 - acc: 0.8065 - val_loss: 0.4870 - val_acc: 0.7308\n",
      "Epoch 127/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.4553 - acc: 0.8387 - val_loss: 0.4859 - val_acc: 0.7308\n",
      "Epoch 128/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.4425 - acc: 0.8258 - val_loss: 0.4846 - val_acc: 0.7308\n",
      "Epoch 129/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.4504 - acc: 0.8645 - val_loss: 0.4832 - val_acc: 0.7308\n",
      "Epoch 130/500\n",
      "155/155 [==============================] - 0s 72us/step - loss: 0.4589 - acc: 0.8516 - val_loss: 0.4820 - val_acc: 0.7308\n",
      "Epoch 131/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.4574 - acc: 0.8258 - val_loss: 0.4808 - val_acc: 0.7115\n",
      "Epoch 132/500\n",
      "155/155 [==============================] - 0s 62us/step - loss: 0.4344 - acc: 0.8645 - val_loss: 0.4798 - val_acc: 0.7308\n",
      "Epoch 133/500\n",
      "155/155 [==============================] - 0s 69us/step - loss: 0.4776 - acc: 0.8129 - val_loss: 0.4790 - val_acc: 0.7308\n",
      "Epoch 134/500\n",
      "155/155 [==============================] - 0s 71us/step - loss: 0.4408 - acc: 0.8581 - val_loss: 0.4785 - val_acc: 0.7115\n",
      "Epoch 135/500\n",
      "155/155 [==============================] - 0s 81us/step - loss: 0.4489 - acc: 0.8645 - val_loss: 0.4781 - val_acc: 0.7308\n",
      "Epoch 136/500\n",
      "155/155 [==============================] - 0s 112us/step - loss: 0.4450 - acc: 0.8516 - val_loss: 0.4777 - val_acc: 0.7308\n",
      "Epoch 137/500\n",
      "155/155 [==============================] - 0s 147us/step - loss: 0.4432 - acc: 0.8387 - val_loss: 0.4773 - val_acc: 0.7308\n",
      "Epoch 138/500\n",
      "155/155 [==============================] - 0s 107us/step - loss: 0.4573 - acc: 0.8065 - val_loss: 0.4769 - val_acc: 0.7308\n",
      "Epoch 139/500\n",
      "155/155 [==============================] - 0s 113us/step - loss: 0.4416 - acc: 0.8452 - val_loss: 0.4764 - val_acc: 0.7308\n",
      "Epoch 140/500\n",
      "155/155 [==============================] - 0s 102us/step - loss: 0.4319 - acc: 0.8581 - val_loss: 0.4756 - val_acc: 0.7308\n",
      "Epoch 141/500\n",
      "155/155 [==============================] - 0s 105us/step - loss: 0.4363 - acc: 0.8387 - val_loss: 0.4748 - val_acc: 0.7308\n",
      "Epoch 142/500\n",
      "155/155 [==============================] - 0s 96us/step - loss: 0.4427 - acc: 0.8194 - val_loss: 0.4737 - val_acc: 0.7308\n",
      "Epoch 143/500\n",
      "155/155 [==============================] - 0s 84us/step - loss: 0.4391 - acc: 0.8194 - val_loss: 0.4726 - val_acc: 0.7308\n",
      "Epoch 144/500\n",
      "155/155 [==============================] - 0s 86us/step - loss: 0.4226 - acc: 0.8581 - val_loss: 0.4714 - val_acc: 0.7308\n",
      "Epoch 145/500\n",
      "155/155 [==============================] - 0s 96us/step - loss: 0.4270 - acc: 0.8516 - val_loss: 0.4702 - val_acc: 0.7308\n",
      "Epoch 146/500\n",
      "155/155 [==============================] - 0s 98us/step - loss: 0.4424 - acc: 0.8516 - val_loss: 0.4690 - val_acc: 0.7308\n",
      "Epoch 147/500\n",
      "155/155 [==============================] - 0s 107us/step - loss: 0.4218 - acc: 0.8516 - val_loss: 0.4678 - val_acc: 0.7308\n",
      "Epoch 148/500\n",
      "155/155 [==============================] - 0s 123us/step - loss: 0.4301 - acc: 0.8452 - val_loss: 0.4667 - val_acc: 0.7308\n",
      "Epoch 149/500\n",
      "155/155 [==============================] - 0s 105us/step - loss: 0.4465 - acc: 0.8323 - val_loss: 0.4655 - val_acc: 0.7308\n",
      "Epoch 150/500\n",
      "155/155 [==============================] - 0s 109us/step - loss: 0.4116 - acc: 0.8710 - val_loss: 0.4645 - val_acc: 0.7308\n",
      "Epoch 151/500\n",
      "155/155 [==============================] - 0s 111us/step - loss: 0.4197 - acc: 0.8645 - val_loss: 0.4637 - val_acc: 0.7308\n",
      "Epoch 152/500\n",
      "155/155 [==============================] - 0s 104us/step - loss: 0.4275 - acc: 0.8323 - val_loss: 0.4629 - val_acc: 0.7308\n",
      "Epoch 153/500\n",
      "155/155 [==============================] - 0s 86us/step - loss: 0.4197 - acc: 0.8452 - val_loss: 0.4621 - val_acc: 0.7308\n",
      "Epoch 154/500\n",
      "155/155 [==============================] - 0s 103us/step - loss: 0.4118 - acc: 0.8710 - val_loss: 0.4615 - val_acc: 0.7308\n",
      "Epoch 155/500\n",
      "155/155 [==============================] - 0s 104us/step - loss: 0.4172 - acc: 0.8710 - val_loss: 0.4609 - val_acc: 0.7308\n",
      "Epoch 156/500\n",
      "155/155 [==============================] - 0s 92us/step - loss: 0.4110 - acc: 0.8452 - val_loss: 0.4605 - val_acc: 0.7308\n",
      "Epoch 157/500\n",
      "155/155 [==============================] - 0s 100us/step - loss: 0.4098 - acc: 0.8516 - val_loss: 0.4597 - val_acc: 0.7308\n",
      "Epoch 158/500\n",
      "155/155 [==============================] - 0s 98us/step - loss: 0.4272 - acc: 0.8323 - val_loss: 0.4591 - val_acc: 0.7308\n",
      "Epoch 159/500\n",
      "155/155 [==============================] - 0s 96us/step - loss: 0.4145 - acc: 0.8452 - val_loss: 0.4583 - val_acc: 0.7308\n",
      "Epoch 160/500\n",
      "155/155 [==============================] - 0s 97us/step - loss: 0.4201 - acc: 0.8516 - val_loss: 0.4577 - val_acc: 0.7308\n",
      "Epoch 161/500\n",
      "155/155 [==============================] - 0s 84us/step - loss: 0.4107 - acc: 0.8710 - val_loss: 0.4568 - val_acc: 0.7308\n",
      "Epoch 162/500\n",
      "155/155 [==============================] - 0s 87us/step - loss: 0.4043 - acc: 0.8452 - val_loss: 0.4561 - val_acc: 0.7308\n",
      "Epoch 163/500\n",
      "155/155 [==============================] - 0s 146us/step - loss: 0.3952 - acc: 0.8903 - val_loss: 0.4554 - val_acc: 0.7308\n",
      "Epoch 164/500\n",
      "155/155 [==============================] - 0s 108us/step - loss: 0.4142 - acc: 0.8645 - val_loss: 0.4547 - val_acc: 0.7308\n",
      "Epoch 165/500\n",
      "155/155 [==============================] - 0s 93us/step - loss: 0.4093 - acc: 0.8516 - val_loss: 0.4539 - val_acc: 0.7308\n",
      "Epoch 166/500\n",
      "155/155 [==============================] - 0s 121us/step - loss: 0.4118 - acc: 0.8774 - val_loss: 0.4532 - val_acc: 0.7308\n",
      "Epoch 167/500\n",
      "155/155 [==============================] - 0s 132us/step - loss: 0.3902 - acc: 0.8774 - val_loss: 0.4527 - val_acc: 0.7308\n",
      "Epoch 168/500\n",
      "155/155 [==============================] - 0s 103us/step - loss: 0.4224 - acc: 0.8323 - val_loss: 0.4521 - val_acc: 0.7308\n",
      "Epoch 169/500\n",
      "155/155 [==============================] - 0s 73us/step - loss: 0.3921 - acc: 0.8581 - val_loss: 0.4516 - val_acc: 0.7308\n",
      "Epoch 170/500\n",
      "155/155 [==============================] - 0s 67us/step - loss: 0.4020 - acc: 0.8581 - val_loss: 0.4508 - val_acc: 0.7308\n",
      "Epoch 171/500\n",
      "155/155 [==============================] - 0s 86us/step - loss: 0.3967 - acc: 0.8839 - val_loss: 0.4500 - val_acc: 0.7500\n",
      "Epoch 172/500\n",
      "155/155 [==============================] - 0s 93us/step - loss: 0.4122 - acc: 0.8194 - val_loss: 0.4493 - val_acc: 0.7500\n",
      "Epoch 173/500\n",
      "155/155 [==============================] - 0s 110us/step - loss: 0.4114 - acc: 0.8516 - val_loss: 0.4485 - val_acc: 0.7500\n",
      "Epoch 174/500\n",
      "155/155 [==============================] - 0s 97us/step - loss: 0.3829 - acc: 0.8645 - val_loss: 0.4480 - val_acc: 0.7500\n",
      "Epoch 175/500\n",
      "155/155 [==============================] - 0s 129us/step - loss: 0.4072 - acc: 0.8581 - val_loss: 0.4474 - val_acc: 0.7500\n",
      "Epoch 176/500\n",
      "155/155 [==============================] - 0s 131us/step - loss: 0.4074 - acc: 0.8710 - val_loss: 0.4470 - val_acc: 0.7500\n",
      "Epoch 177/500\n",
      "155/155 [==============================] - 0s 92us/step - loss: 0.4038 - acc: 0.8645 - val_loss: 0.4466 - val_acc: 0.7500\n",
      "Epoch 178/500\n",
      "155/155 [==============================] - 0s 103us/step - loss: 0.4004 - acc: 0.8516 - val_loss: 0.4464 - val_acc: 0.7500\n",
      "Epoch 179/500\n",
      "155/155 [==============================] - 0s 99us/step - loss: 0.3939 - acc: 0.8839 - val_loss: 0.4465 - val_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(60, input_dim=60, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer = optimizers.adam(lr = 0.001), metrics = ['accuracy'])\n",
    "# Apply earlystopping\n",
    "earlystopping = callbacks.EarlyStopping(monitor ='val_loss', patience = 0, verbose = 0, mode = 'auto')\n",
    "# fit the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y,test_size= 0.25, random_state=seed)\n",
    "history = model.fit(x_train,y_train, validation_data= (x_test,y_test), epochs = 500, batch_size = 200, callbacks = [earlystopping])\n",
    "# list all data in history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "train_line = 'r'\n",
    "val_line = 'g'\n",
    "\n",
    "plt.plot(epochs, loss, train_line, label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, val_line, label = 'Validation loss')\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "Accuracy for both data types are over 0.70 \n",
    "However, the increase in training accuracy may lead to overfitting. Discrepancies with accuracy could be a result from implementing a dropout layer solely on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzsnXl8VNXd/98nISFAEghhSwIEEAHZAkkEF1xBXCruVdH2p7au1arVLtbyVGqr7UPdl9bdp/pQqdXHBdeqBdyKOEEWQRLWQJgASQiQEEK28/vjOyf3zmQmmSwTspz365XXzNx77r1nBj2f813O9yitNRaLxWKxAEQd6Q5YLBaLpeNgRcFisVgs9VhRsFgsFks9VhQsFovFUo8VBYvFYrHUY0XBYrFYLPVYUbBEBKVUtFKqXCk1vC3bHkmUUqOVUm2ew62UmqWU2ub6nKuUOimcti141nNKqbtber2l69PjSHfA0jFQSpW7PvYGDgO1vs83aK0XNud+WutaIL6t23YHtNZj2+I+SqlrgR9orU913fvatri3petiRcECgNa6flD2zUSv1Vp/HKq9UqqH1rqmPfpmsVjaD+s+soSFUuoPSql/KKVeUUqVAT9QSh2vlFqulNqnlCpUSj2mlIrxte+hlNJKqRG+z//rO/++UqpMKfUfpdTI5rb1nT9bKZWnlNqvlHpcKfWFUurqEP0Op483KKU2KaVKlVKPua6NVko9rJQqUUptBs5q5PeZp5RaFHDsSaXUQ7731yqlvvN9n82+WXyoexUopU71ve+tlHrZ17d1QFaQ527x3XedUuo83/FJwBPAST7XXLHrt53vuv5G33cvUUq9qZRKCee3ac7vbPqjlPpYKbVXKbVLKfVL13P+y/ebHFBKeZRSqaGeY2kHtNb2z/75/QHbgFkBx/4AVAFzkMlEL+BYYDpicY4C8oBbfO17ABoY4fv8v0AxkA3EAP8A/rcFbQcBZcD5vnN3ANXA1SG+Szh9fAvoC4wA9prvDtwCrAOGAsnAp/K/TNDnjALKgT6ue+8Bsn2f5/jaKOB04BAw2XduFrDNda8C4FTf+weApUASkA6sD2h7KZDi+ze5wteHwb5z1wJLA/r5v8B83/vZvj5OAeKAvwD/Due3aebv3BfYDdwG9AQSgWm+c78GVgNH+77DFKD/kf5/oDv/WUvB0hw+11ov1lrXaa0Paa2/1lp/pbWu0VpvAZ4BTmnk+te01h6tdTWwEBkAmtv2XGCV1vot37mHEQEJSph9/KPWer/WehsyAJtnXQo8rLUu0FqXAH9q5DlbgG8RsQI4A9intfb4zi/WWm/Rwr+BT4CgweQALgX+oLUu1VrnI7N/93Nf1VoX+v5N/o4IenYY9wW4EnhOa71Ka10J3AWcopQa6moT6rfxo4nf+Txgh9b6Ua31Ya31Aa31Ct+5a4G7tdYbfd9hldZ6b5j9t0QAKwqW5rDD/UEpNU4p9a7PHXAAuBcY0Mj1u1zvK2g8uByqbaq7H1prjcysgxJmH8N6FpDfSH8B/g7M9b2/AhEz049zlVJf+dwn+5BZemO/lSGlsT4opa5WSq32uW32AePCvC/I96u/n9b6AFAKpLnahPVv1sTvPAzYFKIPw4DNYfbX0g5YUbA0h8B0zKeR2fForXUi8FvEPRJJChF3DgBKKYX/IBZIa/pYiAxahqZSZv8BzPLNtM9HRAKlVC/gNeCPiGunH/CvMPuxK1QflFKjgL8CNwHJvvtucN23qfRZL+KSMvdLQNxUO8PoVyCN/c47gKNCXNfYOcsRwIqCpTUkAPuBg0qpY4Ab2uGZ7wCZSqk5SqkeiJ96YIT6+Cpwu1IqTSmVDPyqscZa693A58CLQK7WeqPvVE8gFigCapVS5wIzm9GHu5VS/ZSs47jFdS4eGfiLEH28FrEUDLuBoe6AbwCvAD9WSk1WSvVEROszrXVIy6sRGvud3waGK6VuUUrFKqUSlVLTfOeeA/6glDpKCVOUUv1b8HxLG2FFwdIa7gSuQgK/TyMz5YjiG3gvAx4CSpBZ5jfIuoq27uNfEd//WuBrZLbfFH9HAsd/d/V5H/Az4A0kWHsJIm7hcA9isWwD3gdect13DfAYsMLXZhzwlevaj4CNwG6llNsNZK7/AHHzvOG7fjgSZ2gJIX9nrfV+JMZyMRLYzsOJN/wZeBP5nQ8gsYi4FvbB0gYocclaLJ0TpVQ04ga5RGv92ZHuj8XS2bGWgqXToZQ6SynV1+fy+C+gBpktWyyWVmJFwdIZmQFsQVJRzwIu0FqHch9ZLJZmYN1HFovFYqnHWgoWi8ViqafTFcQbMGCAHjFixJHuhsVisXQqcnJyirXWjaVvA51QFEaMGIHH4znS3bBYLJZOhVKqqRX5gHUfWSwWi8VFREXBlzqY6yu9e1eQ8+lKqU+UUmuUUksDCnFZLBaLpZ2JmCj4FhU9CZwNjAfmKqXGBzR7AHhJaz0ZWVn5x0j1x2KxWCxNE8mYwjRgk6+MLr4NSM5H6sEbxiPL/wGWIMvdm011dTUFBQVUVla2oruWSBMXF8fQoUOJiQlVisdisRxpIikKafiX/C1ANuFwsxqph/IocCGQoJRK9tWur0cpdT1wPcDw4Q0LVRYUFJCQkMCIESOQopmWjobWmpKSEgoKChg5cmTTF1gsliNCJGMKwUbnwJVyP0c29fgGKZC1EylZ4H+R1s9orbO11tkDBzbMqKqsrCQ5OdkKQgdGKUVycrK15iyWDk4kLYUC/OvAD0UKl9WjtfYCFwEopeKBi30VFZuNFYSOj/03slg6PpG0FL4GjlZKjVRKxQKXI3XV61FKDVBKmT78Gnghgv2xWCyWtmPPHvjnP490L9qciImC1roG2RDkQ+A74FWt9Tql1L1KqfN8zU4FcpVSecBg4L5I9SeSlJSUMGXKFKZMmcKQIUNIS0ur/1xVVRXWPa655hpyc3MbbfPkk0+ycOHCRttYLJZ24oUX4NJLYVeDrSo6NRFd0ay1fg94L+DYb13vXyO8jUs6NMnJyaxatQqA+fPnEx8fz89//nO/NlprtNZERQXX4RdffLHJ59x8882t76zFYmkbjBjk5cGQIUe2L22IXdEcQTZt2sTEiRO58cYbyczMpLCwkOuvv57s7GwmTJjAvffeW992xowZrFq1ipqaGvr168ddd91FRkYGxx9/PHv27AFg3rx5PPLII/Xt77rrLqZNm8bYsWP58ssvATh48CAXX3wxGRkZzJ07l+zs7HrBcnPPPfdw7LHH1vfPVMvNy8vj9NNPJyMjg8zMTLZt2wbA/fffz6RJk8jIyOA3v/lNJH82i6Vz4Pv/kiYs/Aa89hq8E+7Gez4OHYILL4R//at517WATlf7qEluvx2CDIKtYsoU8A3GzWX9+vW8+OKLPPXUUwD86U9/on///tTU1HDaaadxySWXMH68/5q+/fv3c8opp/CnP/2JO+64gxdeeIG77mqwIBytNStWrODtt9/m3nvv5YMPPuDxxx9nyJAhvP7666xevZrMzMyg/brtttv43e9+h9aaK664gg8++ICzzz6buXPnMn/+fObMmUNlZSV1dXUsXryY999/nxUrVtCrVy/27t3bot/CYulSGFHIy2vedb/5jVgW554b/jXbt8Obb8JFFzXvWS3AWgoR5qijjuLYY4+t//zKK6+QmZlJZmYm3333HevXr29wTa9evTj77LMByMrKqp+tB3KR7z8Qd5vPP/+cyy+/HICMjAwmTJgQ9NpPPvmEadOmkZGRwbJly1i3bh2lpaUUFxczZ84cQBab9e7dm48//pgf/ehH9OrVC4D+/e2+6hZLiyyF6mrYsgX2NzPJMt9Xyy49vXnXtYCuZym0cEYfKfr06VP/fuPGjTz66KOsWLGCfv368YMf/CBo3n5sbGz9++joaGpqGizdAKBnz54N2oSzaVJFRQW33HILK1euJC0tjXnz5tX3I1jaqNbappNaLIEEsxQ2boQf/hAqK+GUU+DRR/2v2boVampg377mPWv7dnkNsni3rbGWQjty4MABEhISSExMpLCwkA8//LDNnzFjxgxeffVVANauXRvUEjl06BBRUVEMGDCAsrIyXn/9dQCSkpIYMGAAixcvBmRRYEVFBbNnz+b555/n0KFDANZ9ZLHU1UFREURFwebNYgGA+Py/+koG/b/9reF1RkBaYilERUFaWuv6HQZWFNqRzMxMxo8fz8SJE7nuuus48cQT2/wZP/3pT9m5cyeTJ0/mwQcfZOLEifTt29evTXJyMldddRUTJ07kwgsvZPp0p/rIwoULefDBB5k8eTIzZsygqKiIc889l7POOovs7GymTJnCww8/3Ob9tlg6FXv3ijBMmSIzf+PizcuD+Hj48Y9l4D8csHW4EYUDB+T6cMnPF0Foj7phJlWys/xlZWXpQNavX9/gWHelurpaHzp0SGutdV5enh4xYoSurq4+wr1ysP9WlnZn/nytzztP69rahucuuUTruDitExO1/vTTpu91ySVaP/CA1uvWaQ1a33abvC5eLOfPPFPrzEytn35aju/Y4X/99dfLcdB6//7gz9i0SeuRI7X+8kvn2CmnaD1jRlhfNxSAR4cxxlpLoYtRXl7OiSeeSEZGBhdffDFPP/00PXp0vdCRxRI2n3wCb78NL7/sf7yuDt57DzIyZOa+bFnj9ykvh//7P0knNfGEGTPk1VgAeXkwZgwMGiSfTTuDO/4QyoX0j39I7OGGG8QKAbEU2iHIDNZ91OXo168fOTk5rF69mjVr1jB79uwj3SVLV0RrCaYGo66uodtEawi2ur+iou37FojXV3LtF7/wD/B6vfL8q66CoUObTi1dtUq+W16eM9gfcwz07y8ZSJWV4kYaOza0KOTmQkKCvHeLQm2t83suXgx9+8LatfDkk3KuoKBdgsxgRcFisbSEl16CwYPh4MGG5373O5g82d9n/vLL4hN3i8XLL0NSUvPz/JuD1lBYCDNnQnGxDLIGk0o6dqz8NZVampMjr16vBJdBBv9x4+Dbb+WY1qEthbIy6Ut2tnx2C9TNN8tvlp8vgeqf/QzOPBPuucfJWLKWgsVi6bAsXCgul927G55bs0YGejOIgsyyi4slYwegtBTuuEOshzfeiFw/DxwQa+Dss2WmvWGDc86I0Zgx8peXJ4N6KNzf54svJBuof3847TQZyJcvl3OhLAXzvGnT5NVYCjU18Oqrks46Z470Yc4cuPVWaWOymKwoWCyWdqe0NPhA7+bAAVi61GkfiHHX+FKbAZkhA5T49s+aN08yeNLS/NsFsnu3iEkwtm5t2v1k+pKaKoOqWQQGMkj37i19GDtWZu5GtILh8cCIEfL+iy9gwACIjpaVybW1zpqEo48WF1HPno4ofPWVrEgGRxSMpfDll/I7pqeLyygtDaZOhdNPl/4984y0s6JgsVjanVtugQsuaLzNv/7l5OUHEwUjAO76PmZwLimRgfypp+C66yR18z//CT3wn3OOLAYLxvTp4Fu9HxLTl5SUhqKQmysWglLyCqFdWeXlYmVcdpm037fPsQamTZP3a9fKcxITpc2gQSIKa9bAccfBH/4gg7wpPWMshXfekVTTDz+Uay+6SK6Pi4MzznCExcYUOg+nnnpqg4VojzzyCD/5yU8avS4+Ph4Ar9fLJZdcEvLeHo+n0fs88sgjVLhmTOeccw77mrti0mIBKcEQZMGjH+6ZfaAo1NXJQJyQAN98IwFS8BeF3bul3fHHi5vEZAEFkp8PK1eKaAS6dcrKZFa/eHHjlkagpbBzp5PRk5cnFgI4r6HiCqtWSR9mzHAGZyMKUVHwve/JeyMu5vyePSIWAIsWSezBVFQ1orB4MZx6qvRhwwb47/927uErOUNyMriqI0QSKwptwNy5c1m0aJHfsUWLFjF37tywrk9NTeW111peQTxQFN577z369evX4vtZujF79oh7KNSkorZWBvBTT5XPgaJQUiKD7pVXyud33nGCvSAWgZn5Dhoks+aUlOADuzm2f78T2DWY+0VFie/98cedP3dbIwopKTKY19bKscOHxf1kBvH0dJmt5+XBunUNi2qaiVlWliMgRhTAGbyDiUJurvTzggtg5EixAGJj5TfetEmEwFyfkgK+GmOAIzbt5DoCKwptwiWXXMI777zDYV9mxbZt2/B6vcyYMYPy8nJmzpxJZmYmkyZN4q233mpw/bZt25g4cSIgJSguv/xyJk+ezGWXXVZfWgLgpptuqi+7fc899wDw2GOP4fV6Oe200zjttNMAGDFiBMU+c/yhhx5i4sSJTJw4sb7s9rZt2zjmmGO47rrrmDBhArNnz/Z7jmHx4sVMnz6dqVOnMmvWLHb7fM3l5eVcc801TJo0icmTJ9eXyfjggw/IzMwkIyODmTNntslva2lnzIBtau0EsnGjDOyXXiqfA0XBDMIzZ8KwYRJ7KCtzspRKSvxFISpKfPIfftgwZXXxYmd27A7yup8zb57c79Zbnb/TT3eeV1goK4wTEpyBNT9fLKK6OmcQj46G0aNl8J892xE1ECH5299g1CgZtM017v3izzhDLICTTnKOGVHIyxMx8NUqAyTldP9++Owz+RwqdXzIEMlCclUdiDRdblXT7R/czqpdbVs6e8qQKTxyVuhCe8nJyUybNo0PPviA888/n0WLFnHZZZehlCIuLo433niDxMREiouLOe644zjvvPNCFpj761//Su/evVmzZg1r1qzxK31933330b9/f2pra5k5cyZr1qzh1ltv5aGHHmLJkiUMGDDA7145OTm8+OKLfPXVV2itmT59OqeccgpJSUls3LiRV155hWeffZZLL72U119/nR/84Ad+18+YMYPly5ejlOK5555jwYIFPPjgg/z+97+nb9++rPWZxaWlpRQVFXHdddfx6aefMnLkSFsfqTNSUSG+c5CBc/Lkhm127pTXY46RmXUoUUhNhQkTZEA0s3rwFwUzqM6ZA88+C59+CrNmybGyMhGUG2+U+IPHI/78wOdcfjn88pdOjv/KlTLA3n8/3HeftEtNlXNuUTABbzPrN+9NMLiwUPqQkCDPX7VKFpW5r3FbCvHx8iz3/9eDBomLy8Qu3PTrJ5bCtm1yzahRhOT99/3vG2GspdBGuF1IbteR1pq7776byZMnM2vWLHbu3Fk/4w7Gp59+Wj84T548mcmu/zFfffVVMjMzmTp1KuvWrQta7M7N559/zoUXXkifPn2Ij4/noosu4jPfzGTkyJFMmTIFCF2eu6CggDPPPJNJkybx5z//mXXr1gHw8ccf++0Cl5SUxPLlyzn55JMZOXIkYMtrd2jy8mSdQSDuzBt3QNaNGeBTU2WNQaAouM+PHSvPMkICwUVh5kxxqbhdSP/6l1gOF10k4hRoKbgDyH36iM89OVlm7D/8Ifz5z2LVeL3SBpxYQH6+fzqqwbwfO1ZcXiaNdt486eP3v+/fzi0K0HDgHjRIxGrdOn/xAcdS2L5dfqvGahq1c4XiLmcpNDajjyQXXHABd9xxBytXruTQoUP1M/yFCxdSVFRETk4OMTExjBgxImi5bDfBrIitW7fywAMP8PXXX5OUlMTVV1/d5H10IznXPV2mbHR0dFD30U9/+lPuuOMOzjvvPJYuXcr8+fPr7xvYx2DHLB2UZ56BBx+ESy6RbBiDO6c+lPvI7aMPJgrm/JAhMngePOgM6PHxjigkJDi+8969xUJYvFhK3ysllkFMDJx4ovjxFy2Sgdr8N+b1yvUBxR4BWLAAXnkFnn9e2hnXS69eIkTbt0uwOz3d//qzzhLr5PnnYdIk6feqVTKjf/hh59nHHit/TRW0NKJRXd3QUjCicPhwu8YLwsFaCm1EfHw8p556Kj/60Y/8Asz79+9n0KBBxMTEsGTJEvJDzcB8nHzyySxcuBCAb7/9ljVr1gBSdrtPnz707duX3bt38/7779dfk5CQQFlZWdB7vfnmm1RUVHDw4EHeeOMNTnL7PJtg//79pPlK9f7NVQZ49uzZPPHEE/WfS0tLOf7441m2bBlbt24FbHntDo0ZyDdt8j/uFoVQ/516vTKgJySIKAT+OxcWyoKuuDhndmzWNEyc6ASaA2fZc+ZI4NdYv2aG36OHrAAODDYXFsoMO9hEZMgQOPlkERnTzpCeLu6cjz5ygrgGswht4kS5xuORe4wbJyJhSEqCFSvEPdYY7u8Yyn3UjjWNwsWKQhsyd+5cVq9eXb/zGcCVV16Jx+MhOzubhQsXMm7cuEbvcdNNN1FeXs7kyZNZsGAB03wLXTIyMpg6dSoTJkzgRz/6kV/Z7euvv56zzz67PtBsyMzM5Oqrr2batGlMnz6da6+9lqlTp4b9febPn8/3v/99TjrpJL94xbx58ygtLWXixIlkZGSwZMkSBg4cyDPPPMNFF11ERkYGl7n9v5bQfPKJfwpie2BSIXNzxUVz003iajGiMHq0vygsWSLlFkAGWeOO6d9fBEZruPNOGVDd7hozEH72mVgDI0c6lkKgKJgB2riQ3M/JypJXtwvJ/ZxgzJkjAnPokH+79HSJXVRUOBk/wcjKkn4vXdq8bTPduL9jMPdRaSns2NFu6w/CJpxSqh3pz5bO7tzYf6sArrpK67592/eZM2dK6eY//EHKM4PW99+v9Z/+JO8vv1zrIUOc9hdfrLVSWldUSPnmU0+V41deKSWei4vluosv1nraNK3POEPO19Zq3bu3nBs9WutbbtG6Xz+tJ0/W+vzzG/brqKO0vuwyeT9hgtYXXijvDx/WOjZW65//3Gl79NFaX3pp6O+4aZNTovrvf3eO33GHHOvTR2tfifmg/O53zvXLloVu1xg7dsj1vXs3LNtt+gFa/+UvLbt/M8GWzrZYOgHl5TJzr61tv2e6LQUz+zaVP/v0kcyiXbuc4nU5OTJ8bd7sn81jYgrGqvjwQydwCpJuevTR8j41VQLB+/bJPQItBZBZvIlluJ8TGyvlrd2WQqBbKJCjjpLvAf6WgpmVz54tLq5QGOskKQlOOCF0u8YwgfQxY+S3cOOOZVj3kcXSDfjpT+Hpp5tuZ2JBoWrrHzggefeffNJ2fTPPystzFmXl5jpuHTNI7dgh7h6TmZab6+/WSUqSe/niSJSXi5i4B2HjNklJkVpBIHGFUKKQny8ZO6Wl/vfJypJ0U63lNysvb9x9BI57KDCm4D4XCiMK55wjcY2W0LOnDP6B8QTwF4UO5j7qMtlH2ma/dHh0YxUouxovvSTZKTfc0Hg7IwqlpeKjD2T+fPHpH3uspEW2BWa1cm6us8grL0+Cx4MG+adubtniXLdihfjo3ZaC1k4Zhx49ZDWzexA2A6KxFAzBRGH4cBEdY3m475OVJesFNm92SnI3ZikA3HabDL7GWgFJWb3nHmfxXSiGDJECd2ec0Xi7pnjiCQlUB+KuONDBLIUuIQpxcXGUlJSQnJxshaGDorWmpKSEuMZM9q7Cvn0ywzfpmY3hFoVA1q6Fxx6T901krYWN1jK7791b+rlvnwzuJSXw3Xey57AZpLZvl5k/yCBmsojclgJI2mavXiJa77zjP4M3opCS0rQopKdL/1as8H8OOHsQeDxO7aCmRCE1Fe6+2/9Ynz4itOFw663htWuMgAWh9RhLISnJ2XSng9AlRGHo0KEUFBRQ1FjZW8sRJy4ujqFDhx7pbkQeM4C7V/KGwohCsBTee+6RwSOwumdrqKyUjKNp0+Dzz+XYxRfDc8+Ju2j2bNmFLCpKCtp5veKfHzbMKcngthQAVq+WPp53noiC+9/Y+PWHDQtPFMDZl8A96E+YIO6YnBwpKw1Nu486MkYUOpiVAF1EFGJiYupX0losRxwTLN2zRxYuNbZatTFLYf16iSfEx0sQty0w8QS3KFxxhYgCSHA0NlZmuE89JbPYWbP8LYVAUdi2TerzXHWVtHfX6cnKkg1kzjvPsTogtPsIgotCTIyzsjlcS6EjY9xHHSyeADbQbLG0Pe5ZfVMb1phaQ6E2qzElnwsLG+57bKipcWr5GNyVSUHOV1U5opCRIQPt4MFSDtoEU81gvWCBuIT27hXXjTvP3r1OwZCeLmJy+eX+C8qUkvIQPXs2bSkMGyavq1dL39ztwQk2r14tfUtMDP57dAY6sKVgRcFiaWvcotBYXKGqyqkMGigK5eViRRhRAGdvgkAeeUR89+601oULxY3zxRciDqNHS5E4E2ROTpaVu8cfLwOwKchmBuvBg2VTGJANYkxsICFBLBdwLAUIb3Dr00eEQ6mGAz6IcKSkyPdISWm4Wvm440TUXn5ZFsJ15vjhgAHyWzSxmPVI0CXcRxZLh2L7dhmwtG5cFNylSUIVlktJcXz0+fni3w9k6VKZ0ZeUOIP6a69Jls7NN4tff98+yTYyOfd9+8Jbbzm5+qZ4nXsGf8stIhpZWU5JDLfLxi0K4bhBjBhUV0up6mAYqyiYa+iKK8R1dPgwjB/f9PM6MomJErMZPfpI96QBVhQslrYmP18GrXXr/F04BQUyCzaz6nBEITXVP0U0GGZRl1lnUFkptX2OOUZcLatXO/c0lkK/fo67BoJX/lTKyfoZMUJcTO7gbq9eMtutqgrfDTJgQOML9YYPl5hCsCByTIzELroKHVTYrPvIYmlr8vNlMI2K8rcUrrsO3LvxNSYK7n0JzOAdrHKp1+sEcE3ton//W2r7PPSQ1O0ZM0YWa3m9TkwhsLroccdJmmqoGX9MjHwnd2E4pRxrIVxROOaYxgvJmft05iByJ8daChZLW3L4sAzSo0aJq8MtClu3ymdTAjocUUhJcXztwSwF9/7dJiXb7Fh26qmy+KqqSvL1lyxxRCFwu9aLL5ZZeGM58//+d8PVvUlJskI53EH85ZcbP29F4YhjRcHSvSgokMVRF13kHCsrE//6lVe2LHj5yivir09OlhRSkMEtJcXffWR28zKlIEzmkak26qawUPz9ZvAOtVbBXQ9ozx4RnHfe8a/t06uX87yCArFgTLDYoFTTi6jcewcbkpIgLS38UhCxsY2fN5ZKZ16D0MmJqCgopc4CHgWigee01n8KOD8c+BvQz9fmLq31e5Hsk6Wb89vfwv/8j6w4NgPjP/8JP/6xLIpqqkZ+IFVVktNvSi+ccoq8Dh8us10zcor9AAAgAElEQVTj8ikvl2eCBHRTUhxLYfjw4JaCOwMnPd3fKjDk5IhLxtQuKiiQv1//2r+dmXl/950EOdsqc+ekk4Kn07aUrCz5PXwl4y3tT8RiCkqpaOBJ4GxgPDBXKRUYWZkHvKq1ngpcDvwlUv2xWKirg3ffldn0xo3OcbOaODe3+ffctUvu+8wzEi9YtkyOp6fLQGzcQG6LwWwFaURh2LDgloLbhTJ8uKw4NuID8j08HhlABw4UUTDWRGCWklsUAl1HreG//1u+e1uRmirfobnibGkzIhlongZs0lpv0VpXAYuA8wPaaMCsQOkLhFEsxmJpIStWOMFYMzCDfynpUPz97/Dxxw2Pu7OEHnhArA+lJI00JUX8/NXV/qJgnuO2FALLZ7tLR4OITFWVE1ResEAWhe3eLbPrQYP8RSEw8GvcMTt2BN/C0mLxEUlRSAN2uD4X+I65mQ/8QClVALwH/DTYjZRS1yulPEopj61vZGkxixc7+fFuATBpmm6hCOSuu2Rf40DcWUKpqfCXv0i5h9hYZ1DftctpFxfX0FIwfnTTD3Nft1994kR5Xb5cBv+77pKFaVOmwNlnNxQFd7qp6Z/BioKlESIpCsGcloG1k+cC/6O1HgqcA7yslGrQJ631M1rrbK119kCzcYXF0lwWL5aSDsOHN89SqK6GnTud7B437iwhgB/+EF580f+Y1+tYCiec4G8p9Ojh1PIxLiT3ambDCSfIYL54Mbz3nriO3n3XWQDlFoUBAyT7yE1ioqScQtu6jyxdjkiKQgHgnq4MpaF76MfAqwBa6/8AccAALJa2ZscOKUU9Z46s3nULgHvTGUNREZx/vgy0Xq/48t0b2xsKC8X6CDZZMYO61yt/cXFSLG7LFhGa8nLJ+DG5/kYU3C4pQ0yMWATvviuZUmlpTrVQ8BeFYGsGlHJEyloKlkaIpCh8DRytlBqplIpFAslvB7TZDswEUEodg4iC9Q9Z2h4z4Gdny2KuvDyZbYPjtikpcQrLffklvP225OYbl4xJ+XTj9cpMP1jZBlPCYP16xx00dqwUsNu6VayBxkQhMC1zzhwRq7fekkVp7gyiQYMkuykvL/RCMiMy1lKwNELEREFrXQPcAnwIfIdkGa1TSt2rlDrP1+xO4Dql1GrgFeBq3a2257K0G2awT06WgfnAAWfmv3+/LBADRzzMwJyb64jC4cP+C85Mu1A59YmJsutXTo6TTWTKSeTlyb3i4xuKgjtO4ebss0V8tG64naQpT7F1a2hRsJaCJQwiuk7Bt+bgvYBjv3W9Xw+cGMk+WCyAIwoDBjgDc26uVAPdv19cMcuXy2B9/PHOwJyX528F7NnjX7LZ65W6QKHIypKAcO/eUiLClKDOzXUsBVOCOlAUAsUmKUliIitWOIvkDO6aRaFKVRiRsaJgaQRb+8jSPTCi0L+//2wdxH00daoEfU2swQzMubn+NYcC4wqBqaOBZGdLPGPLFmnXv79YK8ZSCOY+2rRJXDzB3DyPPAKLFjVcXewWBes+srQCW+bC0jWpqvIvqVBcLANwbKzMpHv2lAG/rk5cScnJUq8omPsoOVnaHz7sLwpVVXLfxkoyZGXJa3W1MyibQHdZmVwbFyd/RhTy8kS4gq06njJF/gIJRxSs+8gSBtZSsHQ9li2TgS9w5zGzsUt0tASBN26UDKC6Opk9u7OSjKVQXg5ff+0MxG5RMAvJGrMU3BlCZlA2gW6TfQRiQZiU17w8/53OwiEcUTBurmC7nlksPqwoWLoe69bJngLr1jnH3KIAsrhr507/UtJjxohQ1NWJoJhBtLTU2VfALQqhAsJu+vaVYLO73dixcv/du536S+PHw5o1cPCguJuMiytc+vQRl1Lv3v7bZLo58UTZZ+Hkk5t3b0u3woqCpeth4gfuqqIlJRJkNpi6RO5S0mPHiotoyxYZ/E891Wk/ZowM8Hv2iCsoLy906mggxoXkthRAhMtYCllZso7CCFlzLQWlxAJITw9d7E4pmDWrc29jaYk4VhQsXY9golBc7G8ppKSI+8cUwzOWAsBnn0na57RpTvnp9HRngdiLL8qg/eqrcq6p2v8nnyyzeFN6wj3gG1HIzhaxef11+dxcSwHEJWbKYVgsLcQGmi1dj1CWglsUUlPFTWSqpfbt66RyLl0qr2lp4vpZu1bOGVH48ks5v2hR6NXMbq6/XtYVmFTWo45y9nB2WwogezNAy/bufe012SvBYmkF9r8gS9uxe7fk5Bvefx8OHfJvs3SpM2i3Bq3hzTclAyiQ4mJ5NamkNTXiJgq0FEBKSYO4jwYPlkF6yRI55l5s5rYUPB5HCIYMaXogjo6WqqmGuDgnXmFEYcQISU3dsUMsisDaReHQr5//GgqLpQVYUbC0HQsWyKKqykop7XDOOfDSS875mhrZEWzevNY/6+OP4cILZcOcQAItBeMiCowpgPQTxFJQSlw7O3Y4bU4+WayFpCQRhe3bRUhuugkuuMA/u6g5GLExgWalHGuhJa4ji6WNsKJgaTu2b5eZ+9q1suoWnJk4yCKx6mqp9NnaaiZvv+3/6saIwo4dskeBsRwC3Ufu/pncfTMgm8DtrbdKUNl8LisTt1NWlvj/gz0/HExcwb0Fpslwam6Q2WJpQ6woWNoOk43j8Th7B7srj5rFWTt3SsnnYOTnw8MPy8CrNTz9tGQDudFahAXgk0+gosL/fEmJBHZraqRP7rpHhsGDnef17OkElM2APHhww32H3fn9WVniNmppJo8RH7coWEvB0gGwomBpO0zefk6OIwruEtXuLSfNoB7IAw/AHXeI2+kf/4Abb4TLLvPflezbb2Uw//73xVXl3hGtulriBxkZ8nn79uCiEBsrcQGt/Vf4mgE5WEaREYXBg5vOOGqKWbMgMxPGjXOOnXKKHJs1q3X3tlhagRUFS9ugtWMpfPUVrFolAdZt2yT3HxxR6N07uCi4LYBf/lLEITlZLI/nn3favfOOvC5YIDNt8xmc+EFmprzm5wcXBQheC8iIQrC1B0YUsrNbn+s/dqwIp7tPAwfKMbs/seUIYkXB0jw2bYIbbpAZuZt9+5zFWN9+K1lHs2eLG2jzZmljROGii2TwM5aFwVgAN98sA/muXbKpzMknw69/LbEBk3WUlSUZO2eeKamhs2fDCy84AmACwPn5TkxhQMD+TcFqAYVjKRg3j8XSBbGiYGkeTz4JzzzjH0AGZ4A/80zn2BVXyKuJKxhRuPBCeV250v8exkr4zW/gscdkT+Tp0+WZ+/fD3XdLYHfFCtkHGSQQnJEh93r0UUcURoyQcg/GUujZ09mO0hCslHR8PPz853D55Q2/++jRst2m+V4WSxfELl6zhI/bvZOfD5MnO+eM62jOHFlEFR8P3/ueHDNxBSMKxx3nHD/3XOceixeLayYlRawFw8SJcNttEoB+6y35fOONcu6kk2QF8h13wFNPOUXlkpNlwdn27bKWIDm5ocvHWAqBpaT//Ofg3z821j/F1mJpAW9teIv3N73fomuvmHQFJ6dHtnaVFQVLQ4qKxMXz9787pRkANmxwXEHu1cLgWArHHScD8IQJkts/eLC/pRAXJzN0s6eAobhYYhHz5wfv0z33SH927YJ//lP2LHYzdqy4rFavls/JybLg7NtvJYsoMJ4AdtMZyxHhzn/dibfMS2LP5i80PH7o8VYULEeAnBz4/HN5dYuCsRKio/03ngH/zeaffNJJ+TRlokFEwWwo4y5TDVJuQmsnVz+QxESJJXz7bfAqnyYWYEpQJCfL4rK33oKCAtlNLRArCpZ2pvRQKZtLN/PHmX/krhl3HenuBMXGFCwNMeWhy8vlVWuZhb/9tuwrMGpUcEshIUHcRpdd5lQYdQ/+blFwiwX4i0oopk+HH/84+DmzvuCrr5z4wf/7f2K5HD7cMMgMod1HFkuEWFkocbSslI6brGBFwdIQIwpmk/rvf18G2S++kJhBenpwUQg2oI8ZI+6offsaikJhoex6Zq6Hluf/p6RIvaCyMhEApWRx2ZNPymuwjWVMPaJgriWLJQJ4vB4AslKtKFg6E4GisHatZPg88IAEfIOJQmFh8AF95Eh53bZNRMFsAGNm9qZKqdcrvv9gM/pwUMpxIbkH+cxMKcz3i180vCYtTVxSP/hBy55psTQTT6GHkf1G0r9XiI2QOgBWFCwNCRSFAwdkb4E773QCuLt2OYvSQAb1YAu+zNaQ+fkNLQVwXEuFheFVHG0MIzSBM//Zs52qpIGcf76tLGppN3K8OWSnhoibdRCsKFgaEkwU3AOn2XfAVBM1q5mDWQqhRGH0aJndm7hCKPdTcwhmKVgsHYSSihK27tvaoeMJYLOPLMFwi0JNjRScc4uCe6AfPdpZzRzMUhg4UNJQt2wRcTGiEBcn93GLQks2lnETylLopFTXVrP74G56RPVgcJ/BqHbcRvNg1UFKK0ubbtgEqQmpRKkotNbsKt9Fra5lcJ/BxERLSnHRwSIO1x5u4i5dg8+3fw7Q4S0FKwpdleJiqQPUkoqb7uwjYy2EEgVoPEislFgWa9bIZyMKIH1zu49OOqn5fXVjvmtL4xIdjEv+eQlv50pp7ufmPMePM0NkXrUxNXU1jH58NLvKd7X6Xj877mc8dOZDPLfyOa5/53oALhh3AW9c9gYfb/mYM14+o9XP6ExEqSgyUzKPdDcaxYpCV2XePPjgAwnwNget/S0Fkx3kFoWhQ2WwN2sV/vUveT3qqOD3TE+XonbgLwrjxsFzz4klUlLSevfRuHGy5qAL7EdQp+tYsnUJZ4w6g9W7V7Nk25J2E4UNxRvYVb6LG7NubFWWzJNfP8mSbbKL3b+3/ZvBfQYzafAklm5bitaaJVuX0COqB3855y/tagUdSUb0G0FSr6SmGx5BrCh0VbZskUG7pqbhvgCNUV7uBJBDiUJMjAzg+fkyw58/H846K/TCs/R0+Ogjee8WhalTRRCWLZPPwdxPzSE+XhaqBdY46oRs2ruJsqoyLp94Ob1jepNTmNNuz87xyrNunX4rxww8psX32Vq6lQVfLqCyppIcbw4nDDuBc44+h4+3fMyW0i3kFOYwcdBErsu6rq26bmkDbKC5q1JY6D/rDxd3+1CiADLQf/45XHmlxBMeeyx0OWnjbgJ/UTAiYlZKt9ZSABGGLrB5fX0+e0oWWSlZ5BbncuDwgXZ7dp+YPoxJbt1mP1mpWdTU1fBZ/mds3Lux/rsAfO39Go/X0+GDrt2Rzv9/jyU4xs8fWJ66KYwo9O/fuCicfLKU0V62DO67T/YxDkUoURg3TnZIM/shtIUodBFyvDnE9Yhj/MDxZKdmo9F8Uxhit7q2fnZhDpkpmURHRbfqPiag+uzKZ+s/Txg0gZ7RPfm/7/6PkkMlHT7o2h2xotAVqax0NptpqSgcdZSIQrBAM8Af/yh7JdTUSKnpxjAprOAvCj16SNkMk9raWvdRF8JT6CFjcAYx0TH1fv32cCHV1NWwateqNpnBD0scxoDeA3hjwxuAWA6x0bFMHjzZOWYthQ6HFYWuyC5X1oipKRQugaIQylIAcReFEyAMZSmA40JqzWrmLkadrmNl4cr6WfSgPoMYljis3qUUSb4r+o5DNYfaZAavlCI7NZuauhrS+6YzoLf8+5pjMVExTB48uYm7WNobKwpdEbd10FJLYdQof4ujNat+09LEzx8XJ39uzC5mKSldIhbQFuSV5FFeVe43MGenZreLKJhntJVbJzslu8H9zPtJgyfRs0fPNnmOpe2w2UftwEebP2Lh2oX1n+Nj4/nvWf9Nn9g+kXmgWwhaYin07evM2s294uNb3p+YGBGGmpqG59yi0Eq01tyz9B6279/edOMOTMGBAsDftZKVksUbG97gqjevQhG59M2VhStJiE3g6ORGYkTNwLi+Ar9L4DFLx6FJUVBK3QIs1Fq3fnljN+WB/zzAsm3LGBI/hMO1h9lVvosLxl3ArFGzWnfjr7+Gxx+HF1+UPQ4MRgiGDm2ZpTBokCMCO3dKSezWzuLT0x2rw824cZJC2gZB5o17N/L7T3/PwN4D6R3TudNSTx1xql866Jyxc3hpzUss27Ys4s++Zso1RKm2sdpOST+Fk4afxAXjLqg/NmHQBM45+hwum3BZmzzD0raEYykMAb5WSq0EXgA+1FrryHara+Et83LW6LN48/I3+XbPt0z66yRKD7WBxr77Lrz8slQAnTTJ9UBfxdFJk1ouCgkJ8nnnzrYpGHfnnU58wk2PHrBgQePZS2Fi8us/+uFHZAzJaPX9OhKTB08m95bcpht2MJJ6JfHpNZ/6HesR1YN3r3j3CPXI0hRNTge01vOAo4HngauBjUqp+5VSIZavOiilzlJK5SqlNimlGmwzpJR6WCm1yveXp5Ta14Lv0OHxlnlJTZCZcFKcBFr3Hgoya24uZpP6nICslMJCccekpbXMfRQJUbjgAtn0Jhg33yyVTFuJx+uhZ3RPxg8c3+p7WSzdlbBsRJ9lsMv3VwMkAa8ppRaEukYpFQ08CZwNjAfmKqX8/m/VWv9Maz1Faz0FeBz4vxZ9iw5MZU0lew/tdUTBt8S9LYqNhRQFU3E0NRV27w7uyw+GqXY6cKAjCoWFnaa0tKfQw5QhU+qLrVkslubTpCgopW5VSuUAC4AvgEla65uALODiRi6dBmzSWm/RWlcBi4DzG2k/F3gl7J53EkxRMSMKvXr0IjY6tm3cR0YUPAFZKWZvg5QUGeh37w7vfmvXyj2PPdYRherqTiEKJo3TBi8tltYRjqUwALhIa32m1vqfWutqAK11HXBuI9elATtcnwt8xxqglEoHRgL/DnH+eqWURynlKSoqCqPLHQdvmfj0jSgopejfq3/bWgqrV/tbA2ZvAxO8DXQh1dTIYG+oqpJXU27ie9/zzzbqBKIQLI3TYrE0n3BE4T2g3gGulEpQSk0H0Fp/18h1wfLmQgWoLwde01rXBjuptX5Ga52ttc4eOHBgGF3uOBhRSIl3Ui6T4pLaRhSKi6VMxKFD8J3vn8KsLXCLQmCw+cIL4cwzZUXySy9J+mlOjojCsceKhWEsBegUomCCzFYULJbWEU720V8BdwHwg0GOBaMAGOb6PBQIlQpzOXBzGH3pdARaCiBxhbYINOuSYvJnH0vtp5/C8vchrTcU7JCIz8Bo6HNY3m9fDXsnyEW1tfDNJ1BxCB6aB3/5K/Qog1uugI15qFtvY4SuI6oNRKG4opj9lftb/T3DYem2pfTq0atVVT0tFkt4oqDcKaha6zqlVDjXfQ0crZQaCexEBv4rGtxcqbHI0PWf8LrcufCWeYmJiiG5t7MbWFJcUr1YNInWsrl94GY5VVU8O/YgN0z9FKYC3l/B47+Sc7cBhb+GV33vS34Lj//WudZUKj74R7jKHMyDswAe5e5/9+G+0/8gJSy0bpEoFJYVkv5IOtV11U03biNOHHYiPaLsekyLpTWE83/QFqXUrYh1APATYEtTF2mta3wL3z4EooEXtNbrlFL3Ah6t9du+pnOBRV117UNheSEpCSl+i4H69+rPuqJ14d3go4/E1bN2LUyc6BwvKWFZOgyOSuTPa4aIs+438+DrFfD4E3DfH2DYcLjtNhg3Fm76iVz35Rfw1NNwww3w3LOSCjp3Ltx/P5SU8KeLBvHp9k9FEOLjpf5RC0RhecFyquuque/0+xiWOKzpC9qA44cd3y7PsVi6MuGIwo3AY8A8JCbwCXB9ODfXWr+HxCTcx34b8Hl+OPfqrHjLvH7xBPDFFMLNPvpc9nVl48YGouBJheN7j+WHsUfD8uWQ8UNYVgprgOnXS2rp8I/gn+/CE3Nlodj/rISNveD6J+DCe2DIEBGA5y6Eigo8K+/nuW+eo7auluiEhBaLgsfroUdUD3523M/oFdOr2ddbLJYjQziL1/ZorS/XWg/SWg/WWl+htW7mzi3dF/fCNUNSryT2H95PbV3QuLo/Jt00IIPowK588gZAdvJECSh7vc46g5gYZ/P6OXMk8Pyf/zj3mzpVBCIlxalympAAgweTlZpFRXUFuSW5TrC5BaJgdtWygmCxdC7CWacQp5S6WSn1F6XUC+avPTrXFQgqCr5Vzfsqm1jArbWzMC0gg2jlTt/OXKnZIgqVlbBvn7NGwdQqOvNMEYnFi31B5m+cInRBMNk7Hq+nxaKgtba7alksnZRwUlJfRuofnQksQ7KIyiLZqa7CoepD7KvcF9RSgDBWNe/c6ZSyDrAUPCVrAcgaeaJTYbSw0BEFQ2IinHKK7G6WlwcHDzYqCmOTx9Inpo+keLZQFPL359tdtSyWTko4MYXRWuvvK6XO11r/TSn1dyR4bGmCwnIZyANFoX+v/gAN4woFBfDww7Kw7KyznEVlsbENLIWcgxtJ3wcDh46BQl/ap9crwhCYqXTuuXD77fIHzsY2QYiOimZqylQ8hR6I97mgmikKds2AxdJ5CcdSMDmF+5RSE4G+wIiI9agLEWzhGjjuowaWwsKF8NBD8PzzcNFF8OqrUhL75JMbiIKnZjtZu6Nk8VqgpRBYhvqSS2DECCm1nZ0t5aobITslm1W7VlGT4NvvoZmi4PF6iImKYdKgSU03tlgsHYpwLIVnlFJJSPbR20A88F8R7VUXIdjCNXDcRw0WsOXnQ//+kn46bhy88oqUvz7qKCllATy54kk+2/4Zm6L28aMDfeU6IwpbtkBpacMNa9LSYOvWsPudlZpFxVcVbEiqZSJAYiK1dbX84qNf1Fs/higVxW3Tb2Na2jS+KviKR796lM+3f2531bJYOimNioJSKgo44Ntg51NgVLv0qouQWyz179P7pfsdr7cUAt1H+fmyyX1qKvzud3DHHeL/T02FoiJqKiv45ce/pFePXkyqSGDOgSFyXXy8+P9XrpTPrdywpj7YnFAmopCQwJrda3h4+cOkJaT57Ri3bd82olU0L134Eo+veJzXv3udEf1GcM2Ua1rVB4vFcmRoVBR8q5dvQdbGWpqJp9DD2OSxJPb0d7+EDDTn58Po0fL+llvEYrjqKlmjAGzI+5KK6gqe+t5T/PCmv8qOZYbUVCd9tZVbW45JHkN8bDw5Q3tz9e23Q0xM/d69S69eyuj+o+vbnvfKefXnPF4PZ40+i7cuf6tVz7dYLEeOcGIKHymlfq6UGqaU6m/+It6zLkCONydosDWuRxy9evTytxS0FlFI91kVMTHwwguSOeQb5HM2yQ5W2anZUiE12SmdUb9WwbxvBVEqisyUTDx4JfCNrDvo27MvRyX5762UlZLFhuINeMu85JXk1W/UbrFYOifhiMKPkGJ1nwI5vj9Po1dYKCwrZGfZTsnVf/JJ+NWv/M4n9fJVSr39dnjiCVljUF7uiIIb3yDv8XroE9OHMcljRBQGDHDauK2DNtjvuD7YXFdT/+ys1CyU8i9+m52ajUbzwjcvoNH1G7VbLJbOSTgrmkcG+bOxhSbIKXSlZb75ppSodpEUl8Teg8Xw1FNiEeTny4nhwxvezDfge/ZvIDMlk2iNrFIOtBTAfzVzK8hKzaKyppL1Res5XHOYNbvXBLUCjAg8u/JZ+WwXrFksnZoms4+UUkE31tVavxTsuEXI8eagUExNmSqz+l27ZNVxXBzgsxT27oTDh+Hbb+vjBkEthYEDqekRxarqHdyYcr5YFVr7D/7GUnCXrmgFxu2V482huraa6rrqoK6wIfFDSEtIY/v+7QxLHMbg+MGtfrbFYjlyhJOSeqzrfRwwE1gJWFFoBE+hh3EDxhEfG+/skFZQUB9ITopLYnvhKjleXQ3vvivvg4lCdDTrxyVTqYpkYC4uluPBLIU2cB0BjO4/moTYBDxeT33561CuoazULHbm7rSuI4ulCxCO++inrr/rkOr9sZHvWufGL8hsBnHjIkJWNRdV7mXdkCgORwNvvy1WRIid5XJGSxpodmq2iAvA0KFOAyMGrcw8MkSpKLJSs/iy4EuWbFtCUlwSI/uNDNrWuJVskNli6fyEE2gOpAI4uq070pXwlnkpLC8U/3plJVRUyAmXKAyJH4I3+iATb6zjlgtjZdHZ8OEhXT+eNEiojuLo5KOd+7itCiMGbWQpAExPm86qXatY9O0ipg+d3iDIbDD7GBw39Lg2e7bFYjkyhBNTWIyzt3IUMB67bqFR/Gr/GNcR+InCr6bdwbF3Psj88/uSN6wWqAruOjL37FtB5u4o2awnP1/EIy3NaZCaCj17wqi2ywH49Yxfc2zqsdTpukY3sJk5cib/+fF/mJ42vc2ebbFYjgzhxBQecL2vAfK11gUR6k+XwOP1EKWimDJkCmzY7JxwiULS1kIuXlPDa1eNwaM2yMEQolBdW82q2L3cvL1Gso62bxcRiHV58fr0kRXNI4O7eFpC37i+XDz+4ibbKaWslWCxdBHCEYXtQKHWuhJAKdVLKTVCa70toj3rxOQU5nDMgGOkHISJJ0RHy2Bu8K0+Tk0dh7d8JRpQwdJRgXVF6zhMDdlepPy1e5Gbm/Hj2/aLWCyWbkc4MYV/AnWuz7W+Y5YgmA1m6oPMxn10zDF+lgKrVkF8PKnDxlOhD3MgMRamTAl6z3p3VFOiYLFYLK0kHFHoobWuMh987232UQh2lu1k98HdDUUhMxN27IA6n77m5cHYsaQmSlyg8JvPZN+DIHi8HhJ7JnLUgWj47ju5TwirwmKxWFpDOKJQpJQ6z3xQSp0PFEeuS50bM6uvX9lrRGHqVFmPYHZQy80VUfCV1faq8pCZRzmFOWSlZBE16ihYtkzuYy0Fi8USAcIRhRuBu5VS25VS24FfATdEtludF4/XQ7SKJmNIhhwoLpbS1kf7sni3b4dDh+R1zBhSEiSV1Oy9EEhVbRWrd68WkRkzBlaskBNWFCwWSwRoMtCstd4MHKeUigeU1truz+zjwS8f5Phhx3PCsBP4quArFny5gBU7VzB+4Hh6x/jKWptqpmYQz88XkdBaRCG+cVH4ds+3VAJl1XkAABXlSURBVNVWiTtqrJa9lsG6jywWS0Ro0lJQSt2vlOqntS7XWpcppZKUUn9oj851ZOp0HXd9chePLH8EgL96/sq7ee/Sv1d/bshyGVJGFMwgnp8v8QSAsWNJ6JlAQmxCSFGod0elZvnvvWwtBYvFEgHCSUk9W2t9t/mgtS5VSp2DbM/ZbSmuKKamrqa+GmpOYQ4zR83k3Sve9W9oSlwnJoowLF8OtbVyzudSSk1IbbDNpcHj9Tj7GIzxLQ9JSpKd1iwWi6WNCSemEK2Uqt9sVynVC+j2m++amf2W0i0UHChgfdH64GWj3ZvhfO978NFHsGaNLD7zDewpCSmhLYVCqaGklIKxY+WgtRIsFkuECEcU/hf4RCn1Y6XUj4GPgL9FtlsdH/cg/vzK56nTdeL3nzcPnnvOaVhc7IjCuefCwYOyv4LLFZSakBpUFMw+BvViM2SIxCNsPMFisUSIcALNC5RSa4BZgAI+ALr9VNU9iD/3jYhA9qYKuO8+mDEDrr0Wampk7wMjCqefLvsqV1Q4s34gNV5EQWvtV3Ru7Z61/vsYKAX33+93rcVisbQl4VZJ3YWsar4Y2U/hu4j1qJNgRGFY4jAKDhQwpM8QUu+cLyfNyuVS3x7MRhTi4uCMM+R9gKVQWVPJvsp9fs/wCzIbfvpTmD27Tb+LxWKxGEKKglJqjFLqt0qp74AngB1ISuppWusn2q2HHZTCskIG9h5YXz00u3qALEibPh127pQFZmbhmnsv5Tlz5NVtKfgWsAUGmz1eT6P7GFgsFktb05ilsAGxCuZorWdorR9H6h51CQoOFJDjzWHz3s1NNw6Ct9xLakJqvb8/q6SnDP7XXiulLLze4DukXXEFPPywYzFAyAVsfkFmi8ViaQcaE4WLEbfREqXUs0qpmUhModNTVVvF2CfGkv1sNqMfH82W0i3Nvoe3zEtKQgonDDsBgBMKe8j+Bu71CMZScItCr15w++1+Za/TEqT+Uf4+p2BeZU0la/esDZ7RZLFYLBEipChord/QWl8GjAOWAj8DBiul/qqU6tRO7UPVh6iormDG8BkALbIWvGVeUuNTmTF8Bt/c8A1n5FbL7mfulct79sh7t/soCCOTRhIfG8+qXavqj63ZvYaauhonyGyxWCztQDh7NB/UWi/UWp8LDAVWAXdFvGcRpKpWir5OS50GhC4xEYraulp2l++ujwVMGTIFVbhL1h64LYXVqyWFdNiwRu8XpaLITMnEU+ipPxY0yGyxWCwRpll7NGut92qtn9Zanx6pDrUHRhSG95UBvLmiUFRRRK2uJbXWl15aWwu7doml0KsXDBokBe9ycqRkdlTTP3N2Sjardq2ipq4GkCBzcq9k0vt2++xfi8XSjjRLFJqLUuospVSuUmqTUiqodaGUulQptV4ptU4p9fdI9sdQXVcNQL+4fvSL6xeyxEQojIikzH8A7r0XiookuJwqlgPDh8PmzbKRTlZ4M/3s1GwqaypZX7QesEFmi8VyZIiYKCilooEngbOB8cBcpdT4gDZHA78GTtRaTwBuj1R/3BhLISY6JuRq4sYw7VPz98I330imETiikJ4On38OlZVhi4JxE3m8Hg5VH+LbPd/aILPFYml3ImkpTAM2aa23+HZrWwScH9DmOuBJrXUpgNZ6TwT7U48RhdjoWFLiQ9cdAmDDBti0ye9QvSiUIRVPzcY5KZJaSno6VPk2q8sOL1A8uv9oEnsm4vF6WL17NbW61gaZLRZLuxNJUUhDFrwZCnzH3IwBxiilvlBKLVdKnRXsRkqp65VSHqWUp6ioqNUdc4tCk5bCddfBbbf5HSosK0ShGFyOBJQ3+7KX3JYCSME7s7lOE5hgc05hjg0yWyyWI0Y4pbNbSjBnuA7y/KOBU5HMps+UUhO11n71HrTWzwDPAGRnZwfeo9lU10pMwYhCYXlhg7pD9RQXy+pkYGvpVn724c9YtWsVg2L6EVNXKl/ps8+k7eDB8moykKZODSvIbMhOyebRrx5lz8E9DOw9kGGJjWctWSwWS1sTSUuhAHCPakOBwCl5AfCW1rpaa70VyEVEIqLUxxSiJKZQVVvF3kN7gzcuK5M/4P1N7/NW7lsk907m2n6uBKxly2DgQGdBmrEUwownGC6beBnHph3LoD6DuP24222Q2WKxtDuRtBS+Bo5WSo0EdgKXA1cEtHkTmAv8j1JqAOJOav7y4mYSGFMAiRMk905u2LisrH62X1hWSJSKYsW1K4h+/gXgdWlTVAQZGc41Y8fCscfCRRc1q1/Zqdl88aMvmv19LBaLpa2ImKWgta4BbgE+RKqqvqq1XqeUulcpdZ6v2YdAiVJqPbAE+IXWuiRSfTIExhQgxFoFraG8vN5S8JZ5GRI/hOioaKeuUVKSvJogM0h57BUrpIS2xWKxdCIiaSmgtX4PeC/g2G9d7zVwh++v3TDrFGKiYxjUZxAQQhQOHZL1B2VloDXecm+9ZUFJiZTCzsiApUudILPFYrF0YiK6eK2j4uc+ClGhFKi3EKithcOHKSwrrLcs6rfZNCWw3ZaCxWKxdFK6vSjE9Yijf6/+wVc1G1HwvfeWef1FYcAAZ7McaylYLJYuQLcXBSD0AjaXKFTtK6GooqihpWBEwVoKFoulC9AtRcGsU4iJigEIvYDNJQq7ircBODGF4mIRhVmzYN48u0WmxWLpEnRLUQi0FIYmDiV/f37DhuXl9W8L98r5BpZCXBz8/vfQp09kO22xWCztgBUFYPLaPewq30VhWUBcwWUpePcVAD5RqKuD0tImN8+xWCyWzka3FAWTkmpEIXu11FPK2b7cv6FbFMp9RfASUmHfPhGG5CCL3SwWi6UT0y1FwV06G2DKhn0oDTnf/VsamL2V3aJwcDfRKpqBfQYG33vZYrFYugDdVhQUimgVDVoTv3kHxxSBZ8dyWL9edk774gs/USg8XMSQ+CFEqShnNbMVBYvF0sXotqIQGx0rBeeKi+HQIbK9kFOWKxVP6+ogN1cCzT1k0be3aq9/kBmsKFgsli5HtxSF6trqetcR27cDkFUIhboM7zefyvE9e8RSSEqC2Fi8dfsbioINNFssli5GtxQFYykAskkOkL2vNwAeE2w2opCQAAkJeCmzloLFYunyWFHwicKU8acTVQd3Hr2Fc66EHXu31ovC4b7xlERV+hfDi46Gvn2P0DewWCyWyNA9RaHOJQrbt0OfPvSePoM7/wODyuH9o+Htug0iCvHxbEiRuMLouFT485/h44+hf3+wm+BYLJYuRkRLZ3dUqmur60tckJ8vO6WNHcuCu2S/0MF3RZPTYzeUJ0ByMp54WdSW/c1u+OVv5Lqzzz4ynbdYLJYI0i1FoYH7aPjw+hLYKimJLN0bT/xusRRGjCAnuYrE6miO2lkhbqPycujZ8wh+A4vFYokM3dN9FCgK6ekwapRsu5mVRXZMOuuTaqg4uA8SEvAkHiRrb0+i8rdDWprUO7KuI4vF0gXp3qJw8KAEjdPTZeZ/7bVw9dVkJ46jNgpWq91UJfRmTa/9ZO+OdgTEYrFYuijd0n1UXedbp+Bbo8Dw4fL69NMAZP1tL2yDnCGauPhDHFZ1ZBXUwu58u++yxWLp0nRLUai3FHzpqIGz/7TUcQz+Fjyp0LNXKdRA9pZKKC2wloLFYunSdFtRSOyZCJs3y4FRo/zOq8GDyfLCl8PgQNRm+hHHqOJKOWlFwWKxdGG6bUwhJipG6hvFxzfcSnPQIE7cARuT4Y2q1RwfM4r6sLIVBYvF0oXplpZCdW21uI/y8mSP5cBMogEDuPNLOGUb1N7/ByZW9QNukXNWFCwWSxemW4pCfUwh9xs4/viGDXr0oGe/ZE7cUQIpx8H+/c65YcPar6MWi8XSznRb91EsvhTTMWOCNxo0SF7j4+UPpCqq3YvZYrF0YbqlKFTXVRNz8BBoXb+SuQFGFHxVUgHrOrJYLF2e7us+OnBQPjRlKSQkyKY7YEXBYrF0ebqvKOzzbbVpRcFisVjq6b6iUHpAUlGNayiQ0aMhMVHiCT16SL2jCRPat6MWi8XSznRLUaiurSamZF/oeALAT34C3/++CEJ8vKxpSE1tv05aLBbLEaDbiYLWmuq6amKL9oZ2HQHExkpFVIOpj2SxWCxdmG6XfVRdVw1AbPkhmDLlCPfGYrFYOhbdThSqDpUDENOvP1xzzRHujcVisXQsup0oVP/lcQBiL7hYgscWi8ViqafbiULVW28AEDtp6hHuicVisXQ8IioKSqmzlFK5SqlNSqm7gpy/WilVpJRa5fu7NpL9Aagq3AHgbMdpsVgslnoiln2klIoGngTOAAqAr5VSb2ut1wc0/YfW+pZI9cOPigqq9u0FkJ3XLBaLxeJHJC2FacAmrfUWrXUVsAg4P4LPa5odO6iOlrfWUrBYLJaGRFIU0oAdrs8FvmOBXKyUWqOUek0pFbQutVLqeqWURynlKfr/7d1/rNV1Hcfx58vLj1H+AOHqmCBgkQabKTLnKv2jWqkVt2JLnFtUbk2WQ9cqcWzOtf6x1o85LQeLRWXqWmm0mWHMma1EAUEg/IHEJQIBdWYsx7lc3v3x/dzjl8P5coF57vd77/f12M7O93zu9569zuece9/n8/l+z+ccOHDqiXp7abgomJkV6mRRUJu2aLn9B2B6RFwM/BlY2e6OImJZRMyNiLnd3d2nnihXFEaf5ukjM7NWnSwKu4H8O/8pwJ78DhHxekQcSjeXA5d1MA/s2kVjVFarPFIwMztWJ4vCs8BMSTMkjQEWAKvyO0jKfznyPGBbB/NAby99504CXBTMzNrp2NlHEXFY0s3An4AuYEVEbJX0HWBdRKwCFkuaBxwG3gC+3Kk8QDZ9NPkc4ICLgplZGx1dEC8iHgUebWm7I7d9O3B7JzMcpbeXxoUzAJ+SambWTn0+0dzfD7t30zhnIuDpIzOzdupTFPbsgf5++iZNAFwUzMzaqU9R6O0FoOGiYGZWqD5FYdcuABoTzgT8OQUzs3bqUxTSSKEvFQWPFMzMjlWforBoEaxfT6PLH14zMytSn6IwfjzMmUOjvwH4lFQzs3bqUxSSgaLgkYKZ2bFqVxT6jvQBPtBsZtZO7YpCo79Bl7roOq2r7ChmZpVTy6Lg4wlmZu3Vsij4eIKZWXu1Kwp9/X0uCmZmBWpXFDxSMDMrVr+icKThM4/MzArUryh4pGBmVqh2RcHHFMzMitWuKPiUVDOzYrUsCh4pmJm1V5uisOK5Fcz+yWye2vWUDzSbmRUYVXaAoTJx3ERmdc9iVvcs5n9wftlxzMwqqTZFoeeiHnou6ik7hplZpdVm+sjMzAbnomBmZk0uCmZm1uSiYGZmTS4KZmbW5KJgZmZNLgpmZtbkomBmZk2KiLIznBRJB4DeU/jVScBr73KcThguOcFZO2W4ZB0uOcFZAaZFRPdgOw27onCqJK2LiLll5xjMcMkJztopwyXrcMkJznoyPH1kZmZNLgpmZtZUp6KwrOwAJ2i45ARn7ZThknW45ARnPWG1OaZgZmaDq9NIwczMBuGiYGZmTSO+KEi6WtKLkrZLWlJ2njxJUyU9IWmbpK2Sbkntd0r6t6SN6XJt2VkBJO2UtDllWpfazpb0uKSX0/WEkjNemOu3jZLeknRrVfpU0gpJ+yVtybW17UNl7k6v3eclzalA1u9LeiHleVjS+NQ+XdLbuf69rwJZC59zSbenfn1R0qdKzvlQLuNOSRtTezl9GhEj9gJ0Aa8AFwBjgE3ArLJz5fJNBuak7TOAl4BZwJ3AN8vO1ybvTmBSS9v3gCVpewlwV9k5W57/V4FpVelT4CpgDrBlsD4ErgX+CAi4AlhbgayfBEal7btyWafn96tIv7Z9ztPf2CZgLDAj/Y/oKitny89/ANxRZp+O9JHC5cD2iNgREQ3gQaAy38kZEXsjYkPa/i+wDTiv3FQnrQdYmbZXAp8rMUurjwOvRMSpfAK+IyLiL8AbLc1FfdgD/CIyTwPjJU0emqTts0bE6og4nG4+DUwZqjzHU9CvRXqAByPiUET8E9hO9r+i446XU5KALwIPDEWWIiO9KJwH/Ct3ezcV/acraTpwKbA2Nd2chugryp6SyQlgtaT1kr6W2s6NiL2QFTngnNLSHWsBR/+BVbFPobgPq/76/SrZSGbADEnPSXpS0pVlhWrR7jmvar9eCeyLiJdzbUPepyO9KKhNW+XOwZV0OvBb4NaIeAv4KfA+4BJgL9mQsgo+EhFzgGuAr0u6quxARSSNAeYBv0lNVe3T46ns61fSUuAwcH9q2gucHxGXAt8Afi3pzLLyJUXPeVX79XqOfhNTSp+O9KKwG5iauz0F2FNSlrYkjSYrCPdHxO8AImJfRPRHxBFgOUM0tB1MROxJ1/uBh8ly7RuY0kjX+8tLeJRrgA0RsQ+q26dJUR9W8vUraSHwGeCGSJPfaSrm9bS9nmye/gPlpTzuc165fpU0CvgC8NBAW1l9OtKLwrPATEkz0jvHBcCqkjM1pTnEnwHbIuKHufb8vPHngS2tvzvUJL1X0hkD22QHHLeQ9efCtNtC4PflJDzGUe+6qtinOUV9uAr4UjoL6QrgPwPTTGWRdDVwGzAvIv6Xa++W1JW2LwBmAjvKSdnMVPScrwIWSBoraQZZ1meGOl+LTwAvRMTugYbS+nSoj2wP9YXsDI6XyKrs0rLztGT7KNmw9XlgY7pcC/wS2JzaVwGTK5D1ArIzNjYBWwf6EpgIrAFeTtdnVyDre4DXgbNybZXoU7JCtRfoI3vHemNRH5JNc9ybXrubgbkVyLqdbD5+4PV6X9p3fnpdbAI2AJ+tQNbC5xxYmvr1ReCaMnOm9p8DN7XsW0qfepkLMzNrGunTR2ZmdhJcFMzMrMlFwczMmlwUzMysyUXBzMyaXBTMEkn9OnqF1XdtVd204mWVPhth1taosgOYVcjbEXFJ2SHMyuSRgtkg0hr3d0l6Jl3en9qnSVqTFlxbI+n81H5u+q6BTeny4XRXXZKWK/vujNWSxqX9F0v6R7qfB0t6mGaAi4JZ3riW6aPrcj97KyIuB+4Bfpza7iFb2vpisoXh7k7tdwNPRsSHyNbO35raZwL3RsRs4E2yT6xC9h0Kl6b7ualTD87sRPgTzWaJpIMRcXqb9p3AxyJiR1rA8NWImCjpNbKlE/pS+96ImCTpADAlIg7l7mM68HhEzEy3bwNGR8R3JT0GHAQeAR6JiIMdfqhmhTxSMDsxUbBdtE87h3Lb/bxzTO/TZGscXQasTytmmpXCRcHsxFyXu/572v4b2cq7ADcAf03ba4BFAJK6jrcGvqTTgKkR8QTwbWA8cMxoxWyo+B2J2TvGDXxpevJYRAycljpW0lqyN1LXp7bFwApJ3wIOAF9J7bcAyyTdSDYiWES2MmY7XcCvJJ1FtirqjyLizXftEZmdJB9TMBtEOqYwNyJeKzuLWad5+sjMzJo8UjAzsyaPFMzMrMlFwczMmlwUzMysyUXBzMyaXBTMzKzp/7X6A8UjjsqAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label = 'Training acc')\n",
    "plt.plot(epochs, val_acc, 'g', label = 'Validation acc')\n",
    "plt.title('Training and validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "155/155 [==============================] - 4s 26ms/step - loss: 0.7623 - acc: 0.4387\n",
      "Epoch 2/300\n",
      "155/155 [==============================] - 0s 151us/step - loss: 0.6972 - acc: 0.4968\n",
      "Epoch 3/300\n",
      "155/155 [==============================] - 0s 157us/step - loss: 0.6850 - acc: 0.5290\n",
      "Epoch 4/300\n",
      "155/155 [==============================] - 0s 196us/step - loss: 0.6836 - acc: 0.5613\n",
      "Epoch 5/300\n",
      "155/155 [==============================] - 0s 193us/step - loss: 0.6837 - acc: 0.5806\n",
      "Epoch 6/300\n",
      "155/155 [==============================] - 0s 190us/step - loss: 0.6749 - acc: 0.6129\n",
      "Epoch 7/300\n",
      "155/155 [==============================] - 0s 192us/step - loss: 0.6429 - acc: 0.6710\n",
      "Epoch 8/300\n",
      "155/155 [==============================] - 0s 206us/step - loss: 0.6556 - acc: 0.5806\n",
      "Epoch 9/300\n",
      "155/155 [==============================] - 0s 243us/step - loss: 0.6525 - acc: 0.6452\n",
      "Epoch 10/300\n",
      "155/155 [==============================] - 0s 208us/step - loss: 0.6206 - acc: 0.6516\n",
      "Epoch 11/300\n",
      "155/155 [==============================] - 0s 257us/step - loss: 0.6431 - acc: 0.6516\n",
      "Epoch 12/300\n",
      "155/155 [==============================] - 0s 181us/step - loss: 0.6367 - acc: 0.6774\n",
      "Epoch 13/300\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.6441 - acc: 0.6065\n",
      "Epoch 14/300\n",
      "155/155 [==============================] - 0s 161us/step - loss: 0.6250 - acc: 0.7032\n",
      "Epoch 15/300\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.6373 - acc: 0.6452\n",
      "Epoch 16/300\n",
      "155/155 [==============================] - 0s 154us/step - loss: 0.6380 - acc: 0.6839\n",
      "Epoch 17/300\n",
      "155/155 [==============================] - 0s 150us/step - loss: 0.6216 - acc: 0.6516\n",
      "Epoch 18/300\n",
      "155/155 [==============================] - 0s 149us/step - loss: 0.6210 - acc: 0.7097\n",
      "Epoch 19/300\n",
      "155/155 [==============================] - 0s 163us/step - loss: 0.6144 - acc: 0.7032\n",
      "Epoch 20/300\n",
      "155/155 [==============================] - 0s 145us/step - loss: 0.5909 - acc: 0.7161\n",
      "Epoch 21/300\n",
      "155/155 [==============================] - 0s 145us/step - loss: 0.6056 - acc: 0.7032\n",
      "Epoch 22/300\n",
      "155/155 [==============================] - 0s 144us/step - loss: 0.6218 - acc: 0.6645\n",
      "Epoch 23/300\n",
      "155/155 [==============================] - 0s 146us/step - loss: 0.5863 - acc: 0.7032\n",
      "Epoch 24/300\n",
      "155/155 [==============================] - 0s 147us/step - loss: 0.6002 - acc: 0.7290\n",
      "Epoch 25/300\n",
      "155/155 [==============================] - 0s 154us/step - loss: 0.6147 - acc: 0.7032\n",
      "Epoch 26/300\n",
      "155/155 [==============================] - 0s 154us/step - loss: 0.5771 - acc: 0.7290\n",
      "Epoch 27/300\n",
      "155/155 [==============================] - 0s 155us/step - loss: 0.5719 - acc: 0.7677\n",
      "Epoch 28/300\n",
      "155/155 [==============================] - 0s 148us/step - loss: 0.5782 - acc: 0.7484\n",
      "Epoch 29/300\n",
      "155/155 [==============================] - 0s 155us/step - loss: 0.5709 - acc: 0.7806\n",
      "Epoch 30/300\n",
      "155/155 [==============================] - 0s 157us/step - loss: 0.5703 - acc: 0.7355\n",
      "Epoch 31/300\n",
      "155/155 [==============================] - 0s 153us/step - loss: 0.5732 - acc: 0.7290\n",
      "Epoch 32/300\n",
      "155/155 [==============================] - 0s 181us/step - loss: 0.5626 - acc: 0.7806\n",
      "Epoch 33/300\n",
      "155/155 [==============================] - 0s 194us/step - loss: 0.5632 - acc: 0.7742\n",
      "Epoch 34/300\n",
      "155/155 [==============================] - 0s 145us/step - loss: 0.5603 - acc: 0.7806\n",
      "Epoch 35/300\n",
      "155/155 [==============================] - 0s 188us/step - loss: 0.5571 - acc: 0.7742\n",
      "Epoch 36/300\n",
      "155/155 [==============================] - 0s 266us/step - loss: 0.5468 - acc: 0.7484\n",
      "Epoch 37/300\n",
      "155/155 [==============================] - 0s 245us/step - loss: 0.5533 - acc: 0.7613\n",
      "Epoch 38/300\n",
      "155/155 [==============================] - 0s 266us/step - loss: 0.5437 - acc: 0.8065\n",
      "Epoch 39/300\n",
      "155/155 [==============================] - 0s 279us/step - loss: 0.5452 - acc: 0.7419\n",
      "Epoch 40/300\n",
      "155/155 [==============================] - 0s 296us/step - loss: 0.5444 - acc: 0.8000\n",
      "Epoch 41/300\n",
      "155/155 [==============================] - 0s 288us/step - loss: 0.5321 - acc: 0.7871\n",
      "Epoch 42/300\n",
      "155/155 [==============================] - 0s 240us/step - loss: 0.5493 - acc: 0.7871\n",
      "Epoch 43/300\n",
      "155/155 [==============================] - 0s 326us/step - loss: 0.5464 - acc: 0.7742\n",
      "Epoch 44/300\n",
      "155/155 [==============================] - 0s 224us/step - loss: 0.5188 - acc: 0.7871\n",
      "Epoch 45/300\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.5305 - acc: 0.8065\n",
      "Epoch 46/300\n",
      "155/155 [==============================] - 0s 166us/step - loss: 0.5489 - acc: 0.7613\n",
      "Epoch 47/300\n",
      "155/155 [==============================] - 0s 190us/step - loss: 0.5237 - acc: 0.8323\n",
      "Epoch 48/300\n",
      "155/155 [==============================] - 0s 253us/step - loss: 0.5321 - acc: 0.7548\n",
      "Epoch 49/300\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.5151 - acc: 0.7742\n",
      "Epoch 50/300\n",
      "155/155 [==============================] - 0s 165us/step - loss: 0.5219 - acc: 0.7742\n",
      "Epoch 51/300\n",
      "155/155 [==============================] - 0s 308us/step - loss: 0.5177 - acc: 0.7742\n",
      "Epoch 52/300\n",
      "155/155 [==============================] - 0s 190us/step - loss: 0.5056 - acc: 0.7935\n",
      "Epoch 53/300\n",
      "155/155 [==============================] - 0s 207us/step - loss: 0.5036 - acc: 0.8258\n",
      "Epoch 54/300\n",
      "155/155 [==============================] - 0s 206us/step - loss: 0.5260 - acc: 0.7677\n",
      "Epoch 55/300\n",
      "155/155 [==============================] - 0s 277us/step - loss: 0.5213 - acc: 0.7742\n",
      "Epoch 56/300\n",
      "155/155 [==============================] - 0s 202us/step - loss: 0.5093 - acc: 0.7871\n",
      "Epoch 57/300\n",
      "155/155 [==============================] - 0s 185us/step - loss: 0.4854 - acc: 0.8581\n",
      "Epoch 58/300\n",
      "155/155 [==============================] - 0s 181us/step - loss: 0.4857 - acc: 0.8194\n",
      "Epoch 59/300\n",
      "155/155 [==============================] - 0s 162us/step - loss: 0.5090 - acc: 0.7935\n",
      "Epoch 60/300\n",
      "155/155 [==============================] - 0s 180us/step - loss: 0.5023 - acc: 0.7871\n",
      "Epoch 61/300\n",
      "155/155 [==============================] - 0s 180us/step - loss: 0.4911 - acc: 0.8000\n",
      "Epoch 62/300\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.4895 - acc: 0.8000\n",
      "Epoch 63/300\n",
      "155/155 [==============================] - 0s 197us/step - loss: 0.4746 - acc: 0.8065\n",
      "Epoch 64/300\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.5024 - acc: 0.7935\n",
      "Epoch 65/300\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.4847 - acc: 0.8452\n",
      "Epoch 66/300\n",
      "155/155 [==============================] - 0s 215us/step - loss: 0.4706 - acc: 0.8387\n",
      "Epoch 67/300\n",
      "155/155 [==============================] - 0s 215us/step - loss: 0.4683 - acc: 0.8194\n",
      "Epoch 68/300\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.4859 - acc: 0.7742\n",
      "Epoch 69/300\n",
      "155/155 [==============================] - 0s 185us/step - loss: 0.4706 - acc: 0.8129\n",
      "Epoch 70/300\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.4862 - acc: 0.7677\n",
      "Epoch 71/300\n",
      "155/155 [==============================] - 0s 165us/step - loss: 0.4860 - acc: 0.7806\n",
      "Epoch 72/300\n",
      "155/155 [==============================] - 0s 163us/step - loss: 0.4593 - acc: 0.8194\n",
      "Epoch 73/300\n",
      "155/155 [==============================] - 0s 153us/step - loss: 0.4683 - acc: 0.8387\n",
      "Epoch 74/300\n",
      "155/155 [==============================] - 0s 151us/step - loss: 0.4833 - acc: 0.8452\n",
      "Epoch 75/300\n",
      "155/155 [==============================] - 0s 152us/step - loss: 0.4584 - acc: 0.8452\n",
      "Epoch 76/300\n",
      "155/155 [==============================] - 0s 153us/step - loss: 0.4740 - acc: 0.8000\n",
      "Epoch 77/300\n",
      "155/155 [==============================] - 0s 233us/step - loss: 0.4387 - acc: 0.8452\n",
      "Epoch 78/300\n",
      "155/155 [==============================] - 0s 183us/step - loss: 0.4547 - acc: 0.8065\n",
      "Epoch 79/300\n",
      "155/155 [==============================] - 0s 140us/step - loss: 0.4735 - acc: 0.8000\n",
      "Epoch 80/300\n",
      "155/155 [==============================] - 0s 148us/step - loss: 0.4592 - acc: 0.8387\n",
      "Epoch 81/300\n",
      "155/155 [==============================] - 0s 159us/step - loss: 0.4567 - acc: 0.8258\n",
      "Epoch 82/300\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.4487 - acc: 0.8645\n",
      "Epoch 83/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 164us/step - loss: 0.4395 - acc: 0.8452\n",
      "Epoch 84/300\n",
      "155/155 [==============================] - 0s 195us/step - loss: 0.4580 - acc: 0.8129\n",
      "Epoch 85/300\n",
      "155/155 [==============================] - 0s 187us/step - loss: 0.4416 - acc: 0.8581\n",
      "Epoch 86/300\n",
      "155/155 [==============================] - 0s 187us/step - loss: 0.4647 - acc: 0.8129\n",
      "Epoch 87/300\n",
      "155/155 [==============================] - 0s 191us/step - loss: 0.4663 - acc: 0.8065\n",
      "Epoch 88/300\n",
      "155/155 [==============================] - 0s 188us/step - loss: 0.4367 - acc: 0.8194\n",
      "Epoch 89/300\n",
      "155/155 [==============================] - 0s 180us/step - loss: 0.4295 - acc: 0.8387\n",
      "Epoch 90/300\n",
      "155/155 [==============================] - 0s 158us/step - loss: 0.4547 - acc: 0.8387\n",
      "Epoch 91/300\n",
      "155/155 [==============================] - 0s 157us/step - loss: 0.4572 - acc: 0.8065\n",
      "Epoch 92/300\n",
      "155/155 [==============================] - 0s 152us/step - loss: 0.4280 - acc: 0.8194\n",
      "Epoch 93/300\n",
      "155/155 [==============================] - 0s 170us/step - loss: 0.4330 - acc: 0.8323\n",
      "Epoch 94/300\n",
      "155/155 [==============================] - 0s 164us/step - loss: 0.4441 - acc: 0.8387\n",
      "Epoch 95/300\n",
      "155/155 [==============================] - 0s 158us/step - loss: 0.4346 - acc: 0.8387\n",
      "Epoch 96/300\n",
      "155/155 [==============================] - 0s 164us/step - loss: 0.4371 - acc: 0.8516\n",
      "Epoch 97/300\n",
      "155/155 [==============================] - 0s 219us/step - loss: 0.4515 - acc: 0.8065\n",
      "Epoch 98/300\n",
      "155/155 [==============================] - 0s 220us/step - loss: 0.4490 - acc: 0.8323\n",
      "Epoch 99/300\n",
      "155/155 [==============================] - 0s 201us/step - loss: 0.4190 - acc: 0.8452\n",
      "Epoch 100/300\n",
      "155/155 [==============================] - 0s 212us/step - loss: 0.4241 - acc: 0.8258\n",
      "Epoch 101/300\n",
      "155/155 [==============================] - 0s 288us/step - loss: 0.4267 - acc: 0.8516\n",
      "Epoch 102/300\n",
      "155/155 [==============================] - 0s 160us/step - loss: 0.4311 - acc: 0.8387\n",
      "Epoch 103/300\n",
      "155/155 [==============================] - 0s 157us/step - loss: 0.4246 - acc: 0.8581\n",
      "Epoch 104/300\n",
      "155/155 [==============================] - 0s 161us/step - loss: 0.4221 - acc: 0.8516\n",
      "Epoch 105/300\n",
      "155/155 [==============================] - 0s 165us/step - loss: 0.4094 - acc: 0.8452\n",
      "Epoch 106/300\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.4058 - acc: 0.8645\n",
      "Epoch 107/300\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.4113 - acc: 0.8581\n",
      "Epoch 108/300\n",
      "155/155 [==============================] - 0s 167us/step - loss: 0.4079 - acc: 0.8645\n",
      "Epoch 109/300\n",
      "155/155 [==============================] - 0s 180us/step - loss: 0.4139 - acc: 0.8387\n",
      "Epoch 110/300\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.4030 - acc: 0.8194\n",
      "Epoch 111/300\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.4243 - acc: 0.8452\n",
      "Epoch 112/300\n",
      "155/155 [==============================] - 0s 244us/step - loss: 0.4186 - acc: 0.8258\n",
      "Epoch 113/300\n",
      "155/155 [==============================] - 0s 284us/step - loss: 0.4056 - acc: 0.8387\n",
      "Epoch 114/300\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.4198 - acc: 0.8323\n",
      "Epoch 115/300\n",
      "155/155 [==============================] - 0s 166us/step - loss: 0.3806 - acc: 0.8581\n",
      "Epoch 116/300\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.4067 - acc: 0.8452\n",
      "Epoch 117/300\n",
      "155/155 [==============================] - 0s 183us/step - loss: 0.3803 - acc: 0.8839\n",
      "Epoch 118/300\n",
      "155/155 [==============================] - 0s 205us/step - loss: 0.3877 - acc: 0.8710\n",
      "Epoch 119/300\n",
      "155/155 [==============================] - 0s 200us/step - loss: 0.3992 - acc: 0.8710\n",
      "Epoch 120/300\n",
      "155/155 [==============================] - 0s 194us/step - loss: 0.4153 - acc: 0.8516\n",
      "Epoch 121/300\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.3987 - acc: 0.8387\n",
      "Epoch 122/300\n",
      "155/155 [==============================] - 0s 185us/step - loss: 0.3999 - acc: 0.8645\n",
      "Epoch 123/300\n",
      "155/155 [==============================] - 0s 248us/step - loss: 0.4041 - acc: 0.8387\n",
      "Epoch 124/300\n",
      "155/155 [==============================] - 0s 210us/step - loss: 0.4013 - acc: 0.8452\n",
      "Epoch 125/300\n",
      "155/155 [==============================] - 0s 229us/step - loss: 0.3718 - acc: 0.8645\n",
      "Epoch 126/300\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.3962 - acc: 0.8645\n",
      "Epoch 127/300\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.4001 - acc: 0.8516\n",
      "Epoch 128/300\n",
      "155/155 [==============================] - 0s 189us/step - loss: 0.3872 - acc: 0.8774\n",
      "Epoch 129/300\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.3946 - acc: 0.8581\n",
      "Epoch 130/300\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.3730 - acc: 0.8645\n",
      "Epoch 131/300\n",
      "155/155 [==============================] - 0s 261us/step - loss: 0.3938 - acc: 0.8387\n",
      "Epoch 132/300\n",
      "155/155 [==============================] - 0s 232us/step - loss: 0.3947 - acc: 0.8516\n",
      "Epoch 133/300\n",
      "155/155 [==============================] - 0s 273us/step - loss: 0.3877 - acc: 0.8581\n",
      "Epoch 134/300\n",
      "155/155 [==============================] - 0s 242us/step - loss: 0.3755 - acc: 0.8774\n",
      "Epoch 135/300\n",
      "155/155 [==============================] - 0s 274us/step - loss: 0.3847 - acc: 0.8516\n",
      "Epoch 136/300\n",
      "155/155 [==============================] - 0s 222us/step - loss: 0.3595 - acc: 0.8903\n",
      "Epoch 137/300\n",
      "155/155 [==============================] - 0s 237us/step - loss: 0.3838 - acc: 0.8516\n",
      "Epoch 138/300\n",
      "155/155 [==============================] - 0s 276us/step - loss: 0.3679 - acc: 0.8903\n",
      "Epoch 139/300\n",
      "155/155 [==============================] - 0s 229us/step - loss: 0.3888 - acc: 0.8323\n",
      "Epoch 140/300\n",
      "155/155 [==============================] - 0s 221us/step - loss: 0.3655 - acc: 0.8903\n",
      "Epoch 141/300\n",
      "155/155 [==============================] - 0s 190us/step - loss: 0.3769 - acc: 0.8710\n",
      "Epoch 142/300\n",
      "155/155 [==============================] - 0s 180us/step - loss: 0.3791 - acc: 0.8839\n",
      "Epoch 143/300\n",
      "155/155 [==============================] - 0s 210us/step - loss: 0.3863 - acc: 0.8645\n",
      "Epoch 144/300\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.3588 - acc: 0.8839\n",
      "Epoch 145/300\n",
      "155/155 [==============================] - 0s 217us/step - loss: 0.3752 - acc: 0.8581\n",
      "Epoch 146/300\n",
      "155/155 [==============================] - 0s 240us/step - loss: 0.3744 - acc: 0.8645\n",
      "Epoch 147/300\n",
      "155/155 [==============================] - 0s 292us/step - loss: 0.3755 - acc: 0.8710\n",
      "Epoch 148/300\n",
      "155/155 [==============================] - 0s 284us/step - loss: 0.3826 - acc: 0.8452\n",
      "Epoch 149/300\n",
      "155/155 [==============================] - 0s 263us/step - loss: 0.3766 - acc: 0.8710\n",
      "Epoch 150/300\n",
      "155/155 [==============================] - 0s 223us/step - loss: 0.3576 - acc: 0.8645\n",
      "Epoch 151/300\n",
      "155/155 [==============================] - 0s 227us/step - loss: 0.3719 - acc: 0.8968\n",
      "Epoch 152/300\n",
      "155/155 [==============================] - 0s 200us/step - loss: 0.3766 - acc: 0.8581\n",
      "Epoch 153/300\n",
      "155/155 [==============================] - 0s 221us/step - loss: 0.3782 - acc: 0.8581\n",
      "Epoch 154/300\n",
      "155/155 [==============================] - 0s 225us/step - loss: 0.3496 - acc: 0.8710\n",
      "Epoch 155/300\n",
      "155/155 [==============================] - 0s 263us/step - loss: 0.3557 - acc: 0.8710\n",
      "Epoch 156/300\n",
      "155/155 [==============================] - 0s 237us/step - loss: 0.3487 - acc: 0.8516\n",
      "Epoch 157/300\n",
      "155/155 [==============================] - 0s 246us/step - loss: 0.3369 - acc: 0.8839\n",
      "Epoch 158/300\n",
      "155/155 [==============================] - 0s 228us/step - loss: 0.3533 - acc: 0.8774\n",
      "Epoch 159/300\n",
      "155/155 [==============================] - 0s 198us/step - loss: 0.3339 - acc: 0.8710\n",
      "Epoch 160/300\n",
      "155/155 [==============================] - 0s 240us/step - loss: 0.3404 - acc: 0.8903\n",
      "Epoch 161/300\n",
      "155/155 [==============================] - 0s 152us/step - loss: 0.3423 - acc: 0.8774\n",
      "Epoch 162/300\n",
      "155/155 [==============================] - 0s 164us/step - loss: 0.3566 - acc: 0.8903\n",
      "Epoch 163/300\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.3597 - acc: 0.8710\n",
      "Epoch 164/300\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.3471 - acc: 0.8774\n",
      "Epoch 165/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 165us/step - loss: 0.3597 - acc: 0.8516\n",
      "Epoch 166/300\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.3704 - acc: 0.8387\n",
      "Epoch 167/300\n",
      "155/155 [==============================] - 0s 198us/step - loss: 0.3341 - acc: 0.8903\n",
      "Epoch 168/300\n",
      "155/155 [==============================] - 0s 213us/step - loss: 0.3454 - acc: 0.8774\n",
      "Epoch 169/300\n",
      "155/155 [==============================] - 0s 200us/step - loss: 0.3583 - acc: 0.8903\n",
      "Epoch 170/300\n",
      "155/155 [==============================] - 0s 196us/step - loss: 0.3434 - acc: 0.8839\n",
      "Epoch 171/300\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.3555 - acc: 0.8387\n",
      "Epoch 172/300\n",
      "155/155 [==============================] - 0s 161us/step - loss: 0.3362 - acc: 0.8968\n",
      "Epoch 173/300\n",
      "155/155 [==============================] - 0s 160us/step - loss: 0.3371 - acc: 0.8710\n",
      "Epoch 174/300\n",
      "155/155 [==============================] - 0s 157us/step - loss: 0.3383 - acc: 0.8645\n",
      "Epoch 175/300\n",
      "155/155 [==============================] - 0s 159us/step - loss: 0.3439 - acc: 0.8839\n",
      "Epoch 176/300\n",
      "155/155 [==============================] - 0s 165us/step - loss: 0.3379 - acc: 0.8839\n",
      "Epoch 177/300\n",
      "155/155 [==============================] - 0s 157us/step - loss: 0.3397 - acc: 0.8645\n",
      "Epoch 178/300\n",
      "155/155 [==============================] - 0s 163us/step - loss: 0.3357 - acc: 0.9097\n",
      "Epoch 179/300\n",
      "155/155 [==============================] - 0s 180us/step - loss: 0.3367 - acc: 0.8774\n",
      "Epoch 180/300\n",
      "155/155 [==============================] - 0s 193us/step - loss: 0.3392 - acc: 0.8839\n",
      "Epoch 181/300\n",
      "155/155 [==============================] - 0s 196us/step - loss: 0.3461 - acc: 0.8581\n",
      "Epoch 182/300\n",
      "155/155 [==============================] - 0s 206us/step - loss: 0.3585 - acc: 0.8839\n",
      "Epoch 183/300\n",
      "155/155 [==============================] - 0s 199us/step - loss: 0.3358 - acc: 0.8968\n",
      "Epoch 184/300\n",
      "155/155 [==============================] - 0s 193us/step - loss: 0.3399 - acc: 0.8710\n",
      "Epoch 185/300\n",
      "155/155 [==============================] - 0s 158us/step - loss: 0.3379 - acc: 0.8839\n",
      "Epoch 186/300\n",
      "155/155 [==============================] - 0s 158us/step - loss: 0.3310 - acc: 0.8968\n",
      "Epoch 187/300\n",
      "155/155 [==============================] - 0s 157us/step - loss: 0.3359 - acc: 0.8903\n",
      "Epoch 188/300\n",
      "155/155 [==============================] - 0s 155us/step - loss: 0.3233 - acc: 0.8968\n",
      "Epoch 189/300\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.3302 - acc: 0.8774\n",
      "Epoch 190/300\n",
      "155/155 [==============================] - 0s 189us/step - loss: 0.3294 - acc: 0.8903\n",
      "Epoch 191/300\n",
      "155/155 [==============================] - 0s 154us/step - loss: 0.3201 - acc: 0.8774\n",
      "Epoch 192/300\n",
      "155/155 [==============================] - 0s 162us/step - loss: 0.3253 - acc: 0.8839\n",
      "Epoch 193/300\n",
      "155/155 [==============================] - 0s 163us/step - loss: 0.3211 - acc: 0.8903\n",
      "Epoch 194/300\n",
      "155/155 [==============================] - 0s 166us/step - loss: 0.3168 - acc: 0.8839\n",
      "Epoch 195/300\n",
      "155/155 [==============================] - 0s 160us/step - loss: 0.3312 - acc: 0.8903\n",
      "Epoch 196/300\n",
      "155/155 [==============================] - 0s 182us/step - loss: 0.3342 - acc: 0.8839\n",
      "Epoch 197/300\n",
      "155/155 [==============================] - 0s 204us/step - loss: 0.3324 - acc: 0.9097\n",
      "Epoch 198/300\n",
      "155/155 [==============================] - 0s 213us/step - loss: 0.3192 - acc: 0.8968\n",
      "Epoch 199/300\n",
      "155/155 [==============================] - 0s 203us/step - loss: 0.3308 - acc: 0.8774\n",
      "Epoch 200/300\n",
      "155/155 [==============================] - 0s 188us/step - loss: 0.3135 - acc: 0.8774\n",
      "Epoch 201/300\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.3123 - acc: 0.9226\n",
      "Epoch 202/300\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.3257 - acc: 0.8839\n",
      "Epoch 203/300\n",
      "155/155 [==============================] - 0s 161us/step - loss: 0.3188 - acc: 0.8581\n",
      "Epoch 204/300\n",
      "155/155 [==============================] - 0s 153us/step - loss: 0.3157 - acc: 0.9032\n",
      "Epoch 205/300\n",
      "155/155 [==============================] - 0s 164us/step - loss: 0.3055 - acc: 0.8903\n",
      "Epoch 206/300\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.3265 - acc: 0.8774\n",
      "Epoch 207/300\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.3206 - acc: 0.8774\n",
      "Epoch 208/300\n",
      "155/155 [==============================] - 0s 149us/step - loss: 0.3128 - acc: 0.8903\n",
      "Epoch 209/300\n",
      "155/155 [==============================] - 0s 199us/step - loss: 0.3310 - acc: 0.8452\n",
      "Epoch 210/300\n",
      "155/155 [==============================] - 0s 188us/step - loss: 0.3237 - acc: 0.8516\n",
      "Epoch 211/300\n",
      "155/155 [==============================] - 0s 203us/step - loss: 0.3316 - acc: 0.8516\n",
      "Epoch 212/300\n",
      "155/155 [==============================] - 0s 206us/step - loss: 0.3093 - acc: 0.8774\n",
      "Epoch 213/300\n",
      "155/155 [==============================] - 0s 184us/step - loss: 0.3175 - acc: 0.8903\n",
      "Epoch 214/300\n",
      "155/155 [==============================] - 0s 157us/step - loss: 0.3083 - acc: 0.8645\n",
      "Epoch 215/300\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.3321 - acc: 0.8645\n",
      "Epoch 216/300\n",
      "155/155 [==============================] - 0s 158us/step - loss: 0.3023 - acc: 0.8968\n",
      "Epoch 217/300\n",
      "155/155 [==============================] - 0s 165us/step - loss: 0.3161 - acc: 0.9032\n",
      "Epoch 218/300\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.3137 - acc: 0.8774\n",
      "Epoch 219/300\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.3077 - acc: 0.8839\n",
      "Epoch 220/300\n",
      "155/155 [==============================] - 0s 163us/step - loss: 0.3094 - acc: 0.8710\n",
      "Epoch 221/300\n",
      "155/155 [==============================] - 0s 174us/step - loss: 0.2925 - acc: 0.9161\n",
      "Epoch 222/300\n",
      "155/155 [==============================] - 0s 191us/step - loss: 0.3036 - acc: 0.8839\n",
      "Epoch 223/300\n",
      "155/155 [==============================] - 0s 210us/step - loss: 0.2978 - acc: 0.9161\n",
      "Epoch 224/300\n",
      "155/155 [==============================] - 0s 193us/step - loss: 0.2959 - acc: 0.9097\n",
      "Epoch 225/300\n",
      "155/155 [==============================] - 0s 256us/step - loss: 0.3091 - acc: 0.8645\n",
      "Epoch 226/300\n",
      "155/155 [==============================] - 0s 192us/step - loss: 0.2946 - acc: 0.9032\n",
      "Epoch 227/300\n",
      "155/155 [==============================] - 0s 178us/step - loss: 0.3006 - acc: 0.8710\n",
      "Epoch 228/300\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2815 - acc: 0.9161\n",
      "Epoch 229/300\n",
      "155/155 [==============================] - 0s 234us/step - loss: 0.2987 - acc: 0.8710\n",
      "Epoch 230/300\n",
      "155/155 [==============================] - 0s 237us/step - loss: 0.2947 - acc: 0.8968\n",
      "Epoch 231/300\n",
      "155/155 [==============================] - 0s 173us/step - loss: 0.2969 - acc: 0.9097\n",
      "Epoch 232/300\n",
      "155/155 [==============================] - 0s 188us/step - loss: 0.2915 - acc: 0.9226\n",
      "Epoch 233/300\n",
      "155/155 [==============================] - 0s 252us/step - loss: 0.3066 - acc: 0.8839\n",
      "Epoch 234/300\n",
      "155/155 [==============================] - 0s 414us/step - loss: 0.2934 - acc: 0.8774\n",
      "Epoch 235/300\n",
      "155/155 [==============================] - 0s 358us/step - loss: 0.2899 - acc: 0.8968\n",
      "Epoch 236/300\n",
      "155/155 [==============================] - 0s 332us/step - loss: 0.2976 - acc: 0.9097\n",
      "Epoch 237/300\n",
      "155/155 [==============================] - 0s 313us/step - loss: 0.3074 - acc: 0.8774\n",
      "Epoch 238/300\n",
      "155/155 [==============================] - 0s 283us/step - loss: 0.2929 - acc: 0.8903\n",
      "Epoch 239/300\n",
      "155/155 [==============================] - 0s 301us/step - loss: 0.3001 - acc: 0.8903\n",
      "Epoch 240/300\n",
      "155/155 [==============================] - 0s 271us/step - loss: 0.3036 - acc: 0.8774\n",
      "Epoch 241/300\n",
      "155/155 [==============================] - 0s 322us/step - loss: 0.2989 - acc: 0.8903\n",
      "Epoch 242/300\n",
      "155/155 [==============================] - 0s 187us/step - loss: 0.2728 - acc: 0.9032\n",
      "Epoch 243/300\n",
      "155/155 [==============================] - 0s 271us/step - loss: 0.3065 - acc: 0.8968\n",
      "Epoch 244/300\n",
      "155/155 [==============================] - 0s 264us/step - loss: 0.2948 - acc: 0.8645\n",
      "Epoch 245/300\n",
      "155/155 [==============================] - 0s 270us/step - loss: 0.2890 - acc: 0.8774\n",
      "Epoch 246/300\n",
      "155/155 [==============================] - 0s 151us/step - loss: 0.2835 - acc: 0.9226\n",
      "Epoch 247/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155/155 [==============================] - 0s 178us/step - loss: 0.2883 - acc: 0.8774\n",
      "Epoch 248/300\n",
      "155/155 [==============================] - 0s 184us/step - loss: 0.2814 - acc: 0.8903\n",
      "Epoch 249/300\n",
      "155/155 [==============================] - 0s 170us/step - loss: 0.2710 - acc: 0.9032\n",
      "Epoch 250/300\n",
      "155/155 [==============================] - 0s 186us/step - loss: 0.3100 - acc: 0.8839\n",
      "Epoch 251/300\n",
      "155/155 [==============================] - 0s 162us/step - loss: 0.2897 - acc: 0.8968\n",
      "Epoch 252/300\n",
      "155/155 [==============================] - 0s 161us/step - loss: 0.2791 - acc: 0.8968\n",
      "Epoch 253/300\n",
      "155/155 [==============================] - 0s 201us/step - loss: 0.2627 - acc: 0.9161\n",
      "Epoch 254/300\n",
      "155/155 [==============================] - 0s 233us/step - loss: 0.2915 - acc: 0.9032\n",
      "Epoch 255/300\n",
      "155/155 [==============================] - 0s 171us/step - loss: 0.2775 - acc: 0.9097\n",
      "Epoch 256/300\n",
      "155/155 [==============================] - 0s 157us/step - loss: 0.2715 - acc: 0.9161\n",
      "Epoch 257/300\n",
      "155/155 [==============================] - 0s 162us/step - loss: 0.2761 - acc: 0.8903\n",
      "Epoch 258/300\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2585 - acc: 0.9226\n",
      "Epoch 259/300\n",
      "155/155 [==============================] - 0s 164us/step - loss: 0.2683 - acc: 0.9161\n",
      "Epoch 260/300\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.2715 - acc: 0.9290\n",
      "Epoch 261/300\n",
      "155/155 [==============================] - 0s 171us/step - loss: 0.2811 - acc: 0.9097\n",
      "Epoch 262/300\n",
      "155/155 [==============================] - 0s 179us/step - loss: 0.2828 - acc: 0.9097\n",
      "Epoch 263/300\n",
      "155/155 [==============================] - 0s 194us/step - loss: 0.2734 - acc: 0.8903\n",
      "Epoch 264/300\n",
      "155/155 [==============================] - 0s 221us/step - loss: 0.2533 - acc: 0.8968\n",
      "Epoch 265/300\n",
      "155/155 [==============================] - 0s 297us/step - loss: 0.2812 - acc: 0.8839\n",
      "Epoch 266/300\n",
      "155/155 [==============================] - 0s 225us/step - loss: 0.2948 - acc: 0.9097\n",
      "Epoch 267/300\n",
      "155/155 [==============================] - 0s 167us/step - loss: 0.2874 - acc: 0.8968\n",
      "Epoch 268/300\n",
      "155/155 [==============================] - 0s 156us/step - loss: 0.2695 - acc: 0.9226\n",
      "Epoch 269/300\n",
      "155/155 [==============================] - 0s 164us/step - loss: 0.2444 - acc: 0.8968\n",
      "Epoch 270/300\n",
      "155/155 [==============================] - 0s 160us/step - loss: 0.2706 - acc: 0.9097\n",
      "Epoch 271/300\n",
      "155/155 [==============================] - 0s 159us/step - loss: 0.2709 - acc: 0.9032\n",
      "Epoch 272/300\n",
      "155/155 [==============================] - 0s 167us/step - loss: 0.2626 - acc: 0.9161\n",
      "Epoch 273/300\n",
      "155/155 [==============================] - 0s 170us/step - loss: 0.2734 - acc: 0.9226\n",
      "Epoch 274/300\n",
      "155/155 [==============================] - 0s 158us/step - loss: 0.2744 - acc: 0.9032\n",
      "Epoch 275/300\n",
      "155/155 [==============================] - 0s 156us/step - loss: 0.2704 - acc: 0.9161\n",
      "Epoch 276/300\n",
      "155/155 [==============================] - 0s 159us/step - loss: 0.2857 - acc: 0.8774\n",
      "Epoch 277/300\n",
      "155/155 [==============================] - 0s 161us/step - loss: 0.2831 - acc: 0.8968\n",
      "Epoch 278/300\n",
      "155/155 [==============================] - 0s 164us/step - loss: 0.2825 - acc: 0.8968\n",
      "Epoch 279/300\n",
      "155/155 [==============================] - 0s 158us/step - loss: 0.2609 - acc: 0.9226\n",
      "Epoch 280/300\n",
      "155/155 [==============================] - 0s 157us/step - loss: 0.2711 - acc: 0.9161\n",
      "Epoch 281/300\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.2807 - acc: 0.8839\n",
      "Epoch 282/300\n",
      "155/155 [==============================] - 0s 171us/step - loss: 0.2618 - acc: 0.9161\n",
      "Epoch 283/300\n",
      "155/155 [==============================] - 0s 160us/step - loss: 0.2816 - acc: 0.8968\n",
      "Epoch 284/300\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.2658 - acc: 0.8903\n",
      "Epoch 285/300\n",
      "155/155 [==============================] - 0s 175us/step - loss: 0.2632 - acc: 0.9032\n",
      "Epoch 286/300\n",
      "155/155 [==============================] - 0s 169us/step - loss: 0.2510 - acc: 0.9097\n",
      "Epoch 287/300\n",
      "155/155 [==============================] - 0s 176us/step - loss: 0.2514 - acc: 0.9032\n",
      "Epoch 288/300\n",
      "155/155 [==============================] - 0s 172us/step - loss: 0.2452 - acc: 0.9290\n",
      "Epoch 289/300\n",
      "155/155 [==============================] - 0s 182us/step - loss: 0.2590 - acc: 0.9290\n",
      "Epoch 290/300\n",
      "155/155 [==============================] - 0s 184us/step - loss: 0.2374 - acc: 0.9226\n",
      "Epoch 291/300\n",
      "155/155 [==============================] - 0s 177us/step - loss: 0.2773 - acc: 0.8968\n",
      "Epoch 292/300\n",
      "155/155 [==============================] - 0s 195us/step - loss: 0.2557 - acc: 0.9097\n",
      "Epoch 293/300\n",
      "155/155 [==============================] - 0s 167us/step - loss: 0.2632 - acc: 0.8968\n",
      "Epoch 294/300\n",
      "155/155 [==============================] - 0s 186us/step - loss: 0.2595 - acc: 0.9032\n",
      "Epoch 295/300\n",
      "155/155 [==============================] - 0s 226us/step - loss: 0.2403 - acc: 0.9226\n",
      "Epoch 296/300\n",
      "155/155 [==============================] - 0s 325us/step - loss: 0.2492 - acc: 0.9290\n",
      "Epoch 297/300\n",
      "155/155 [==============================] - 0s 325us/step - loss: 0.2575 - acc: 0.8968\n",
      "Epoch 298/300\n",
      "155/155 [==============================] - 0s 239us/step - loss: 0.2547 - acc: 0.9161\n",
      "Epoch 299/300\n",
      "155/155 [==============================] - 0s 257us/step - loss: 0.2559 - acc: 0.9032\n",
      "Epoch 300/300\n",
      "155/155 [==============================] - 0s 259us/step - loss: 0.2488 - acc: 0.8903\n",
      "52/52 [==============================] - 1s 25ms/step\n",
      "[0.41383109184411854, 0.7692307738157419]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(60, input_dim=60, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "             loss = 'binary_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "model.fit(x_train, y_train, epochs = 300, batch_size = 50, verbose = 1)\n",
    "\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data / Conclusion\n",
    "\n",
    "Finally we can see that test_loss and test_accuracy are actually improving therefore the model is able to predict whether sonar sound is being bounced off a metal or rock cylinder.\n",
    "Further tuning can be done to further reduce the noise and continuously improve the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
